<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": 4.0,
  "old_code": "# [rewrite_cell]\\nfrom typing import Any\\nimport jax\\nfrom sklearn.decomposition import TruncatedSVD\\nimport tensorflow as tf\\nimport torch\\nimport numpy as np\\nimport scanpy as sc\\nfrom sklearn.neighbors import NearestNeighbors\\nfrom scipy.sparse import csr_matrix\\n\\n# Define parameters for the config.\\nconfig = {\\n    'n_neighbors_per_batch': 15,  # k for KNN within each batch as per advice\\n    'n_pcs': 50,  # Number of principal components for embedding\\n    'min_dist_umap': 0.5,  # UMAP parameter\\n    'spread_umap': 1.0,  # UMAP parameter\\n    'random_state': 42,  # For reproducibility\\n}\\n\\n\\ndef eliminate_batch_effect_fn(\\n    adata: ad.AnnData, config: dict[str, Any]\\n) -> ad.AnnData:\\n  # 1. Preprocessing: Normalize, log-transform, scale, and PCA\\n  # These are standard steps before building a neighborhood graph\\n  # for single-cell data.\\n  sc.pp.normalize_total(adata, target_sum=1e4)\\n  sc.pp.log1p(adata)\\n  sc.pp.scale(adata, max_value=10) # Clip values after scaling to prevent outliers from dominating PCA\\n  sc.tl.pca(\\n      adata,\\n      n_comps=config.get('n_pcs', 50),\\n      svd_solver='arpack',\\n      random_state=config.get('random_state', 42)\\n  )\\n\\n  # Get PCA embedding, batch labels, and number of cells\\n  X_pca = adata.obsm['X_pca']\\n  n_cells = adata.shape[0]\\n  batch_labels = adata.obs['batch']\\n  unique_batches = batch_labels.unique()\\n\\n  n_neighbors_per_batch = config.get('n_neighbors_per_batch', 15)\\n\\n  # Prepare lists to store edges for the combined graph\\n  sources = []\\n  targets = []\\n  edge_distances = []\\n\\n  # 2. Batch-Corrected Neighborhood Graph Construction\\n  # For each cell, identify k-nearest neighbors independently within each batch.\\n  # This follows the \\"Major advice\\" description.\\n  for batch_id in unique_batches:\\n    # Get indices and PCA data for the current batch\\n    batch_indices = np.where(batch_labels == batch_id)[0]\\n    batch_X_pca = X_pca[batch_indices]\\n\\n    # Handle batches smaller than k_neighbors (NearestNeighbors needs at least k+1 samples)\\n    k_current = min(n_neighbors_per_batch, len(batch_indices) - 1)\\n    if k_current <= 0: # If batch has 0 or 1 cell, cannot find neighbors\\n      continue\\n\\n    # Find k-nearest neighbors within the current batch\\n    # Use k_current + 1 because NearestNeighbors includes the query point itself\\n    nn = NearestNeighbors(\\n        n_neighbors=k_current + 1, metric='euclidean', algorithm='kd_tree'\\n    )\\n    nn.fit(batch_X_pca)\\n    dists, indices = nn.kneighbors(batch_X_pca)\\n\\n    # Convert batch-local indices back to global indices and store neighbors/distances\\n    for i in range(len(batch_indices)):\\n      global_source_idx = batch_indices[i]\\n      # Exclude the query point itself (the first index in \`indices\`)\\n      global_target_indices = batch_indices[indices[i, 1:]]\\n      current_dists = dists[i, 1:]\\n\\n      sources.extend([global_source_idx] * len(global_target_indices))\\n      targets.extend(global_target_indices)\\n      edge_distances.extend(current_dists)\\n\\n  # Fallback if no neighbors are found (e.g., all batches too small or no data)\\n  # In such a case, PCA embedding is returned directly as a simple representation.\\n  if not sources or not targets or not edge_distances:\\n      output_data = ad.AnnData(\\n          obs=adata.obs,\\n          var=adata.var,\\n          obsm={'X_emb': adata.obsm['X_pca']}\\n      )\\n      return output_data\\n\\n  # 3. Construct combined sparse matrices for distances and connectivities\\n  # These will be stored in adata.obsp and used by UMAP.\\n  distances_matrix = csr_matrix(\\n      (edge_distances, (sources, targets)), shape=(n_cells, n_cells)\\n  )\\n\\n  # For connectivities, we use a simple binary matrix where an edge exists if cells are neighbors.\\n  connectivities_matrix = distances_matrix.copy()\\n  connectivities_matrix.data = np.ones_like(connectivities_matrix.data, dtype=np.float32)\\n\\n  # Make matrices symmetric for undirected graph and remove self-loops.\\n  # This is important for many graph-based algorithms like UMAP.\\n  adata.obsp['distances'] = distances_matrix.maximum(distances_matrix.T).tocsr()\\n  adata.obsp['connectivities'] = connectivities_matrix.maximum(connectivities_matrix.T).tocsr()\\n\\n  adata.obsp['distances'].setdiag(0)\\n  adata.obsp['connectivities'].setdiag(0)\\n\\n  adata.obsp['distances'].eliminate_zeros()\\n  adata.obsp['connectivities'].eliminate_zeros()\\n\\n  # 4. Set adata.uns['neighbors'] to make Scanpy's UMAP compatible\\n  # This structure mimics what sc.pp.neighbors would produce.\\n  # The n_neighbors value here is a conceptual placeholder as the actual neighbors are batch-specific.\\n  adata.uns['neighbors'] = {\\n      'params': {\\n          'n_neighbors': n_neighbors_per_batch,\\n          'method': 'custom_batch_corrected_knn',\\n          'metric': 'euclidean',\\n          'use_rep': 'X_pca',\\n      },\\n      'connectivities_key': 'connectivities',\\n      'distances_key': 'distances',\\n  }\\n\\n  # 5. Run UMAP using the newly constructed graph\\n  sc.tl.umap(\\n      adata,\\n      min_dist=config.get('min_dist_umap', 0.5),\\n      spread=config.get('spread_umap', 1.0),\\n      random_state=config.get('random_state', 42)\\n  )\\n\\n  # The batch-integrated embedding is the UMAP result.\\n  output_data = ad.AnnData(\\n      obs=adata.obs,\\n      var=adata.var,\\n      obsm={\\n          'X_emb': adata.obsm['X_umap']\\n      },\\n  )\\n\\n  return output_data",
  "new_index": 19,
  "new_code": "# [rewrite_cell]\\nfrom typing import Any\\nimport numpy as np\\nimport scanpy as sc\\nfrom sklearn.neighbors import NearestNeighbors\\nfrom scipy.sparse import csr_matrix, coo_matrix\\n\\n# Define parameters for the config.\\nconfig = {\\n    'n_neighbors_per_batch': 15,  # k for KNN within each batch as per advice\\n    'n_pcs': 50,  # Number of principal components for embedding\\n    'min_dist_umap': 0.5,  # UMAP parameter\\n    'spread_umap': 1.0,  # UMAP parameter\\n    'random_state': 42,  # For reproducibility\\n}\\n\\n\\ndef eliminate_batch_effect_fn(\\n    adata: ad.AnnData, config: dict[str, Any]\\n) -> ad.AnnData:\\n  # 1. Preprocessing: Normalize, log-transform, scale, and PCA\\n  # These are standard steps before building a neighborhood graph\\n  # for single-cell data.\\n  sc.pp.normalize_total(adata, target_sum=1e4)\\n  sc.pp.log1p(adata)\\n  sc.pp.scale(adata, max_value=10) # Clip values after scaling to prevent outliers from dominating PCA\\n  sc.tl.pca(\\n      adata,\\n      n_comps=config.get('n_pcs', 50),\\n      svd_solver='arpack',\\n      random_state=config.get('random_state', 42)\\n  )\\n\\n  # Get PCA embedding, batch labels, and number of cells\\n  X_pca = adata.obsm['X_pca']\\n  n_cells = adata.shape[0]\\n  batch_labels = adata.obs['batch'].astype('category') # Ensure categorical for efficient unique() and indexing\\n  unique_batches = batch_labels.unique()\\n\\n  n_neighbors_per_batch = config.get('n_neighbors_per_batch', 15)\\n\\n  # Store NearestNeighbors models fitted for each batch\\n  nn_models_per_batch = {}\\n  batch_global_indices = {} # Map batch_id to global indices for efficient lookup\\n\\n  for batch_id in unique_batches:\\n    current_batch_global_indices = np.where(batch_labels == batch_id)[0]\\n    batch_global_indices[batch_id] = current_batch_global_indices\\n\\n    # Fit a NearestNeighbors model only on the data points of the current batch\\n    if len(current_batch_global_indices) > 0:\\n      batch_X_pca = X_pca[current_batch_global_indices]\\n      # k_actual: number of neighbors to query. If batch is smaller than k_neighbors_per_batch,\\n      # we query all cells in the batch. +1 because kNN includes query point itself.\\n      k_actual = min(n_neighbors_per_batch + 1, len(batch_X_pca))\\n      if k_actual > 0: # Ensure k_actual is positive\\n          nn = NearestNeighbors(\\n              n_neighbors=k_actual, metric='euclidean', algorithm='kd_tree', n_jobs=-1\\n          )\\n          nn.fit(batch_X_pca)\\n          nn_models_per_batch[batch_id] = nn\\n\\n  # Prepare lists to store edges for the combined graph\\n  sources_list = []\\n  targets_list = []\\n  distances_list = []\\n\\n  # 2. Batch-Corrected Neighborhood Graph Construction\\n  # For each cell, iterate through every batch to find k-nearest neighbors\\n  # from within that batch, and then merge these lists.\\n  for i in range(n_cells):\\n    current_cell_pca = X_pca[i:i+1] # Query point (1, n_pcs)\\n\\n    # Use a dictionary to collect unique neighbor indices and store the minimum distance\\n    # if a target cell appears via multiple batch searches.\\n    temp_neighbors = {} # Stores {global_target_idx: min_distance_to_target}\\n\\n    for batch_id in unique_batches:\\n      if batch_id in nn_models_per_batch: # Check if model was fitted for this batch\\n        nn_model = nn_models_per_batch[batch_id]\\n        current_batch_indices = batch_global_indices[batch_id]\\n\\n        # Determine how many neighbors to query from this specific batch.\\n        # This is the max number of neighbors requested, or the total available cells in batch.\\n        # We query for n_neighbors_per_batch *other* cells. If the batch contains the query cell itself,\\n        # NearestNeighbors might return it as one of the closest.\\n        k_to_query = min(n_neighbors_per_batch + 1, len(current_batch_indices))\\n\\n        if k_to_query == 0: # If batch has 0 or 1 cell (and n_neighbors_per_batch is >0), k_to_query might become 0.\\n          continue\\n\\n        # Query the batch-specific NN model\\n        dists, local_indices = nn_model.kneighbors(current_cell_pca, n_neighbors=k_to_query)\\n\\n        # Convert local indices back to global indices\\n        global_target_indices = current_batch_indices[local_indices[0]]\\n        current_dists = dists[0]\\n\\n        for k in range(len(global_target_indices)):\\n          target_idx = global_target_indices[k]\\n          dist = current_dists[k]\\n\\n          # Add edge, ensuring no self-loops and taking the minimum distance if duplicate\\n          if i != target_idx:\\n            if target_idx not in temp_neighbors or dist < temp_neighbors[target_idx]:\\n              temp_neighbors[target_idx] = dist\\n\\n    # Add the collected neighbors for cell 'i' to the global lists\\n    for target_idx, dist in temp_neighbors.items():\\n      sources_list.append(i)\\n      targets_list.append(target_idx)\\n      distances_list.append(dist)\\n\\n  # Fallback if no neighbors are found (e.g., all batches too small or no data)\\n  # In such a case, PCA embedding is returned directly as a simple representation.\\n  if not sources_list:\\n      output_data = ad.AnnData(\\n          obs=adata.obs,\\n          var=adata.var,\\n          obsm={'X_emb': adata.obsm['X_pca']}\\n      )\\n      return output_data\\n\\n  # 3. Construct combined sparse matrices for distances and connectivities\\n  # Use coo_matrix for efficient construction from lists of (row, col, data)\\n  distances_coo = coo_matrix(\\n      (distances_list, (sources_list, targets_list)), shape=(n_cells, n_cells)\\n  )\\n\\n  # For connectivities, a simple binary matrix where an edge exists if cells are neighbors.\\n  # UMAP's neighbor calculation relies on these, even if they are simple binary.\\n  connectivities_data = np.ones_like(distances_list, dtype=np.float32)\\n  connectivities_coo = coo_matrix(\\n      (connectivities_data, (sources_list, targets_list)), shape=(n_cells, n_cells)\\n  )\\n\\n  # Make matrices symmetric for undirected graph and remove self-loops.\\n  # This is important for many graph-based algorithms like UMAP.\\n  # Add transpose and take maximum to ensure symmetry. Convert to CSR for efficiency.\\n  adata.obsp['distances'] = distances_coo.maximum(distances_coo.T).tocsr()\\n  adata.obsp['connectivities'] = connectivities_coo.maximum(connectivities_coo.T).tocsr()\\n\\n  adata.obsp['distances'].setdiag(0)\\n  adata.obsp['connectivities'].setdiag(0)\\n\\n  adata.obsp['distances'].eliminate_zeros()\\n  adata.obsp['connectivities'].eliminate_zeros()\\n\\n  # 4. Set adata.uns['neighbors'] to make Scanpy's UMAP compatible\\n  # This structure mimics what sc.pp.neighbors would produce.\\n  # The n_neighbors value here is a conceptual placeholder as the actual neighbors are batch-specific.\\n  adata.uns['neighbors'] = {\\n      'params': {\\n          'n_neighbors': n_neighbors_per_batch, # This is 'k' for the *within-batch* search\\n          'method': 'custom_batch_corrected_knn',\\n          'metric': 'euclidean',\\n          'use_rep': 'X_pca', # UMAP will use this as a hint but the graph is directly provided\\n      },\\n      'connectivities_key': 'connectivities',\\n      'distances_key': 'distances',\\n  }\\n\\n  # 5. Run UMAP using the newly constructed graph\\n  # Scanpy's UMAP will automatically use adata.obsp['connectivities'] and adata.obsp['distances']\\n  # if they are already present.\\n  sc.tl.umap(\\n      adata,\\n      min_dist=config.get('min_dist_umap', 0.5),\\n      spread=config.get('spread_umap', 1.0),\\n      random_state=config.get('random_state', 42)\\n  )\\n\\n  # The batch-integrated embedding is the UMAP result.\\n  output_data = ad.AnnData(\\n      obs=adata.obs,\\n      var=adata.var,\\n      obsm={\\n          'X_emb': adata.obsm['X_umap']\\n      },\\n  )\\n\\n  return output_data"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
