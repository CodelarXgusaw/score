<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": "317",
  "old_code": "import numpy as np\\nimport pandas as pd\\nfrom lightgbm import LGBMRegressor\\nfrom typing import Any\\n\\ndef fit_and_predict_fn(\\n    train_x: pd.DataFrame,\\n    train_y: pd.Series,\\n    test_x: pd.DataFrame,\\n    config: dict[str, Any]\\n) -> pd.DataFrame:\\n    \\"\\"\\"Make probabilistic predictions for test_x by modeling train_x to train_y.\\n\\n    The model uses LightGBM for quantile regression. It incorporates time-series\\n    features, a population-normalized and transformed target variable,\\n    and location information. The approach aims for robustness and generalization\\n    by leveraging common time-series patterns and normalizing the target by population.\\n    Lagged target variables and rolling means are explicitly created and utilized.\\n\\n    Improved missing data handling for time-series features involves:\\n    1. Using \`closed='left'\` for rolling means to correctly compute statistics from past data\\n       and prevent future data leakage.\\n    2. Applying \`ffill()\` followed by \`fillna(0)\` to impute NaNs in lagged/rolling\\n       features for training data within each group, preserving more data points\\n       compared to simple \`dropna()\`.\\n\\n    Args:\\n        train_x (pd.DataFrame): Training features.\\n        train_y (pd.Series): Training target values (Total COVID-19 Admissions).\\n        test_x (pd.DataFrame): Test features for future time periods.\\n        config (dict[str, Any]): Configuration parameters for the model.\\n\\n    Returns:\\n        pd.DataFrame: DataFrame with quantile predictions for each row in test_x.\\n                      Columns are named 'quantile_0.XX'.\\n    \\"\\"\\"\\n    QUANTILES = [\\n        0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\\n        0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.975, 0.99\\n    ]\\n    TARGET_COL = 'Total COVID-19 Admissions'\\n    DATE_COL = 'target_end_date'\\n    LOCATION_COL = 'location'\\n    POPULATION_COL = 'population'\\n    HORIZON_COL = 'horizon'\\n    \\n    # Define a new transformed target column name\\n    TRANSFORMED_TARGET_COL = 'transformed_admissions_per_million'\\n\\n    # --- Configuration for LightGBM and Feature Engineering ---\\n    # Default LGBM parameters, optimized from previous trials.\\n    default_lgbm_params = {\\n        'objective': 'quantile',\\n        'metric': 'quantile',\\n        'n_estimators': 200,      \\n        'learning_rate': 0.03,     \\n        'num_leaves': 25,         \\n        'max_depth': 5,           \\n        'min_child_samples': 20,  \\n        'random_state': 42,       \\n        'n_jobs': -1,             \\n        'verbose': -1,            \\n        'colsample_bytree': 0.8,  \\n        'subsample': 0.8,         \\n        'reg_alpha': 0.1,         \\n        'reg_lambda': 0.1         \\n    }\\n    lgbm_params = {**default_lgbm_params, **config.get('lgbm_params', {})}\\n\\n    # Lag weeks and rolling windows for feature engineering.\\n    # These parameters can be overridden by the \`config\` dictionary.\\n    LAG_WEEKS = config.get('lag_weeks', [1, 2, 3, 4, 8, 26, 52]) \\n    ROLLING_WINDOWS = config.get('rolling_windows', [2, 4, 8, 16]) \\n    \\n    # Target transformation type - configurable via the 'config' dictionary.\\n    target_transform_type = config.get('target_transform', 'log1p') # Default to log1p\\n\\n    # --- Feature Engineering ---\\n\\n    # 1. Combine train_x and train_y, and prepare for transformations\\n    df_train_full = train_x.copy()\\n    df_train_full[TARGET_COL] = train_y\\n    df_train_full[DATE_COL] = pd.to_datetime(df_train_full[DATE_COL])\\n    # Sort data for correct lag/rolling calculations. Essential for time-series features.\\n    df_train_full = df_train_full.sort_values(by=[LOCATION_COL, DATE_COL]).reset_index(drop=True)\\n\\n    # Calculate transformed target: Admissions per million people, then apply chosen transformation.\\n    # Handle potential division by zero for population.\\n    admissions_per_million = df_train_full[TARGET_COL] / df_train_full[POPULATION_COL].replace(0, np.nan) * 1_000_000\\n    admissions_per_million = admissions_per_million.fillna(0) # Fill NaNs from 0 population or missing\\n    admissions_per_million[admissions_per_million < 0] = 0 # Ensure non-negative before transform\\n\\n    if target_transform_type == 'log1p':\\n        df_train_full[TRANSFORMED_TARGET_COL] = np.log1p(admissions_per_million)\\n    elif target_transform_type == 'sqrt':\\n        df_train_full[TRANSFORMED_TARGET_COL] = np.sqrt(admissions_per_million)\\n    elif target_transform_type == 'fourth_root':\\n        df_train_full[TRANSFORMED_TARGET_COL] = np.power(admissions_per_million, 0.25)\\n    else: # Fallback to raw (per million) if transform type is unknown/invalid\\n        df_train_full[TRANSFORMED_TARGET_COL] = admissions_per_million\\n\\n    # 2. Function to add common date-based features\\n    def add_base_features(df_input: pd.DataFrame, min_date_global: pd.Timestamp) -> pd.DataFrame:\\n        df = df_input.copy()\\n        df[DATE_COL] = pd.to_datetime(df[DATE_COL])\\n        \\n        df['year'] = df[DATE_COL].dt.year\\n        df['month'] = df[DATE_COL].dt.month\\n        # Use .isocalendar().week for ISO week number, handling potential differences around year end.\\n        df['week_of_year'] = df[DATE_COL].dt.isocalendar().week.astype(int)\\n        \\n        # Add cyclical features for week of year to capture seasonality smoothly\\n        df['sin_week_of_year'] = np.sin(2 * np.pi * df['week_of_year'] / 52)\\n        df['cos_week_of_year'] = np.cos(2 * np.pi * df['week_of_year'] / 52)\\n\\n        # Weeks since start of the entire dataset, to capture overall trend.\\n        df['weeks_since_start'] = ((df[DATE_COL] - min_date_global).dt.days / 7).astype(int)\\n        \\n        return df\\n\\n    # Determine the global minimum date from the training set for \`weeks_since_start\` consistency\\n    min_date_global = df_train_full[DATE_COL].min()\\n    \\n    # Apply feature extraction to training and test dataframes\\n    df_train_full = add_base_features(df_train_full, min_date_global)\\n    test_x_processed = add_base_features(test_x.copy(), min_date_global) \\n    \\n    # Define base features (features not derived from the target variable)\\n    BASE_FEATURES = [POPULATION_COL, 'year', 'month', 'week_of_year',\\n                     'sin_week_of_year', 'cos_week_of_year', 'weeks_since_start']\\n    CATEGORICAL_FEATURES_LIST = [LOCATION_COL] \\n\\n    # 3. Generate time-series dependent features for training data\\n    train_features_df = df_train_full.copy()\\n    \\n    # Generate lagged transformed target features for each location group\\n    for lag in LAG_WEEKS:\\n        train_features_df[f'lag_{lag}_wk'] = train_features_df.groupby(LOCATION_COL)[TRANSFORMED_TARGET_COL].shift(lag)\\n\\n    # Generate rolling mean features, shifted by 1 to avoid data leakage (using past data), based on transformed target\\n    for window in ROLLING_WINDOWS:\\n        # Use \`closed='left'\` to ensure window includes data *before* the current date.\\n        # This correctly computes rolling mean of the previous 'window' periods.\\n        train_features_df[f'rolling_mean_{window}_wk'] = \\\\\\n            train_features_df.groupby(LOCATION_COL)[TRANSFORMED_TARGET_COL].transform(\\n                lambda x: x.rolling(window=window, min_periods=1, closed='left').mean()\\n            )\\n    \\n    y_train_model = train_features_df[TRANSFORMED_TARGET_COL]\\n    \\n    # Compile the list of all feature columns for training\\n    train_specific_features = [f'lag_{lag}_wk' for lag in LAG_WEEKS] + \\\\\\n                              [f'rolling_mean_{window}_wk' for window in ROLLING_WINDOWS] \\n    \\n    X_train_model_cols = BASE_FEATURES + CATEGORICAL_FEATURES_LIST + train_specific_features\\n    X_train_model = train_features_df[X_train_model_cols].copy()\\n\\n    # Add the 'horizon' feature to the training data. For historical data, horizon is 0.\\n    # This column is present in \`test_x\` but not in \`train_x\`.\\n    if HORIZON_COL not in X_train_model.columns:\\n        X_train_model[HORIZON_COL] = 0 \\n\\n    # --- Time-series specific missing data handling for training features ---\\n    # Apply forward fill then fill remaining initial NaNs with 0 within each location group.\\n    # This helps preserve more data points compared to dropping rows while maintaining time-series context.\\n    for col in train_specific_features:\\n        if X_train_model[col].isnull().any():\\n            # First, forward fill within each group to fill gaps within a time series\\n            X_train_model[col] = X_train_model.groupby(LOCATION_COL)[col].transform(lambda x: x.ffill())\\n            # Then, fill any remaining NaNs (typically at the very beginning of a series where ffill can't apply) with 0.0\\n            X_train_model[col] = X_train_model[col].fillna(0.0)\\n    \\n    # Drop rows from training data where the target is NaN (should not be many)\\n    # or if some very specific edge cases resulted in NaNs in features even after imputation.\\n    # This is a final safeguard for model training.\\n    train_combined = X_train_model.copy()\\n    train_combined[TRANSFORMED_TARGET_COL] = y_train_model\\n    train_combined.dropna(inplace=True) \\n    \\n    X_train_model = train_combined.drop(columns=[TRANSFORMED_TARGET_COL])\\n    y_train_model = train_combined[TRANSFORMED_TARGET_COL]\\n\\n    # Cast 'location' to category type for LightGBM for efficient handling\\n    X_train_model[LOCATION_COL] = X_train_model[LOCATION_COL].astype('category')\\n\\n\\n    # 4. Generate features for test data\\n    # Initial features for test set, including the inherent 'horizon' from test_x\\n    X_test_model = test_x_processed[BASE_FEATURES + CATEGORICAL_FEATURES_LIST + [HORIZON_COL]].copy()\\n    \\n    # Derive 'latest observed' lag and rolling features for the test data.\\n    # These features must be based ONLY on the *transformed* data available up to the last date in train_y.\\n    max_train_date = df_train_full[DATE_COL].max() # The latest date for which target data is available\\n    \\n    # Create an empty DataFrame to hold the new lag/rolling features for test_x\\n    test_lag_rolling_features = pd.DataFrame(index=X_test_model.index)\\n    for col in train_specific_features:\\n        test_lag_rolling_features[col] = 0.0 # Initialize with default zero\\n\\n    # Calculate and apply the latest available lagged/rolling features for each location in test_x\\n    for loc_id in X_test_model[LOCATION_COL].unique():\\n        # Filter historical data for the current location, up to max_train_date\\n        loc_hist_data = df_train_full[\\n            (df_train_full[LOCATION_COL] == loc_id) & \\n            (df_train_full[DATE_COL] <= max_train_date)\\n        ].sort_values(DATE_COL)\\n        \\n        # Get the indices in X_test_model that belong to the current location\\n        loc_test_indices = X_test_model.index[X_test_model[LOCATION_COL] == loc_id]\\n\\n        if not loc_hist_data.empty:\\n            # Populate lag features from the end of the historical transformed data\\n            for lag in LAG_WEEKS:\\n                lag_col_name = f'lag_{lag}_wk'\\n                if len(loc_hist_data) >= lag:\\n                    latest_lag_value = loc_hist_data[TRANSFORMED_TARGET_COL].iloc[-lag]\\n                else:\\n                    # If not enough history for a specific lag, use the most recent available value (if any)\\n                    # or 0 if no data.\\n                    latest_lag_value = loc_hist_data[TRANSFORMED_TARGET_COL].iloc[-1] if not loc_hist_data[TRANSFORMED_TARGET_COL].empty else 0.0\\n                test_lag_rolling_features.loc[loc_test_indices, lag_col_name] = latest_lag_value\\n            \\n            # Populate rolling features from the end of the historical transformed data\\n            for window in ROLLING_WINDOWS:\\n                rolling_col_name = f'rolling_mean_{window}_wk'\\n                # Get the last 'window' values from historical data for the rolling mean.\\n                rolling_data = loc_hist_data[TRANSFORMED_TARGET_COL].tail(window) \\n                if not rolling_data.empty:\\n                    rolling_mean_val = rolling_data.mean()\\n                    test_lag_rolling_features.loc[loc_test_indices, rolling_col_name] = rolling_mean_val if not pd.isna(rolling_mean_val) else 0.0\\n                else:\\n                    test_lag_rolling_features.loc[loc_test_indices, rolling_col_name] = 0.0\\n        else: # Handle case where there's NO historical data for a location in train_x\\n            for col in train_specific_features:\\n                test_lag_rolling_features.loc[loc_test_indices, col] = 0.0 # Default to 0 for missing history\\n    \\n    # Merge the computed lag/rolling features into X_test_model\\n    X_test_model = pd.concat([X_test_model, test_lag_rolling_features], axis=1)\\n\\n    # Impute any remaining NaNs in test features (e.g., for new locations not in train or specific edge cases)\\n    for col in train_specific_features: # Only numerical features are likely to have NaNs here\\n        if col in X_test_model.columns:\\n            X_test_model[col] = X_test_model[col].fillna(0.0)\\n\\n\\n    # 5. Align columns between train and test datasets\\n    # This step is critical to ensure feature consistency for the model\\n    final_feature_cols = X_train_model.columns.tolist() \\n\\n    # Ensure both DataFrames have the exact same columns in the exact same order\\n    # It is crucial to reindex X_test_model with the columns from X_train_model\\n    X_test_model = X_test_model.reindex(columns=final_feature_cols, fill_value=0) \\n\\n    # Re-cast 'location' in X_test_model to category type with categories from train.\\n    train_location_categories = X_train_model[LOCATION_COL].cat.categories\\n    X_test_model[LOCATION_COL] = X_test_model[LOCATION_COL].astype(pd.CategoricalDtype(categories=train_location_categories))\\n    \\n    # Identify categorical features for LightGBM based on the final aligned columns\\n    categorical_features_lgbm = [LOCATION_COL] \\n    # Treat 'horizon' as categorical if it's present, as its values are discrete and limited.\\n    if HORIZON_COL in final_feature_cols:\\n        X_train_model[HORIZON_COL] = X_train_model[HORIZON_COL].astype('category')\\n        # Ensure test horizon categories are consistent with train, including potential new horizon values in test_x\\n        test_horizon_categories = X_train_model[HORIZON_COL].cat.categories.union(test_x_processed[HORIZON_COL].astype('category').cat.categories)\\n        X_test_model[HORIZON_COL] = X_test_model[HORIZON_COL].astype(pd.CategoricalDtype(categories=test_horizon_categories))\\n        categorical_features_lgbm.append(HORIZON_COL)\\n\\n\\n    # --- Model Training and Prediction ---\\n    predictions = {}\\n    for q in QUANTILES:\\n        model_params = lgbm_params.copy()\\n        model_params['alpha'] = q # Set the quantile for this specific model for LightGBM's quantile objective\\n\\n        # Initialize and train LightGBM Regressor for the current quantile\\n        model = LGBMRegressor(**model_params)\\n        model.fit(X_train_model, y_train_model,\\n                  categorical_feature=categorical_features_lgbm)\\n        \\n        # Make predictions for the current quantile on the test set\\n        preds_q_transformed = model.predict(X_test_model)\\n        predictions[f'quantile_{q}'] = preds_q_transformed\\n\\n    # --- Post-processing ---\\n    # Convert predictions dictionary to a DataFrame, matching the test_x index\\n    predictions_df = pd.DataFrame(predictions, index=test_x.index)\\n\\n    # Inverse transform predictions based on the chosen transformation\\n    if target_transform_type == 'log1p':\\n        predictions_df = np.expm1(predictions_df)\\n    elif target_transform_type == 'sqrt':\\n        predictions_df = np.power(predictions_df, 2)\\n    elif target_transform_type == 'fourth_root':\\n        predictions_df = np.power(predictions_df, 4)\\n    # If no specific transformation, then predictions_df is already in admissions_per_million scale.\\n\\n    # Convert from admissions per million back to total admissions\\n    # Use .replace(0, np.nan) to avoid division by zero if population somehow becomes 0.\\n    predictions_df = predictions_df.multiply(test_x[POPULATION_COL].replace(0, np.nan), axis=0) / 1_000_000 \\n    \\n    # Ensure no NaNs are left (e.g., from division by zero population or other edge cases)\\n    predictions_df = predictions_df.fillna(0)\\n\\n    # Ensure all predictions are non-negative, as hospital admissions cannot be negative\\n    predictions_df[predictions_df < 0] = 0\\n\\n    # Ensure monotonicity of quantiles across each row (important for valid quantile forecasts)\\n    # Convert to numpy array for efficient sorting\\n    predictions_array = predictions_df.values\\n    predictions_array.sort(axis=1) # Sorts each row in-place\\n    # Convert back to DataFrame with original columns and index\\n    predictions_df = pd.DataFrame(predictions_array, columns=predictions_df.columns, index=predictions_df.index)\\n\\n    return predictions_df\\n\\nconfig_list = [\\n    { # Config 1: Enhanced version of previous best, focusing on robust long-term patterns\\n        'lgbm_params': {\\n            'n_estimators': 250,      \\n            'learning_rate': 0.02,   \\n            'num_leaves': 30,         \\n            'max_depth': 5,           \\n            'min_child_samples': 20,  \\n            'random_state': 42,       \\n            'n_jobs': -1,             \\n            'verbose': -1,            \\n            'colsample_bytree': 0.8,  \\n            'subsample': 0.8,         \\n            'reg_alpha': 0.1,         \\n            'reg_lambda': 0.1         \\n        },\\n        'target_transform': 'log1p',\\n        'lag_weeks': [1, 4, 8, 16, 26, 39, 52, 78, 104], \\n        'rolling_windows': [8, 16, 26, 52]      \\n    },\\n    { # Config 2: Balanced approach with slightly more recent focus, fewer very long lags\\n        'lgbm_params': {\\n            'n_estimators': 200,      \\n            'learning_rate': 0.03,    \\n            'num_leaves': 25,         \\n            'max_depth': 5,           \\n            'min_child_samples': 20,  \\n            'random_state': 42,       \\n            'n_jobs': -1,             \\n            'verbose': -1,            \\n            'colsample_bytree': 0.8,  \\n            'subsample': 0.8,         \\n            'reg_alpha': 0.1,         \\n            'reg_lambda': 0.1         \\n        },\\n        'target_transform': 'log1p',\\n        'lag_weeks': [1, 2, 4, 8, 12, 26, 52], \\n        'rolling_windows': [2, 4, 8, 16]         \\n    },\\n    { # Config 3: Exploring 'fourth_root' transformation with similar feature set\\n        'lgbm_params': {\\n            'n_estimators': 220,      \\n            'learning_rate': 0.03,    \\n            'num_leaves': 26,         \\n            'max_depth': 5,           \\n            'min_child_samples': 20,  \\n            'random_state': 42,       \\n            'n_jobs': -1,             \\n            'verbose': -1,            \\n            'colsample_bytree': 0.8,  \\n            'subsample': 0.8,         \\n            'reg_alpha': 0.1,         \\n            'reg_lambda': 0.1         \\n        },\\n        'target_transform': 'fourth_root', # New transformation\\n        'lag_weeks': [1, 4, 8, 16, 26, 52], \\n        'rolling_windows': [8, 16, 26]      \\n    },\\n    { # Config 4: Simpler feature set, faster training for baseline comparison\\n        'lgbm_params': {\\n            'n_estimators': 150,      \\n            'learning_rate': 0.05,    \\n            'num_leaves': 20,         \\n            'max_depth': 4,           \\n            'min_child_samples': 25,  \\n            'random_state': 42,       \\n            'n_jobs': -1,             \\n            'verbose': -1,            \\n            'colsample_bytree': 0.75,  \\n            'subsample': 0.75,         \\n            'reg_alpha': 0.15,         \\n            'reg_lambda': 0.15         \\n        },\\n        'target_transform': 'log1p',\\n        'lag_weeks': [1, 4, 8, 26], \\n        'rolling_windows': [4, 8]      \\n    }\\n]",
  "new_index": "350",
  "new_code": "import numpy as np\\nimport pandas as pd\\nfrom lightgbm import LGBMRegressor\\nfrom xgboost import XGBRegressor # Required for ensembling\\nfrom typing import Any\\n\\n# Define global constants for column names and quantiles\\nQUANTILES = [\\n    0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\\n    0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.975, 0.99\\n]\\nTARGET_COL = 'Total COVID-19 Admissions'\\nDATE_COL = 'target_end_date'\\nLOCATION_COL = 'location'\\nPOPULATION_COL = 'population'\\nHORIZON_COL = 'horizon'\\nTRANSFORMED_TARGET_COL = 'transformed_admissions_per_million'\\n\\ndef add_base_features(df_input: pd.DataFrame, min_date_global: pd.Timestamp) -> pd.DataFrame:\\n    \\"\\"\\"\\n    Adds common date-based features to the DataFrame, including cyclical features\\n    for seasonality and 'weeks_since_start' for overall trend.\\n    \\"\\"\\"\\n    df = df_input.copy()\\n    df[DATE_COL] = pd.to_datetime(df[DATE_COL])\\n    \\n    df['year'] = df[DATE_COL].dt.year\\n    df['month'] = df[DATE_COL].dt.month\\n    # Using isocalendar().week for ISO week number is robust across year boundaries.\\n    df['week_of_year'] = df[DATE_COL].dt.isocalendar().week.astype(int)\\n    \\n    # Cyclical features for week of year to capture seasonality smoothly\\n    df['sin_week_of_year'] = np.sin(2 * np.pi * df['week_of_year'] / 52)\\n    df['cos_week_of_year'] = np.cos(2 * np.pi * df['week_of_year'] / 52)\\n\\n    # Weeks since the global start of the entire dataset, to capture long-term trends.\\n    df['weeks_since_start'] = ((df[DATE_COL] - min_date_global).dt.days / 7).astype(int)\\n    \\n    return df\\n\\ndef fit_and_predict_fn(\\n    train_x: pd.DataFrame,\\n    train_y: pd.Series,\\n    test_x: pd.DataFrame,\\n    config: dict[str, Any]\\n) -> pd.DataFrame:\\n    \\"\\"\\"\\n    Makes probabilistic predictions for test_x by modeling train_x to train_y using\\n    an ensemble of LightGBM and XGBoost for quantile regression.\\n\\n    The model incorporates comprehensive time-series feature engineering, including\\n    lagged target variables, rolling means, and cyclical date features. The target\\n    variable is normalized by population and transformed (e.g., log1p) to handle\\n    skewness and large values effectively. The ensemble approach aims to combine\\n    the strengths of different gradient boosting models for more robust predictions.\\n\\n    Args:\\n        train_x (pd.DataFrame): Training features.\\n        train_y (pd.Series): Training target values (Total COVID-19 Admissions).\\n        test_x (pd.DataFrame): Test features for future time periods.\\n        config (dict[str, Any]): Configuration parameters for the model, including\\n                                  model-specific hyperparameters, feature engineering\\n                                  parameters, and models to include in the ensemble.\\n\\n    Returns:\\n        pd.DataFrame: DataFrame with quantile predictions for each row in test_x.\\n                      Columns are named 'quantile_0.XX' according to the required format.\\n    \\"\\"\\"\\n    \\n    # --- Configuration Parameters ---\\n    # Default parameters for LightGBM, can be overridden by 'lgbm_params' in config.\\n    default_lgbm_params = {\\n        'objective': 'quantile',\\n        'metric': 'quantile',\\n        'n_estimators': 200,      \\n        'learning_rate': 0.03,     \\n        'num_leaves': 25,         \\n        'max_depth': 5,           \\n        'min_child_samples': 20,  \\n        'random_state': 42,       \\n        'n_jobs': -1,             \\n        'verbose': -1,            \\n        'colsample_bytree': 0.8,  \\n        'subsample': 0.8,         \\n        'reg_alpha': 0.1,         \\n        'reg_lambda': 0.1         \\n    }\\n    lgbm_params = {**default_lgbm_params, **config.get('lgbm_params', {})}\\n\\n    # Default parameters for XGBoost, can be overridden by 'xgb_params' in config.\\n    # 'reg:quantileerror' objective is used for quantile regression.\\n    default_xgb_params = {\\n        'objective': 'reg:quantileerror', # XGBoost's quantile regression objective\\n        'n_estimators': 200,\\n        'learning_rate': 0.03,\\n        'max_depth': 5,\\n        'subsample': 0.8,\\n        'colsample_bytree': 0.8,\\n        'random_state': 42,\\n        'n_jobs': -1,\\n        'tree_method': 'hist', # 'hist' for faster training on large datasets\\n        'enable_categorical': True # Enables native handling of pandas 'category' dtypes\\n    }\\n    xgb_params = {**default_xgb_params, **config.get('xgb_params', {})}\\n\\n    # List of models to include in the ensemble (e.g., ['lgbm'], ['xgb'], ['lgbm', 'xgb']).\\n    models_to_use = config.get('models_to_use', ['lgbm', 'xgb'])\\n\\n    # Feature engineering parameters: number of past weeks for lags and rolling windows.\\n    LAG_WEEKS = config.get('lag_weeks', [1, 2, 3, 4, 8, 26, 52]) \\n    ROLLING_WINDOWS = config.get('rolling_windows', [2, 4, 8, 16]) \\n    \\n    # Type of transformation to apply to the target variable.\\n    target_transform_type = config.get('target_transform', 'log1p') \\n\\n    # --- Data Preparation and Feature Engineering ---\\n\\n    # 1. Combine train_x and train_y into a single DataFrame for easier processing\\n    df_train_full = train_x.copy()\\n    df_train_full[TARGET_COL] = train_y\\n    df_train_full[DATE_COL] = pd.to_datetime(df_train_full[DATE_COL])\\n    # Sort data by location and date, crucial for correct time-series feature generation\\n    df_train_full = df_train_full.sort_values(by=[LOCATION_COL, DATE_COL]).reset_index(drop=True)\\n\\n    # Normalize target by population and apply transformation\\n    admissions_per_million = df_train_full[TARGET_COL] / df_train_full[POPULATION_COL].replace(0, np.nan) * 1_000_000\\n    admissions_per_million = admissions_per_million.fillna(0) # Fill NaNs from zero population or missing\\n    admissions_per_million[admissions_per_million < 0] = 0 # Ensure non-negative before transformation\\n\\n    if target_transform_type == 'log1p':\\n        df_train_full[TRANSFORMED_TARGET_COL] = np.log1p(admissions_per_million)\\n    elif target_transform_type == 'sqrt':\\n        df_train_full[TRANSFORMED_TARGET_COL] = np.sqrt(admissions_per_million)\\n    elif target_transform_type == 'fourth_root':\\n        df_train_full[TRANSFORMED_TARGET_COL] = np.power(admissions_per_million, 0.25)\\n    else: # Fallback to raw per million if transformation type is invalid\\n        df_train_full[TRANSFORMED_TARGET_COL] = admissions_per_million\\n\\n    # Determine the global minimum date from the training set for consistent 'weeks_since_start'\\n    min_date_global = df_train_full[DATE_COL].min()\\n    \\n    # Add base date-related features to both training and test dataframes\\n    df_train_full = add_base_features(df_train_full, min_date_global)\\n    test_x_processed = add_base_features(test_x.copy(), min_date_global) \\n    \\n    # Define features that are not derived from the target variable\\n    BASE_FEATURES = [POPULATION_COL, 'year', 'month', 'week_of_year',\\n                     'sin_week_of_year', 'cos_week_of_year', 'weeks_since_start']\\n    CATEGORICAL_FEATURES_LIST = [LOCATION_COL] \\n\\n    # 2. Generate time-series dependent features for training data\\n    train_features_df = df_train_full.copy()\\n    \\n    # Generate lagged transformed target features for each location group\\n    for lag in LAG_WEEKS:\\n        train_features_df[f'lag_{lag}_wk'] = train_features_df.groupby(LOCATION_COL)[TRANSFORMED_TARGET_COL].shift(lag)\\n\\n    # Generate rolling mean features, shifted by 1 to avoid data leakage (using only past data)\\n    for window in ROLLING_WINDOWS:\\n        train_features_df[f'rolling_mean_{window}_wk'] = \\\\\\n            train_features_df.groupby(LOCATION_COL)[TRANSFORMED_TARGET_COL].transform(\\n                lambda x: x.rolling(window=window, min_periods=1, closed='left').mean()\\n            )\\n    \\n    y_train_model = train_features_df[TRANSFORMED_TARGET_COL]\\n    \\n    # Compile the list of all feature columns for training model\\n    train_specific_features = [f'lag_{lag}_wk' for lag in LAG_WEEKS] + \\\\\\n                              [f'rolling_mean_{window}_wk' for window in ROLLING_WINDOWS] \\n    \\n    X_train_model_cols = BASE_FEATURES + CATEGORICAL_FEATURES_LIST + train_specific_features\\n    X_train_model = train_features_df[X_train_model_cols].copy()\\n\\n    # Add the 'horizon' feature to the training data; for historical data, horizon is 0.\\n    # This ensures consistency with the \`test_x\` schema which includes \`horizon\`.\\n    if HORIZON_COL not in X_train_model.columns:\\n        X_train_model[HORIZON_COL] = 0 \\n\\n    # Handle missing values in time-series features (lags and rolling means) for training data\\n    # Forward fill within each group, then fill any remaining initial NaNs with 0.\\n    for col in train_specific_features:\\n        if X_train_model[col].isnull().any():\\n            X_train_model[col] = X_train_model.groupby(LOCATION_COL)[col].transform(lambda x: x.ffill())\\n            X_train_model[col] = X_train_model[col].fillna(0.0)\\n    \\n    # Drop any rows from training data that still have NaNs (e.g., if target itself was NaN)\\n    train_combined = X_train_model.copy()\\n    train_combined[TRANSFORMED_TARGET_COL] = y_train_model\\n    train_combined.dropna(inplace=True) \\n    \\n    X_train_model = train_combined.drop(columns=[TRANSFORMED_TARGET_COL])\\n    y_train_model = train_combined[TRANSFORMED_TARGET_COL]\\n\\n    # Convert categorical features to 'category' dtype for LightGBM and XGBoost (if enable_categorical=True)\\n    X_train_model[LOCATION_COL] = X_train_model[LOCATION_COL].astype('category')\\n    X_train_model[HORIZON_COL] = X_train_model[HORIZON_COL].astype('category')\\n\\n\\n    # 3. Generate features for test data\\n    # Start with base features and the inherent 'horizon' from test_x\\n    X_test_model = test_x_processed[BASE_FEATURES + CATEGORICAL_FEATURES_LIST + [HORIZON_COL]].copy()\\n    \\n    # Determine the latest date for which target data is available in the training set.\\n    # Test set features (lags/rolls) must only use data observed up to this date.\\n    max_train_date = df_train_full[DATE_COL].max() \\n    \\n    # Create an empty DataFrame to hold new lag/rolling features for the test set\\n    test_lag_rolling_features = pd.DataFrame(index=X_test_model.index)\\n    for col in train_specific_features:\\n        test_lag_rolling_features[col] = 0.0 # Initialize with default zero\\n\\n    # Calculate latest available lagged/rolling features for each location in test_x\\n    for loc_id in X_test_model[LOCATION_COL].unique():\\n        # Filter historical data for the current location, up to max_train_date\\n        loc_hist_data = df_train_full[\\n            (df_train_full[LOCATION_COL] == loc_id) & \\n            (df_train_full[DATE_COL] <= max_train_date)\\n        ].sort_values(DATE_COL)\\n        \\n        loc_test_indices = X_test_model.index[X_test_model[LOCATION_COL] == loc_id]\\n\\n        if not loc_hist_data.empty:\\n            # Populate lag features from the end of the historical transformed data\\n            for lag in LAG_WEEKS:\\n                lag_col_name = f'lag_{lag}_wk'\\n                if len(loc_hist_data) >= lag:\\n                    latest_lag_value = loc_hist_data[TRANSFORMED_TARGET_COL].iloc[-lag]\\n                else:\\n                    # If not enough history for a specific lag, use the most recent available value\\n                    latest_lag_value = loc_hist_data[TRANSFORMED_TARGET_COL].iloc[-1] if not loc_hist_data[TRANSFORMED_TARGET_COL].empty else 0.0\\n                test_lag_rolling_features.loc[loc_test_indices, lag_col_name] = latest_lag_value\\n            \\n            # Populate rolling features from the end of the historical transformed data\\n            for window in ROLLING_WINDOWS:\\n                rolling_col_name = f'rolling_mean_{window}_wk'\\n                rolling_data = loc_hist_data[TRANSFORMED_TARGET_COL].tail(window) \\n                if not rolling_data.empty:\\n                    rolling_mean_val = rolling_data.mean()\\n                    test_lag_rolling_features.loc[loc_test_indices, rolling_col_name] = rolling_mean_val if not pd.isna(rolling_mean_val) else 0.0\\n                else:\\n                    test_lag_rolling_features.loc[loc_test_indices, rolling_col_name] = 0.0\\n        else: # If there's no historical data for a location in train_x, default to 0\\n            for col in train_specific_features:\\n                test_lag_rolling_features.loc[loc_test_indices, col] = 0.0\\n    \\n    # Merge the computed lag/rolling features into X_test_model\\n    X_test_model = pd.concat([X_test_model, test_lag_rolling_features], axis=1)\\n\\n    # Impute any remaining NaNs in test features (e.g., for new locations not in train)\\n    for col in train_specific_features: \\n        if col in X_test_model.columns:\\n            X_test_model[col] = X_test_model[col].fillna(0.0)\\n\\n\\n    # 4. Align columns between train and test datasets\\n    # This step is critical to ensure feature consistency for the models\\n    final_feature_cols = X_train_model.columns.tolist() \\n\\n    X_test_model = X_test_model.reindex(columns=final_feature_cols, fill_value=0) \\n\\n    # Re-cast 'location' and 'horizon' in X_test_model to category type with consistent categories\\n    train_location_categories = X_train_model[LOCATION_COL].cat.categories\\n    X_test_model[LOCATION_COL] = X_test_model[LOCATION_COL].astype(pd.CategoricalDtype(categories=train_location_categories))\\n    \\n    train_horizon_categories = X_train_model[HORIZON_COL].cat.categories\\n    # Union categories from train and test to handle any new horizon values in test_x\\n    test_horizon_categories_union = train_horizon_categories.union(test_x_processed[HORIZON_COL].astype('category').cat.categories)\\n    X_test_model[HORIZON_COL] = X_test_model[HORIZON_COL].astype(pd.CategoricalDtype(categories=test_horizon_categories_union))\\n\\n    # Define categorical features for LightGBM. XGBoost with \`enable_categorical=True\` handles these natively.\\n    categorical_features_lgbm = [LOCATION_COL, HORIZON_COL]\\n    \\n    # --- Model Training and Ensemble Prediction ---\\n    ensemble_predictions = {}\\n    for q in QUANTILES:\\n        current_quantile_preds = []\\n\\n        # Train and predict with LightGBM if included in models_to_use\\n        if 'lgbm' in models_to_use:\\n            model_params_lgbm = lgbm_params.copy()\\n            model_params_lgbm['alpha'] = q # Set the quantile for this specific model\\n            lgbm_model = LGBMRegressor(**model_params_lgbm)\\n            lgbm_model.fit(X_train_model, y_train_model,\\n                           categorical_feature=categorical_features_lgbm)\\n            preds_lgbm = lgbm_model.predict(X_test_model)\\n            current_quantile_preds.append(preds_lgbm)\\n\\n        # Train and predict with XGBoost if included in models_to_use\\n        if 'xgb' in models_to_use:\\n            model_params_xgb = xgb_params.copy()\\n            model_params_xgb['quantile_alpha'] = q # Set the quantile for XGBoost\\n            xgb_model = XGBRegressor(**model_params_xgb)\\n            # XGBoost automatically uses \`enable_categorical=True\` if set in params\\n            xgb_model.fit(X_train_model, y_train_model) \\n            preds_xgb = xgb_model.predict(X_test_model)\\n            current_quantile_preds.append(preds_xgb)\\n        \\n        # Average predictions from all models included in the ensemble for the current quantile\\n        if current_quantile_preds:\\n            avg_preds_transformed = np.mean(current_quantile_preds, axis=0)\\n            ensemble_predictions[f'quantile_{q}'] = avg_preds_transformed\\n        else:\\n            # Fallback if no models were selected (should not happen in typical config)\\n            ensemble_predictions[f'quantile_{q}'] = np.zeros(len(X_test_model))\\n\\n\\n    # --- Post-processing ---\\n    # Convert predictions dictionary to a DataFrame, ensuring index matches test_x\\n    predictions_df = pd.DataFrame(ensemble_predictions, index=test_x.index)\\n\\n    # Inverse transform predictions back to the original scale of 'admissions_per_million'\\n    if target_transform_type == 'log1p':\\n        predictions_df = np.expm1(predictions_df)\\n    elif target_transform_type == 'sqrt':\\n        predictions_df = np.power(predictions_df, 2)\\n    elif target_transform_type == 'fourth_root':\\n        predictions_df = np.power(predictions_df, 4)\\n\\n    # Convert from admissions per million back to total admissions\\n    predictions_df = predictions_df.multiply(test_x[POPULATION_COL].replace(0, np.nan), axis=0) / 1_000_000 \\n    \\n    # Fill any remaining NaNs (e.g., from zero population divisions) with 0\\n    predictions_df = predictions_df.fillna(0)\\n\\n    # Ensure all predictions are non-negative, as hospital admissions cannot be negative\\n    predictions_df[predictions_df < 0] = 0\\n\\n    # Ensure monotonicity of quantiles across each row, which is crucial for Weighted Interval Score\\n    predictions_array = predictions_df.values\\n    predictions_array.sort(axis=1) # Sorts each row in-place\\n    # Convert back to DataFrame with original columns and index\\n    predictions_df = pd.DataFrame(predictions_array, columns=predictions_df.columns, index=predictions_df.index)\\n\\n    return predictions_df\\n\\n# --- Configuration List for Model Tuning ---\\n# This list defines different sets of hyperparameters and model choices to be evaluated\\n# by the Kaggle harness. The harness will select the best performing configuration.\\nconfig_list = [\\n    { # Config 1: Ensemble with default parameters for LGBM and XGBoost, log1p transform, extended lags/rolls\\n        'models_to_use': ['lgbm', 'xgb'],\\n        'lgbm_params': {\\n            'n_estimators': 250,      \\n            'learning_rate': 0.02,   \\n            'num_leaves': 30,         \\n            'max_depth': 5,           \\n            'min_child_samples': 20,  \\n            'random_state': 42,       \\n            'n_jobs': -1,             \\n            'verbose': -1,            \\n            'colsample_bytree': 0.8,  \\n            'subsample': 0.8,         \\n            'reg_alpha': 0.1,         \\n            'reg_lambda': 0.1         \\n        },\\n        'xgb_params': {\\n            'n_estimators': 250,\\n            'learning_rate': 0.02,\\n            'max_depth': 5,\\n            'subsample': 0.8,\\n            'colsample_bytree': 0.8,\\n            'random_state': 42,\\n            'n_jobs': -1,\\n            'tree_method': 'hist',\\n            'enable_categorical': True\\n        },\\n        'target_transform': 'log1p',\\n        'lag_weeks': [1, 4, 8, 16, 26, 39, 52, 78, 104], # Longer lags capture yearly/bi-yearly patterns\\n        'rolling_windows': [8, 16, 26, 52]      \\n    },\\n    { # Config 2: Ensemble with slightly different parameters, log1p, shorter lags/rolls\\n        'models_to_use': ['lgbm', 'xgb'],\\n        'lgbm_params': {\\n            'n_estimators': 200,      \\n            'learning_rate': 0.03,    \\n            'num_leaves': 25,         \\n            'max_depth': 5,           \\n            'min_child_samples': 20,  \\n            'random_state': 42,       \\n            'n_jobs': -1,             \\n            'verbose': -1,            \\n            'colsample_bytree': 0.8,  \\n            'subsample': 0.8,         \\n            'reg_alpha': 0.1,         \\n            'reg_lambda': 0.1         \\n        },\\n        'xgb_params': {\\n            'n_estimators': 200,\\n            'learning_rate': 0.03,\\n            'max_depth': 5,\\n            'subsample': 0.8,\\n            'colsample_bytree': 0.8,\\n            'random_state': 42,\\n            'n_jobs': -1,\\n            'tree_method': 'hist',\\n            'enable_categorical': True\\n        },\\n        'target_transform': 'log1p',\\n        'lag_weeks': [1, 2, 4, 8, 12, 26, 52], # More recent focus\\n        'rolling_windows': [2, 4, 8, 16]         \\n    },\\n    { # Config 3: Ensemble with 'fourth_root' transform, similar feature set to Config 1\\n        'models_to_use': ['lgbm', 'xgb'],\\n        'lgbm_params': {\\n            'n_estimators': 220,      \\n            'learning_rate': 0.03,    \\n            'num_leaves': 26,         \\n            'max_depth': 5,           \\n            'min_child_samples': 20,  \\n            'random_state': 42,       \\n            'n_jobs': -1,             \\n            'verbose': -1,            \\n            'colsample_bytree': 0.8,  \\n            'subsample': 0.8,         \\n            'reg_alpha': 0.1,         \\n            'reg_lambda': 0.1         \\n        },\\n        'xgb_params': {\\n            'n_estimators': 220,\\n            'learning_rate': 0.03,\\n            'max_depth': 5,\\n            'subsample': 0.8,\\n            'colsample_bytree': 0.8,\\n            'random_state': 42,\\n            'n_jobs': -1,\\n            'tree_method': 'hist',\\n            'enable_categorical': True\\n        },\\n        'target_transform': 'fourth_root', # Exploring a different target transformation\\n        'lag_weeks': [1, 4, 8, 16, 26, 52], \\n        'rolling_windows': [8, 16, 26]      \\n    },\\n    { # Config 4: Single LGBM model (replicate best from previous trial for direct comparison)\\n        'models_to_use': ['lgbm'], # Only LightGBM\\n        'lgbm_params': {\\n            'n_estimators': 250,      \\n            'learning_rate': 0.02,   \\n            'num_leaves': 30,         \\n            'max_depth': 5,           \\n            'min_child_samples': 20,  \\n            'random_state': 42,       \\n            'n_jobs': -1,             \\n            'verbose': -1,            \\n            'colsample_bytree': 0.8,  \\n            'subsample': 0.8,         \\n            'reg_alpha': 0.1,         \\n            'reg_lambda': 0.1         \\n        },\\n        'target_transform': 'log1p',\\n        'lag_weeks': [1, 4, 8, 16, 26, 39, 52, 78, 104], \\n        'rolling_windows': [8, 16, 26, 52]      \\n    }\\n]"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
