<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": "88",
  "old_code": "# YOUR CODE\\nimport numpy as np\\nimport pandas as pd\\nfrom typing import Any\\n\\ndef fit_and_predict_fn(\\n    train_x: pd.DataFrame,\\n    train_y: pd.Series,\\n    test_x: pd.DataFrame,\\n    config: dict[str, Any]\\n) -> pd.DataFrame:\\n    \\"\\"\\"Make probabilistic predictions using a persistence model with historical quantile residuals.\\n\\n    This function implements a \\"simpler model\\" strategy as requested, moving away from complex\\n    machine learning models for direct quantile regression. It uses a persistence forecast\\n    (last observed value) as the median prediction and derives other quantiles by adding\\n    pre-calculated historical residuals (differences between observed and lagged values)\\n    from the training data.\\n\\n    Args:\\n        train_x (pd.DataFrame): Training features.\\n        train_y (pd.Series): Training target values (Total COVID-19 Admissions).\\n        test_x (pd.DataFrame): Test features for future time periods.\\n        config (dict[str, Any]): Configuration parameters for the model.\\n                                  Supports 'default_spread_for_empty_residuals' (float),\\n                                  used when there's insufficient historical data to\\n                                  compute robust quantile residuals.\\n\\n    Returns:\\n        pd.DataFrame: DataFrame with quantile predictions for each row in test_x.\\n                      Columns are named 'quantile_0.XX'.\\n    \\"\\"\\"\\n    QUANTILES = [\\n        0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\\n        0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.975, 0.99\\n    ]\\n    TARGET_COL = 'Total COVID-19 Admissions'\\n    DATE_COL = 'target_end_date'\\n    LOCATION_COL = 'location'\\n\\n    # Configuration for default spread if historical residuals are not available\\n    default_spread_for_empty_residuals = config.get('default_spread_for_empty_residuals', 5.0)\\n\\n    # --- Data Preparation ---\\n    # Combine train_x and train_y into a single DataFrame for easier processing\\n    df_train_full = train_x.copy()\\n    df_train_full[TARGET_COL] = train_y\\n    df_train_full[DATE_COL] = pd.to_datetime(df_train_full[DATE_COL])\\n    # Sort data to ensure correct lag calculations per location\\n    df_train_full = df_train_full.sort_values(by=[LOCATION_COL, DATE_COL]).reset_index(drop=True)\\n\\n    # Convert date columns in test_x to datetime\\n    test_x_processed = test_x.copy()\\n    test_x_processed[DATE_COL] = pd.to_datetime(test_x_processed[DATE_COL])\\n    # Ensure 'reference_date' is datetime if present (it should be according to scaffolds)\\n    if 'reference_date' in test_x_processed.columns:\\n        test_x_processed['reference_date'] = pd.to_datetime(test_x_processed['reference_date'])\\n\\n    # --- Calculate historical residuals for quantile spreading ---\\n    # For each location, find the value from the previous week (lag_1_wk).\\n    # This serves as the 'prediction' for observed training data points.\\n    df_train_full['lag_1_wk'] = df_train_full.groupby(LOCATION_COL)[TARGET_COL].shift(1)\\n\\n    # Calculate residuals: observed value - lagged value.\\n    # Drop NaNs which occur at the beginning of each location's series.\\n    residuals = (df_train_full[TARGET_COL] - df_train_full['lag_1_wk']).dropna()\\n\\n    # Calculate quantiles of these residuals\\n    quantile_residuals = {}\\n    # Check if there are enough unique residual values to compute all quantiles meaningfully.\\n    # If not, use a default linear spread.\\n    if not residuals.empty and len(residuals.drop_duplicates()) >= len(QUANTILES):\\n        for q in QUANTILES:\\n            quantile_residuals[q] = residuals.quantile(q)\\n    else:\\n        # Fallback if historical residuals are insufficient.\\n        # Use a fixed spread, linearly interpolating between -default_spread and +default_spread\\n        # around the median (0). This provides a default range of uncertainty.\\n        for q in QUANTILES:\\n            if q <= 0.5:\\n                # Scale from -default_spread to 0 as q goes from 0 to 0.5\\n                quantile_residuals[q] = -default_spread_for_empty_residuals * (0.5 - q) * 2\\n            else:\\n                # Scale from 0 to +default_spread as q goes from 0.5 to 1\\n                quantile_residuals[q] = default_spread_for_empty_residuals * (q - 0.5) * 2\\n        # Ensure median residual is exactly 0\\n        quantile_residuals[0.5] = 0.0 \\n    \\n    # Ensure the calculated (or default) quantile_residuals are strictly monotonic.\\n    # This prevents issues where, due to discrete data or approximation, q_res[0.01] might be > q_res[0.025].\\n    # Collect (quantile, value) pairs, sort by quantile, then ensure values are non-decreasing.\\n    quantile_residuals_items = sorted(quantile_residuals.items())\\n    \\n    # Store just the values and sort them to guarantee monotonicity\\n    sorted_residual_values = [item[1] for item in quantile_residuals_items]\\n    sorted_residual_values.sort() \\n    \\n    # Re-assign the sorted values back to the quantiles\\n    quantile_residuals = {q: val for (q, _), val in zip(quantile_residuals_items, sorted_residual_values)}\\n\\n    # Fallback for base prediction (if a location has no history in train_x)\\n    global_median = df_train_full[TARGET_COL].median()\\n    # If training data is entirely empty or all NaN for the target column, default to 0.0\\n    if pd.isna(global_median) or df_train_full[TARGET_COL].isnull().all(): \\n        global_median = 0.0 \\n\\n\\n    # --- Generate Predictions for test_x ---\\n    predictions_df = pd.DataFrame(index=test_x.index)\\n\\n    # Get the last observed value and its date for each location from training data.\\n    # .groupby().tail(1) is robust and handles locations with no history or single points.\\n    last_observed_data_per_loc = df_train_full.groupby(LOCATION_COL).tail(1)\\n    \\n    # Convert to dictionaries for fast lookup during prediction loop\\n    last_observed_values_dict = last_observed_data_per_loc.set_index(LOCATION_COL)[TARGET_COL].to_dict()\\n    last_observed_dates_dict = last_observed_data_per_loc.set_index(LOCATION_COL)[DATE_COL].to_dict()\\n\\n    for q in QUANTILES:\\n        col_name = f'quantile_{q}'\\n        preds_q = []\\n        for idx, row in test_x_processed.iterrows():\\n            loc = row[LOCATION_COL]\\n            target_date = row[DATE_COL]\\n            # 'reference_date' and 'horizon' from test_x implicitly handled by target_date\\n\\n            base_prediction = global_median # Default base if no specific history for current location\\n            \\n            loc_last_val = last_observed_values_dict.get(loc)\\n            loc_last_date = last_observed_dates_dict.get(loc)\\n\\n            # Check if a last observed value exists and is not NaN for this location\\n            if loc_last_val is not None and not pd.isna(loc_last_val):\\n                # Critical handling for 'horizon=-1': the target_end_date for this horizon\\n                # is typically the last date available in the training data (\`reference_date - 7 days\`).\\n                # If the test row's target_end_date matches the last observed training date\\n                # for this location, we use that exact observed value as the base prediction.\\n                if loc_last_date == target_date:\\n                    base_prediction = loc_last_val\\n                else:\\n                    # For all other horizons (0, 1, 2, 3), where target_end_date is\\n                    # after the last observed training date, we use the last observed\\n                    # value as a simple persistence (carry-forward) forecast.\\n                    base_prediction = loc_last_val\\n            # If \`loc_last_val\` is None or NaN (meaning location not in train_x or no valid history),\\n            # \`base_prediction\` remains \`global_median\`.\\n\\n            # Calculate the final quantile prediction by adding the pre-computed residual quantile.\\n            predicted_value = base_prediction + quantile_residuals[q]\\n            preds_q.append(predicted_value)\\n        \\n        predictions_df[col_name] = preds_q\\n\\n    # --- Post-processing ---\\n    # Hospital admissions cannot be negative. Ensure all predictions are non-negative.\\n    predictions_df[predictions_df < 0] = 0\\n\\n    # Ensure strict monotonicity of quantiles across each row.\\n    # This is a crucial requirement for valid quantile forecasts and handles any\\n    # potential non-monotonicity introduced by previous steps (e.g., floor to 0).\\n    predictions_array = predictions_df.values\\n    \\n    # Sort each row in-place, ensuring that quantile_0.01 <= quantile_0.025 <= ... <= quantile_0.99\\n    predictions_array.sort(axis=1) \\n    \\n    predictions_df = pd.DataFrame(predictions_array, columns=predictions_df.columns, index=predictions_df.index)\\n\\n    return predictions_df\\n\\n# These will get scored by code that I supply. You'll get back a summary\\n# of the performance of each of them.\\nconfig_list = [\\n    { # Default configuration for the persistence model, with a moderate default spread\\n        'default_spread_for_empty_residuals': 5.0 \\n    },\\n    { # A configuration with a slightly larger default spread, to explore uncertainty range\\n        'default_spread_for_empty_residuals': 10.0\\n    },\\n    { # A configuration with an even larger default spread, for greater uncertainty capture\\n        'default_spread_for_empty_residuals': 20.0\\n    }\\n]",
  "new_index": "131",
  "new_code": "# YOUR CODE\\nimport numpy as np\\nimport pandas as pd\\nfrom typing import Any\\n\\ndef fit_and_predict_fn(\\n    train_x: pd.DataFrame,\\n    train_y: pd.Series,\\n    test_x: pd.DataFrame,\\n    config: dict[str, Any]\\n) -> pd.DataFrame:\\n    \\"\\"\\"Make probabilistic predictions using a persistence model with historical quantile residuals.\\n\\n    This function implements a \\"simpler model\\" strategy by using a persistence forecast\\n    (last observed value) as the median prediction and deriving other quantiles by adding\\n    pre-calculated historical residuals from the training data.\\n\\n    It specifically addresses missing data in time series by:\\n    1. Reindexing each location's training data to a complete weekly date range.\\n    2. Forward-filling (ffill) any \`Total COVID-19 Admissions\` values for dates that were\\n       missing in the original dataset but are within the observed range for that location.\\n    This ensures that the \`shift(1)\` operation, used for calculating historical residuals,\\n    correctly refers to the value from the immediately preceding week, even if that week\\n    was not explicitly present in the \`dataset.csv\`. The base persistence value for prediction\\n    still relies on the *last actual observed* value from the training data.\\n\\n    Args:\\n        train_x (pd.DataFrame): Training features.\\n        train_y (pd.Series): Training target values (Total COVID-19 Admissions).\\n        test_x (pd.DataFrame): Test features for future time periods.\\n        config (dict[str, Any]): Configuration parameters for the model.\\n                                  Supports 'default_spread_for_empty_residuals' (float),\\n                                  used when there's insufficient historical data to\\n                                  compute robust quantile residuals.\\n\\n    Returns:\\n        pd.DataFrame: DataFrame with quantile predictions for each row in test_x.\\n                      Columns are named 'quantile_0.XX'.\\n    \\"\\"\\"\\n    QUANTILES = [\\n        0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\\n        0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.975, 0.99\\n    ]\\n    TARGET_COL = 'Total COVID-19 Admissions'\\n    DATE_COL = 'target_end_date'\\n    LOCATION_COL = 'location'\\n\\n    # Configuration for default spread if historical residuals are not available\\n    default_spread_for_empty_residuals = config.get('default_spread_for_empty_residuals', 5.0)\\n\\n    # --- Data Preparation ---\\n    # Combine train_x and train_y into a single DataFrame for easier processing\\n    df_train_full = train_x.copy()\\n    df_train_full[TARGET_COL] = train_y\\n    df_train_full[DATE_COL] = pd.to_datetime(df_train_full[DATE_COL])\\n    df_train_full[LOCATION_COL] = df_train_full[LOCATION_COL].astype(str) # Ensure location is string for grouping consistency\\n    # Sort data for correct base persistence value extraction\\n    df_train_full = df_train_full.sort_values(by=[LOCATION_COL, DATE_COL]).reset_index(drop=True)\\n\\n    # Convert date columns in test_x to datetime\\n    test_x_processed = test_x.copy()\\n    test_x_processed[DATE_COL] = pd.to_datetime(test_x_processed[DATE_COL])\\n    # Ensure 'reference_date' is datetime if present (it should be according to scaffolds)\\n    if 'reference_date' in test_x_processed.columns:\\n        test_x_processed['reference_date'] = pd.to_datetime(test_x_processed['reference_date'])\\n\\n    # --- Calculate historical residuals for quantile spreading ---\\n    # Time-series specific handling for potential missing weeks:\\n    # 1. Determine the overall min/max date range from the training data.\\n    # 2. Create a complete weekly date range for each location within this span.\\n    # 3. Merge the actual training data onto this scaffold.\\n    # 4. Forward-fill any newly exposed \`NaN\` values in \`Total COVID-19 Admissions\`.\\n    # This makes the time series regular and enables proper lag calculation based on weeks.\\n\\n    all_locations = df_train_full[LOCATION_COL].unique()\\n    min_date_train = df_train_full[DATE_COL].min()\\n    max_date_train = df_train_full[DATE_COL].max()\\n    # Assuming weekly data ends on Saturday based on sample \`target_end_date\` values\\n    full_date_range = pd.date_range(start=min_date_train, end=max_date_train, freq='W-SAT')\\n\\n    # Create a scaffold for all locations and all dates within the training period\\n    full_scaffold_list = []\\n    for loc in all_locations:\\n        loc_df = pd.DataFrame({\\n            LOCATION_COL: loc,\\n            DATE_COL: full_date_range\\n        })\\n        full_scaffold_list.append(loc_df)\\n    full_scaffold = pd.concat(full_scaffold_list, ignore_index=True)\\n\\n    # Merge the actual training data onto the scaffold to identify implicit missing weeks\\n    df_train_aligned = pd.merge(full_scaffold, df_train_full,\\n                                on=[LOCATION_COL, DATE_COL], how='left')\\n\\n    # Sort and group before filling missing values to ensure ffill works correctly within each time series\\n    df_train_aligned = df_train_aligned.sort_values(by=[LOCATION_COL, DATE_COL])\\n    # Apply ffill to impute missing 'Total COVID-19 Admissions' values within each location's time series.\\n    # This will use the last valid observation to fill gaps.\\n    df_train_aligned[TARGET_COL] = df_train_aligned.groupby(LOCATION_COL)[TARGET_COL].ffill()\\n    # Note: If a location's very first entry in the aligned data is NaN (i.e., its first actual observation\\n    # occurred later than \`min_date_train\`), \`ffill\` will not fill it. These initial NaNs will be handled\\n    # by \`dropna()\` when calculating residuals.\\n\\n    # Calculate the 1-week lag on the aligned and filled data\\n    df_train_aligned['lag_1_wk'] = df_train_aligned.groupby(LOCATION_COL)[TARGET_COL].shift(1)\\n\\n    # Calculate residuals: observed value - lagged value.\\n    # Drop NaNs which occur at the beginning of each location's series (where no lag exists)\\n    # or where ffill couldn't impute (e.g., initial NaNs).\\n    residuals = (df_train_aligned[TARGET_COL] - df_train_aligned['lag_1_wk']).dropna()\\n\\n    # Calculate quantiles of these historical residuals\\n    quantile_residuals = {}\\n    # Check if there are enough unique residual values to compute all quantiles meaningfully.\\n    # If not, or if residuals are empty, use a default linear spread.\\n    if not residuals.empty and len(residuals.drop_duplicates()) >= len(QUANTILES):\\n        for q in QUANTILES:\\n            quantile_residuals[q] = residuals.quantile(q)\\n    else:\\n        # Fallback if historical residuals are insufficient.\\n        # Use a fixed spread, linearly interpolating around the median (0).\\n        for q in QUANTILES:\\n            if q <= 0.5:\\n                # Scale from -default_spread to 0 as q goes from 0 to 0.5\\n                quantile_residuals[q] = -default_spread_for_empty_residuals * (0.5 - q) * 2\\n            else:\\n                # Scale from 0 to +default_spread as q goes from 0.5 to 1\\n                quantile_residuals[q] = default_spread_for_empty_residuals * (q - 0.5) * 2\\n        # Ensure median residual is exactly 0\\n        quantile_residuals[0.5] = 0.0\\n\\n    # Ensure the calculated (or default) quantile_residuals are strictly monotonic.\\n    # This is important to ensure the final predictions maintain the correct quantile order.\\n    quantile_residuals_items = sorted(quantile_residuals.items())\\n    current_residual_values = [item[1] for item in quantile_residuals_items]\\n    current_residual_values.sort() # Sorts values in-place to guarantee non-decreasing order\\n\\n    # Re-assign the sorted values back to their corresponding quantile keys\\n    quantile_residuals = {q_item[0]: sorted_val for q_item, sorted_val in zip(quantile_residuals_items, current_residual_values)}\\n\\n\\n    # Fallback for base prediction: if a location has no history in train_x at all,\\n    # or if all its values are NaN, use the global median from \`train_y\`.\\n    global_median = df_train_full[TARGET_COL].median()\\n    if pd.isna(global_median) or df_train_full[TARGET_COL].isnull().all():\\n        global_median = 0.0\\n\\n\\n    # --- Generate Predictions for test_x ---\\n    predictions_df = pd.DataFrame(index=test_x.index)\\n\\n    # Get the last observed value and its date for each location from ORIGINAL training data.\\n    # The base persistence forecast should come from actual observed data, not the ffilled/imputed data.\\n    last_observed_data_per_loc = df_train_full.groupby(LOCATION_COL).tail(1)\\n\\n    # Convert to dictionaries for fast lookup during prediction loop\\n    last_observed_values_dict = last_observed_data_per_loc.set_index(LOCATION_COL)[TARGET_COL].to_dict()\\n    last_observed_dates_dict = last_observed_data_per_loc.set_index(LOCATION_COL)[DATE_COL].to_dict()\\n\\n    for q in QUANTILES:\\n        col_name = f'quantile_{q}'\\n        preds_q = []\\n        for idx, row in test_x_processed.iterrows():\\n            loc = row[LOCATION_COL]\\n            target_date = row[DATE_COL]\\n\\n            base_prediction = global_median # Default base if no specific history for current location\\n\\n            loc_last_val = last_observed_values_dict.get(loc)\\n            loc_last_date = last_observed_dates_dict.get(loc)\\n\\n            # Check if a last observed value exists and is not NaN for this location\\n            if loc_last_val is not None and not pd.isna(loc_last_val):\\n                # For horizon=-1, target_end_date might be the last observed date in training data.\\n                # In this specific case, use the exact last observed value as the base.\\n                if loc_last_date == target_date:\\n                    base_prediction = loc_last_val\\n                else:\\n                    # For all other horizons (0, 1, 2, 3), use the last observed value as a persistence forecast.\\n                    base_prediction = loc_last_val\\n            # If \`loc_last_val\` is None or NaN (meaning location not in train_x or no valid history),\\n            # \`base_prediction\` remains \`global_median\`.\\n\\n            # Calculate the final quantile prediction by adding the pre-computed residual quantile.\\n            predicted_value = base_prediction + quantile_residuals[q]\\n            preds_q.append(predicted_value)\\n\\n        predictions_df[col_name] = preds_q\\n\\n    # --- Post-processing ---\\n    # Hospital admissions cannot be negative. Ensure all predictions are non-negative.\\n    predictions_df[predictions_df < 0] = 0\\n\\n    # Ensure strict monotonicity of quantiles across each row.\\n    # This is a crucial requirement for valid quantile forecasts and handles any\\n    # potential non-monotonicity introduced by previous steps (e.g., flooring to 0).\\n    predictions_array = predictions_df.values\\n\\n    # Sort each row in-place, ensuring that quantile_0.01 <= quantile_0.025 <= ... <= quantile_0.99\\n    predictions_array.sort(axis=1)\\n\\n    predictions_df = pd.DataFrame(predictions_array, columns=predictions_df.columns, index=predictions_df.index)\\n\\n    return predictions_df\\n\\n# These will get scored by code that I supply. You'll get back a summary\\n# of the performance of each of them.\\nconfig_list = [\\n    { # Default configuration for the persistence model, with a moderate default spread\\n        'default_spread_for_empty_residuals': 5.0\\n    },\\n    { # A configuration with a slightly larger default spread, to explore uncertainty range\\n        'default_spread_for_empty_residuals': 10.0\\n    },\\n    { # A configuration with an even larger default spread, for greater uncertainty capture\\n        'default_spread_for_empty_residuals': 20.0\\n    }\\n]"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
