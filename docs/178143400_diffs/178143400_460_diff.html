<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": 443.0,
  "old_code": "# TODO: Implement the \`quadrature()\` function to numerically evaluate integrals.\\n\\nimport math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # Define strict error tolerances for internal quad calls\\n    # These are at or near machine epsilon for float64, pushing quad to its limits.\\n    STRICT_EPSABS = 1e-15 \\n    STRICT_EPSREL = 1e-15 \\n    HIGH_LIMIT = 500000 # Increased iteration limit for quad\\n\\n    # Define thresholds for deeming quad's result \\"unreliable\\" for initial pass\\n    # These are slightly relaxed to give quad more chance to pass, as its error estimates are often conservative.\\n    ABS_ERROR_THRESHOLD_SMALL_ANSWER = 5e-13 # Absolute error for small answers (<1e-10)\\n    REL_ERROR_THRESHOLD_LARGE_ANSWER = 5e-7  # Relative error for large answers (>=1e-10)\\n\\n    # --- Step 1: Initial Aggressive Attempt with scipy.integrate.quad() ---\\n    # This is the primary attempt with relatively strict tolerances.\\n    # If it provides a numerically stable answer with acceptable error, we use it.\\n    try:\\n        answer, error_estimate = scipy.integrate.quad(\\n            integrand, lower_limit, upper_limit,\\n            limit=HIGH_LIMIT,\\n            epsabs=STRICT_EPSABS,\\n            epsrel=STRICT_EPSREL\\n        )\\n\\n        is_nan_inf = np.isnan(answer) or np.isinf(answer) or \\\\\\n                     np.isnan(error_estimate) or np.isinf(error_estimate)\\n        \\n        is_error_too_high = False\\n        if not is_nan_inf: # Only check error if results are finite and not NaN\\n            if abs(answer) >= 1e-10: # For larger answers, check relative error\\n                if error_estimate / abs(answer) > REL_ERROR_THRESHOLD_LARGE_ANSWER:\\n                    is_error_too_high = True\\n            else: # For small answers, check absolute error\\n                if error_estimate > ABS_ERROR_THRESHOLD_SMALL_ANSWER:\\n                    is_error_too_high = True\\n\\n        if is_nan_inf or is_error_too_high:\\n            # If deemed unreliable, fall through to more robust methods.\\n            pass # Do not return, proceed to next strategies.\\n        else:\\n            return answer, error_estimate\\n    except Exception:\\n        # If quad raises an error (e.g., \`points\` error, \`divergence\`), fall through.\\n        pass\\n\\n    # --- Step 2: Handle Infinite Limits via Transformations ---\\n    # Convert all integrals to the form [a, inf) for uniform processing by specialized methods.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        # Recursively call quadrature for the split parts.\\n        # Note: If 0 is a problematic point for integrand, another split point might be better,\\n        # but 0 is standard for general cases.\\n        val1, err1 = quadrature(integrand, -np.inf, 0)\\n        val2, err2 = quadrature(integrand, 0, np.inf)\\n        \\n        # If either sub-integral failed (NaN result, or infinite error indicating deep problems),\\n        # propagate failure.\\n        if np.isnan(val1) or np.isnan(val2) or np.isinf(err1) or np.isinf(err2):\\n            return np.nan, np.inf\\n        \\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-upper_limit}^{inf} f(-t) dt.\\n        # This converts (-inf, b] to [-b, inf).\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t)\\n        # Recursively call \`quadrature\` with the new lower limit and positive infinity.\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] (finite interval) where initial quad failed.\\n        # This implies a very difficult finite integral. Re-attempt with maximal aggression.\\n        # \`quad\` is generally very good at finite intervals. If it failed, it's truly hard.\\n        try:\\n            answer, error_estimate = scipy.integrate.quad(\\n                integrand, lower_limit, upper_limit,\\n                limit=HIGH_LIMIT * 2, epsabs=1e-17, epsrel=1e-17 # Extremely aggressive\\n            )\\n            # Apply very strict error checks for finite integrals here.\\n            # If it's still unreliable even after extreme aggression, it's likely a failure.\\n            is_nan_inf = np.isnan(answer) or np.isinf(answer) or \\\\\\n                         np.isnan(error_estimate) or np.isinf(error_estimate)\\n            \\n            is_error_too_high = False\\n            if not is_nan_inf:\\n                if abs(answer) >= 1e-10:\\n                    if error_estimate / abs(answer) > 1e-8: # Even tighter relative error\\n                        is_error_too_high = True\\n                else: # For small answers, use absolute error threshold\\n                    if error_estimate > 1e-16: # Even tighter absolute error\\n                        is_error_too_high = True\\n\\n            if is_nan_inf or is_error_too_high: \\n                raise ValueError(\\"Aggressive quad also failed for finite interval.\\") # Force failure to NaN, Inf\\n            return answer, error_estimate\\n        except Exception:\\n            # If aggressive quad fails or raises an error, indicate failure.\\n            return np.nan, np.inf \\n\\n    # --- Step 3: Specialized Methods for [a, inf) ---\\n    # At this point, we are dealing with integrals of the form [lower_limit, inf),\\n    # where lower_limit is finite, and initial quad (for this form) failed.\\n\\n    # Strategy 3a: Transformation x = lower_limit + t / (1-t)\\n    # This maps [lower_limit, inf) to [0, 1).\\n    # Integral of f(x) dx from a to inf becomes integral of f(a + t/(1-t)) * (1/(1-t)^2) dt from 0 to 1.\\n    try:\\n        def transformed_integrand_zero_to_one(t):\\n            # Use machine epsilon to handle t very close to 1\\n            if t >= 1.0 - np.finfo(float).eps:\\n                return 0.0 \\n\\n            denominator = 1.0 - t\\n            # Check for t very close to 1, where 1-t approaches 0.\\n            if denominator < 1e-10: # Static cutoff for numerical stability near t=1\\n                return 0.0 \\n\\n            x_val = lower_limit + t / denominator\\n            dx_dt = 1.0 / (denominator * denominator)\\n            \\n            # If integrand evaluates to NaN/Inf for large x_val, clamp to 0 for numerical stability\\n            # for converging integrals, as f(infinity) should effectively be 0.\\n            try:\\n                f_x = integrand(x_val)\\n                if np.isnan(f_x) or np.isinf(f_x):\\n                    return 0.0 \\n                return f_x * dx_dt\\n            except Exception:\\n                return 0.0 \\n\\n        # Add points to help quad handle the singularity at t=1.0.\\n        # These points are concentrated near t=1 to help quad adapt to the behavior there.\\n        singularity_points = np.linspace(0.9, 0.99999, 15).tolist() # More points approaching 1.0\\n        singularity_points.append(1.0) # Explicitly include the upper limit\\n        singularity_points = sorted(list(set(singularity_points))) # Remove duplicates and sort\\n\\n        answer, error_estimate = scipy.integrate.quad(\\n            transformed_integrand_zero_to_one, 0, 1,\\n            points=singularity_points, # Pass the singularity points\\n            limit=HIGH_LIMIT * 3, epsabs=1e-17, epsrel=1e-17 # Extremely aggressive parameters\\n        )\\n        \\n        # Apply very strict error checks for this transformed finite integral.\\n        # If it's still unreliable, we fall back.\\n        is_nan_inf = np.isnan(answer) or np.isinf(answer) or \\\\\\n                     np.isnan(error_estimate) or np.isinf(error_estimate)\\n        \\n        is_error_too_high = False\\n        if not is_nan_inf:\\n            if abs(answer) >= 1e-10:\\n                if error_estimate / abs(answer) > 1e-8: # Even tighter relative error threshold\\n                    is_error_too_high = True\\n            else: # For small answers, use absolute error threshold\\n                if error_estimate > 1e-16: # Even tighter absolute error threshold\\n                    is_error_too_high = True\\n\\n        if is_nan_inf or is_error_too_high:\\n            raise ValueError(\\"t/(1-t) transformation quad attempt failed or unreliable.\\")\\n        \\n        return answer, error_estimate\\n    except Exception:\\n        # Fallback to Strategy 3b if transformation fails (e.g., due to severe singularity at t=1, or numerical instability)\\n        pass\\n\\n    # Strategy 3b: Segment Summation with Euler Acceleration (for highly oscillatory integrals)\\n    # This method is most effective for alternating series with decaying terms.\\n    # It assumes the integrand is oscillatory and integrable from \`lower_limit\` to infinity.\\n    # The \`segment_length = math.pi\` is a strong heuristic; ideally, this would be adaptive\\n    # or determined by analyzing the integrand's dominant frequency.\\n\\n    current_segment_start = float(lower_limit)\\n    segment_length = math.pi  # Heuristic for common oscillatory functions like sin(x) or cos(x)\\n                              # This is a key limitation if true periodicity is different.\\n    \\n    segment_integrals = []\\n    \\n    max_segments_to_compute = 500000 # Increased maximum segments to collect for slow convergence\\n    min_segments_for_euler = 500     # Increased minimum terms for Euler transformation stability\\n\\n    prev_seg_val = None\\n    consistent_sign_count = 0     # To detect non-alternating series (Euler works best for alternating)\\n    consecutive_decay_count = 0   # To detect rapid decay and allow early stopping\\n    \\n    # Initialize error tracker for segments (for Euler error estimation later)\\n    segment_errors_sum_sq = 0.0 # Sum of squared errors for total error propagation\\n\\n    for i in range(max_segments_to_compute):\\n        seg_start = current_segment_start\\n        seg_end = current_segment_start + segment_length\\n\\n        # Ensure segment length is positive and non-trivial\\n        if seg_end <= seg_start + 1e-12: \\n            if len(segment_integrals) == 0:\\n                return np.nan, np.inf # Could not even compute first segment reliably.\\n            else:\\n                break # Stop if segment length becomes too small (numerical issue or end of domain for very large 'a')\\n\\n        try:\\n            # Integrate each segment using scipy.integrate.quad with strict parameters.\\n            seg_val, seg_err = scipy.integrate.quad(\\n                integrand, seg_start, seg_end,\\n                limit=HIGH_LIMIT, epsabs=STRICT_EPSABS, epsrel=STRICT_EPSREL \\n            )\\n            \\n            # If segment integral fails or error is too high relative to segment value,\\n            # consider this segment unreliable. This will break the loop and proceed to Euler.\\n            if np.isnan(seg_val) or np.isinf(seg_val):\\n                # If the current segment itself produces NaN/Inf, break and sum what's collected so far\\n                raise ValueError(f\\"Segment integral produced NaN/Inf at {i}-th segment: val={seg_val}\\")\\n            \\n            # Strict error checks for individual segments. If they are not met, the terms might be too noisy for Euler.\\n            if abs(seg_val) >= 1e-10 and seg_err / abs(seg_val) > 1e-6: # Relative error for larger segment values\\n                raise ValueError(f\\"Segment integral relative error too high at {i}-th segment: val={seg_val}, err={seg_err}\\")\\n            elif abs(seg_val) < 1e-10 and seg_err > 1e-15: # Absolute error for small segment values\\n                raise ValueError(f\\"Segment integral absolute error too high at {i}-th segment: val={seg_val}, err={seg_err}\\")\\n\\n            segment_integrals.append(seg_val)\\n            segment_errors_sum_sq += seg_err**2 # Accumulate squared errors for total error propagation\\n            current_segment_start = seg_end\\n\\n            # --- Checks for suitability of Euler transformation and early stopping ---\\n            if i > 0:\\n                # Check for non-alternating signs (Euler works best for alternating series)\\n                # If terms consistently do not alternate AND are not negligible, Euler is likely not suitable.\\n                # In this case, sum collected terms with high error to indicate this method is not fitting.\\n                if seg_val * prev_seg_val >= 0 and abs(seg_val) > 1e-15: # Same sign AND not effectively zero\\n                    consistent_sign_count += 1\\n                else:\\n                    consistent_sign_count = 0 \\n                \\n                if consistent_sign_count >= 50 and i >= min_segments_for_euler: \\n                    # Many non-alternating terms: assume simple sum is best, but error is high.\\n                    return np.sum(segment_integrals), np.inf \\n\\n                # Check for very rapid decay. If terms become negligible, implies direct sum convergence.\\n                # Thresholds are tuned to float64 precision.\\n                # This avoids summing too many tiny terms.\\n                if abs(prev_seg_val) > 1e-25 and abs(seg_val) < (1e-12 * abs(prev_seg_val) + 1e-25): # Relaxed threshold for decay\\n                    consecutive_decay_count += 1\\n                    if consecutive_decay_count >= 30: # Sufficient consecutive decay detected\\n                        # If the total sum accumulated so far is also stable and small, implies overall convergence.\\n                        # This avoids summing too many tiny terms.\\n                        if abs(np.sum(segment_integrals[:-30])) < 1e-10: \\n                            break # Break loop, sum will be performed.\\n                else:\\n                    consecutive_decay_count = 0\\n                \\n                # Check for strong divergence in terms.\\n                # If terms start growing wildly, this method is likely unsuitable.\\n                if i >= min_segments_for_euler and abs(seg_val) > abs(segment_integrals[-2]) * 10000 and abs(segment_integrals[-2]) > 1e-15: \\n                    # If Euler has started producing diagonal values, use the last stable one.\\n                    # Otherwise, use the direct sum up to that point.\\n                    final_answer_before_divergence = euler_diagonal_values[-2] if 'euler_diagonal_values' in locals() and len(euler_diagonal_values) >= 2 else np.sum(segment_integrals)\\n                    return final_answer_before_divergence, np.inf # Indicate divergence by infinite error\\n\\n            prev_seg_val = seg_val\\n\\n        except Exception:\\n            # If any segment integration fails or is unreliable, sum successful segments\\n            # with high error to indicate uncertainty and stop trying more segments.\\n            # The error for this fallback is the square root of the sum of squared errors from successful segments.\\n            return np.sum(segment_integrals), np.sqrt(segment_errors_sum_sq) + np.inf # Add Inf to signal high uncertainty\\n\\n    # Apply Euler's Transformation\\n    N_segments = len(segment_integrals)\\n    if N_segments < min_segments_for_euler:\\n        # Not enough terms collected for reliable Euler transformation.\\n        # Fallback to simple sum with high error.\\n        return np.sum(segment_integrals), np.sqrt(segment_errors_sum_sq) + np.inf \\n\\n    # Prepare for Euler: The sums are the actual terms a_n to be transformed.\\n    euler_sums = np.array(segment_integrals, dtype=float) \\n    euler_diagonal_values = [euler_sums[0]] # Stores e_{0,0}\\n\\n    # Parameters for Euler convergence.\\n    consecutive_converged_count = 0\\n    target_consecutive_converged = 10 # More consecutive converged steps needed for strong confidence.\\n\\n    euler_diff_history = [] # To track differences for robust error estimation\\n\\n    try:\\n        max_euler_levels = N_segments - 1\\n\\n        for m in range(max_euler_levels): \\n            if len(euler_sums) < 2: \\n                break \\n\\n            # This computes the next diagonal values: e_{m+1,n} = (e_{m,n} + e_{m,n+1})/2\\n            new_euler_sums = (euler_sums[:-1] + euler_sums[1:]) / 2.0\\n            euler_sums = new_euler_sums\\n            \\n            euler_diagonal_values.append(euler_sums[0]) # Stores e_{m,0} (the diagonal values)\\n            \\n            if m > 0: # Start checking convergence after at least one step of Euler\\n                diff = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n                \\n                # Converged if difference is very small relatively OR absolutely (for very small answers).\\n                # These thresholds reflect machine precision for float64.\\n                if (abs(euler_diagonal_values[-1]) >= 1e-10 and diff < 1e-14 * abs(euler_diagonal_values[-1])) or \\\\\\n                   (abs(euler_diagonal_values[-1]) < 1e-10 and diff < 1e-20): \\n                    consecutive_converged_count += 1\\n                else:\\n                    consecutive_converged_count = 0 \\n                \\n                # If enough consecutive converged steps are observed, we can stop.\\n                if consecutive_converged_count >= target_consecutive_converged:\\n                    break\\n\\n                # Check for strong divergence in Euler diagonal values.\\n                if m > 2 and abs(euler_diagonal_values[-1]) > abs(euler_diagonal_values[-2]) * 1000 and abs(euler_diagonal_values[-2]) > 1e-15: \\n                    # Use the last \\"most stable\\" value before divergence, and indicate high error.\\n                    final_answer = euler_diagonal_values[-2] if len(euler_diagonal_values) >= 2 else np.sum(segment_integrals)\\n                    return final_answer, np.inf \\n\\n            # Keep track of differences for robust error estimation\\n            if m > 0:\\n                euler_diff_history.append(abs(euler_diagonal_values[-1] - euler_diagonal_values[-2]))\\n\\n    except Exception:\\n        # If Euler transformation process itself encounters an error (e.g., due to NaNs introduced),\\n        # return with high uncertainty.\\n        return np.nan, np.inf\\n\\n    # Final result from Euler acceleration.\\n    final_answer = euler_diagonal_values[-1] if len(euler_diagonal_values) > 0 else np.sum(segment_integrals)\\n    \\n    # Estimate error based on the last few Euler diagonal values and total segment errors.\\n    if len(euler_diff_history) > 0:\\n        # Use the maximum of the last few differences as an indicator of remaining error from acceleration.\\n        euler_accel_error = np.max(euler_diff_history[-min(len(euler_diff_history), 5):]) # Max of last 5 diffs\\n        # Total error is estimated by adding the propagated errors from segments (in quadrature)\\n        # to the error from acceleration (Euler). Using sqrt(sum_sq) for independent errors.\\n        error_estimate = np.sqrt(segment_errors_sum_sq) + euler_accel_error\\n        \\n        # Add a floor to ensure the error estimate is at least machine precision relevant to the answer.\\n        error_estimate = max(error_estimate, 1e-14 * abs(final_answer), 1e-25) \\n    elif len(segment_integrals) > 0:\\n        # If Euler didn't run effectively (e.g., N_segments < min_segments_for_euler), \\n        # error is much higher than a simple Euler estimate. Use accumulated segment errors.\\n        error_estimate = np.sqrt(segment_errors_sum_sq) + abs(segment_integrals[-1]) * 100 + 1e-10 # Sum of quad errors + conservative estimate\\n    else:\\n        # No segments computed, this indicates a complete failure.\\n        error_estimate = np.inf\\n\\n    # Final check for NaN/Inf results from the Euler method.\\n    if np.isnan(final_answer) or np.isinf(final_answer):\\n        return np.nan, np.inf\\n\\n    return final_answer, error_estimate",
  "new_index": 460,
  "new_code": "import math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # Define strict error tolerances for internal quad calls\\n    # These are at or near machine epsilon for float64, pushing quad to its limits.\\n    STRICT_EPSABS = 1e-15 \\n    STRICT_EPSREL = 1e-15 \\n    HIGH_LIMIT = 500000 # Increased iteration limit for quad\\n\\n    # Define thresholds for deeming quad's result \\"unreliable\\" for initial pass\\n    # These are slightly relaxed to give quad more chance to pass, as its error estimates are often conservative.\\n    ABS_ERROR_THRESHOLD_SMALL_ANSWER = 5e-13 # Absolute error for small answers (<1e-10)\\n    REL_ERROR_THRESHOLD_LARGE_ANSWER = 5e-7  # Relative error for large answers (>=1e-10)\\n\\n    # --- Step 1: Initial Aggressive Attempt with scipy.integrate.quad() ---\\n    # This is the primary attempt with relatively strict tolerances.\\n    # If it provides a numerically stable answer with acceptable error, we use it.\\n    try:\\n        answer, error_estimate = scipy.integrate.quad(\\n            integrand, lower_limit, upper_limit,\\n            limit=HIGH_LIMIT,\\n            epsabs=STRICT_EPSABS,\\n            epsrel=STRICT_EPSREL\\n        )\\n\\n        is_nan_inf = np.isnan(answer) or np.isinf(answer) or \\\\\\n                     np.isnan(error_estimate) or np.isinf(error_estimate)\\n        \\n        is_error_too_high = False\\n        if not is_nan_inf: # Only check error if results are finite and not NaN\\n            if abs(answer) >= 1e-10: # For larger answers, check relative error\\n                if error_estimate / abs(answer) > REL_ERROR_THRESHOLD_LARGE_ANSWER:\\n                    is_error_too_high = True\\n            else: # For small answers, check absolute error\\n                if error_estimate > ABS_ERROR_THRESHOLD_SMALL_ANSWER:\\n                    is_error_too_high = True\\n\\n        if is_nan_inf or is_error_too_high:\\n            # If deemed unreliable, fall through to more robust methods.\\n            pass # Do not return, proceed to next strategies.\\n        else:\\n            return answer, error_estimate\\n    except Exception:\\n        # If quad raises an error (e.g., \`points\` error, \`divergence\`), fall through.\\n        pass\\n\\n    # --- Step 2: Handle Infinite Limits via Transformations ---\\n    # Convert all integrals to the form [a, inf) for uniform processing by specialized methods.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        # Recursively call quadrature for the split parts.\\n        # Note: If 0 is a problematic point for integrand, another split point might be better,\\n        # but 0 is standard for general cases.\\n        val1, err1 = quadrature(integrand, -np.inf, 0)\\n        val2, err2 = quadrature(integrand, 0, np.inf)\\n        \\n        # If either sub-integral failed (NaN result, or infinite error indicating deep problems),\\n        # propagate failure.\\n        if np.isnan(val1) or np.isnan(val2) or np.isinf(err1) or np.isinf(err2):\\n            return np.nan, np.inf\\n        \\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-upper_limit}^{inf} f(-t) dt.\\n        # This converts (-inf, b] to [-b, inf).\\n        def transformed_integrand_neg_inf(t):\\n            try: # Wrap integrand evaluation in try-except for robustness\\n                return integrand(-t)\\n            except Exception:\\n                return 0.0 # Return 0 if evaluation fails for extreme values\\n\\n        # Recursively call \`quadrature\` with the new lower limit and positive infinity.\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] (finite interval) where initial quad failed.\\n        # This implies a very difficult finite integral. Re-attempt with maximal aggression.\\n        # \`quad\` is generally very good at finite intervals. If it failed, it's truly hard.\\n        try:\\n            answer, error_estimate = scipy.integrate.quad(\\n                integrand, lower_limit, upper_limit,\\n                limit=HIGH_LIMIT * 2, epsabs=1e-17, epsrel=1e-17 # Extremely aggressive\\n            )\\n            # Apply very strict error checks for finite integrals here.\\n            # If it's still unreliable even after extreme aggression, it's likely a failure.\\n            is_nan_inf = np.isnan(answer) or np.isinf(answer) or \\\\\\n                         np.isnan(error_estimate) or np.isinf(error_estimate)\\n            \\n            is_error_too_high = False\\n            if not is_nan_inf:\\n                if abs(answer) >= 1e-10:\\n                    if error_estimate / abs(answer) > 1e-8: # Even tighter relative error\\n                        is_error_too_high = True\\n                else: # For small answers, use absolute error threshold\\n                    if error_estimate > 1e-16: # Even tighter absolute error\\n                        is_error_too_high = True\\n\\n            if is_nan_inf or is_error_too_high: \\n                return np.nan, np.inf # Force failure to NaN, Inf\\n            return answer, error_estimate\\n        except Exception:\\n            # If aggressive quad fails or raises an error, indicate failure.\\n            return np.nan, np.inf \\n\\n    # --- Step 3: Specialized Methods for [a, inf) ---\\n    # At this point, we are dealing with integrals of the form [lower_limit, inf),\\n    # where lower_limit is finite, and initial quad (for this form) failed.\\n\\n    # Strategy 3a: Attempt with Zero-Crossing-Aware quad for oscillatory functions.\\n    # This can significantly help quad if the function has regular zero crossings.\\n    try:\\n        # Helper function to find zeros using brentq\\n        def find_zeros_in_interval(func, a, b, num_points_for_search=2000):\\n            zeros = []\\n            x_vals = np.linspace(a, b, num_points_for_search)\\n            for i in range(len(x_vals) - 1):\\n                try:\\n                    val_i = func(x_vals[i])\\n                    val_i_plus_1 = func(x_vals[i+1])\\n\\n                    # Check for sign change\\n                    if val_i * val_i_plus_1 < 0:\\n                        zero = scipy.optimize.brentq(func, x_vals[i], x_vals[i+1])\\n                        zeros.append(zero)\\n                    elif abs(val_i) < 1e-10: # If it's already very close to zero\\n                        zeros.append(x_vals[i])\\n                except Exception:\\n                    continue # Skip if function evaluation fails in interval\\n            return zeros\\n\\n        # Try to find a reasonable number of zero crossings in an initial range.\\n        # This range is chosen to cover a few \\"cycles\\" if period is ~pi.\\n        # The number of points and search range can be tuned for various oscillatory types.\\n        search_range_length = 20 * math.pi # Search up to 20 pi-cycles\\n        search_range_end = lower_limit + search_range_length\\n        if search_range_end <= lower_limit: # Handle cases where lower_limit is very large, making addition trivial\\n            search_range_end = lower_limit + 1000 # Fallback to a fixed large interval\\n\\n        num_zeros_to_find = 50 # Max zeros to find\\n\\n        # Find zeros within the initial segment\\n        initial_zeros = find_zeros_in_interval(integrand, lower_limit, search_range_end, num_points_for_search=2000)\\n        \\n        # Filter for unique and sort them, keeping a manageable number\\n        initial_zeros = sorted(list(set(initial_zeros)))[:num_zeros_to_find]\\n        \\n        if len(initial_zeros) > 0:\\n            answer, error_estimate = scipy.integrate.quad(\\n                integrand, lower_limit, np.inf,\\n                points=initial_zeros,\\n                limit=HIGH_LIMIT * 2, epsabs=STRICT_EPSABS, epsrel=STRICT_EPSREL\\n            )\\n\\n            is_nan_inf = np.isnan(answer) or np.isinf(answer) or \\\\\\n                         np.isnan(error_estimate) or np.isinf(error_estimate)\\n            \\n            is_error_too_high = False\\n            if not is_nan_inf:\\n                if abs(answer) >= 1e-10:\\n                    if error_estimate / abs(answer) > 1e-8:\\n                        is_error_too_high = True\\n                else:\\n                    if error_estimate > 1e-16:\\n                        is_error_too_high = True\\n\\n            if not (is_nan_inf or is_error_too_high):\\n                return answer, error_estimate\\n    except Exception:\\n        pass # Fall through if finding zeros or quad with points fails\\n\\n    # Strategy 3b: Transformation x = lower_limit + t / (1-t) (maps [a, inf) to [0, 1))\\n    # This can help for functions that decay rapidly but might have a singularity at the lower limit \`a\` if \`a=0\`.\\n    try:\\n        def transformed_integrand_zero_to_one(t):\\n            # Use machine epsilon to handle t very close to 1\\n            if t >= 1.0 - np.finfo(float).eps:\\n                return 0.0 \\n\\n            denominator = 1.0 - t\\n            # Check for t very close to 1, where 1-t approaches 0.\\n            if denominator < 1e-15: # Tighter cutoff for numerical stability near t=1\\n                return 0.0 \\n\\n            x_val = lower_limit + t / denominator\\n            dx_dt = 1.0 / (denominator * denominator)\\n            \\n            # If integrand evaluates to NaN/Inf for large x_val, clamp to 0 for numerical stability\\n            # for converging integrals, as f(infinity) should effectively be 0.\\n            try:\\n                f_x = integrand(x_val)\\n                if np.isnan(f_x) or np.isinf(f_x):\\n                    return 0.0 \\n                return f_x * dx_dt\\n            except Exception:\\n                return 0.0 \\n\\n        # Add points to help quad handle the singularity at t=1.0.\\n        # These points are concentrated near t=1 to help quad adapt to the behavior there.\\n        singularity_points = np.logspace(-1, -12, 30, base=10.0).tolist() # More log-spaced points very close to 1\\n        singularity_points = [1.0 - p for p in singularity_points if 1.0 - p > 0] # Transform to be 0.9, 0.99 etc.\\n        singularity_points.append(1.0) # Explicitly include the upper limit\\n        singularity_points = sorted(list(set(singularity_points))) # Remove duplicates and sort\\n\\n        answer, error_estimate = scipy.integrate.quad(\\n            transformed_integrand_zero_to_one, 0, 1,\\n            points=singularity_points, # Pass the singularity points\\n            limit=HIGH_LIMIT * 3, epsabs=1e-17, epsrel=1e-17 # Extremely aggressive parameters\\n        )\\n        \\n        # Apply very strict error checks for this transformed finite integral.\\n        # If it's still unreliable, we fall back.\\n        is_nan_inf = np.isnan(answer) or np.isinf(answer) or \\\\\\n                     np.isnan(error_estimate) or np.isinf(error_estimate)\\n        \\n        is_error_too_high = False\\n        if not is_nan_inf:\\n            if abs(answer) >= 1e-10:\\n                if error_estimate / abs(answer) > 1e-8: # Even tighter relative error threshold\\n                    is_error_too_high = True\\n            else: # For small answers, use absolute error threshold\\n                if error_estimate > 1e-16: # Even tighter absolute error threshold\\n                    is_error_too_high = True\\n\\n        if not (is_nan_inf or is_error_too_high):\\n            return answer, error_estimate\\n    except Exception:\\n        # Fallback to Strategy 3c if transformation fails (e.g., due to severe singularity at t=1, or numerical instability)\\n        pass\\n\\n    # Strategy 3c: Segment Summation with Euler Acceleration (for highly oscillatory integrals)\\n    # This method is most effective for alternating series with decaying terms.\\n    # It assumes the integrand is oscillatory and integrable from \`lower_limit\` to infinity.\\n    # The \`segment_length = math.pi\` is a strong heuristic; ideally, this would be adaptive\\n    # or determined by analyzing the integrand's dominant frequency.\\n\\n    current_segment_start = float(lower_limit)\\n    segment_length = math.pi  # Heuristic for common oscillatory functions like sin(x) or cos(x)\\n                              # This is a key limitation if true periodicity is different.\\n    \\n    segment_integrals = []\\n    \\n    max_segments_to_compute = 1000 # Reduced maximum segments to avoid extremely long computations for non-convergent cases\\n    min_segments_for_euler = 50   # Reduced minimum terms for Euler transformation stability\\n\\n    prev_seg_val = None\\n    consistent_sign_count = 0     # To detect non-alternating series (Euler works best for alternating)\\n    consecutive_decay_count = 0   # To detect rapid decay and allow early stopping\\n    \\n    # Initialize error tracker for segments (for Euler error estimation later)\\n    segment_errors_sum_sq = 0.0 # Sum of squared errors for total error propagation\\n\\n    for i in range(max_segments_to_compute):\\n        seg_start = current_segment_start\\n        seg_end = current_segment_start + segment_length\\n\\n        # Ensure segment length is positive and non-trivial\\n        if seg_end <= seg_start + 1e-12: \\n            break \\n\\n        try:\\n            # Integrate each segment using scipy.integrate.quad with strict parameters.\\n            seg_val, seg_err = scipy.integrate.quad(\\n                integrand, seg_start, seg_end,\\n                limit=HIGH_LIMIT, epsabs=STRICT_EPSABS, epsrel=STRICT_EPSREL \\n            )\\n            \\n            # If segment integral fails or error is too high relative to segment value,\\n            # consider this segment unreliable. This will break the loop and proceed to Euler.\\n            if np.isnan(seg_val) or np.isinf(seg_val):\\n                raise ValueError(f\\"Segment integral produced NaN/Inf at {i}-th segment: val={seg_val}\\")\\n            \\n            # Stricter error checks for individual segments. If they are not met, the terms might be too noisy for Euler.\\n            if abs(seg_val) >= 1e-10 and seg_err / abs(seg_val) > 1e-7: # Relative error for larger segment values\\n                raise ValueError(f\\"Segment integral relative error too high at {i}-th segment: val={seg_val}, err={seg_err}\\")\\n            elif abs(seg_val) < 1e-10 and seg_err > 1e-16: # Absolute error for small segment values\\n                raise ValueError(f\\"Segment integral absolute error too high at {i}-th segment: val={seg_val}, err={seg_err}\\")\\n\\n            segment_integrals.append(seg_val)\\n            segment_errors_sum_sq += seg_err**2 # Accumulate squared errors for total error propagation\\n            current_segment_start = seg_end\\n\\n            # --- Checks for suitability of Euler transformation and early stopping ---\\n            if i > 0:\\n                # Check for non-alternating signs (Euler works best for alternating series)\\n                # If terms consistently do not alternate AND are not negligible, Euler is likely not suitable.\\n                if seg_val * prev_seg_val >= 0 and abs(seg_val) > 1e-15: # Same sign AND not effectively zero\\n                    consistent_sign_count += 1\\n                else:\\n                    consistent_sign_count = 0 \\n                \\n                if consistent_sign_count >= 10 and i >= min_segments_for_euler: # Fewer consecutive same-sign terms for earlier sum fallback\\n                    break \\n\\n                # Check for very rapid decay. If terms become negligible, implies direct sum convergence.\\n                # Thresholds are tuned to float64 precision.\\n                if abs(prev_seg_val) > 1e-30 and abs(seg_val) < (1e-15 * abs(prev_seg_val) + 1e-30): # Tighter threshold for decay\\n                    consecutive_decay_count += 1\\n                    if consecutive_decay_count >= 10: # Sufficient consecutive decay detected\\n                        break\\n                else:\\n                    consecutive_decay_count = 0\\n                \\n        except Exception:\\n            break # Stop collecting segments if a segment fails.\\n\\n        prev_seg_val = seg_val\\n\\n    # Apply Euler's Transformation\\n    N_segments = len(segment_integrals)\\n    if N_segments < min_segments_for_euler:\\n        # Not enough terms collected for reliable Euler transformation.\\n        # Fallback to simple sum with high error.\\n        return np.sum(segment_integrals), np.sqrt(segment_errors_sum_sq) + np.inf \\n\\n    euler_sums = np.array(segment_integrals, dtype=float) \\n    euler_diagonal_values = [euler_sums[0]] \\n\\n    consecutive_converged_count = 0\\n    target_consecutive_converged = 5 # Fewer consecutive converged steps for strong confidence.\\n\\n    try:\\n        max_euler_levels = N_segments - 1\\n\\n        for m in range(max_euler_levels): \\n            if len(euler_sums) < 2: \\n                break \\n\\n            # This computes the next diagonal values: e_{m+1,n} = (e_{m,n} + e_{m,n+1})/2\\n            new_euler_sums = (euler_sums[:-1] + euler_sums[1:]) / 2.0\\n            euler_sums = new_euler_sums\\n            \\n            euler_diagonal_values.append(euler_sums[0]) # Stores e_{m,0} (the diagonal values)\\n            \\n            if m > 0: # Start checking convergence after at least one step of Euler\\n                diff = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n                \\n                # Converged if difference is very small relatively OR absolutely (for very small answers).\\n                # These thresholds reflect machine precision for float64.\\n                if (abs(euler_diagonal_values[-1]) >= 1e-10 and diff < 5e-15 * abs(euler_diagonal_values[-1])) or \\\\\\n                   (abs(euler_diagonal_values[-1]) < 1e-10 and diff < 5e-21): \\n                    consecutive_converged_count += 1\\n                else:\\n                    consecutive_converged_count = 0 \\n                \\n                # If enough consecutive converged steps are observed, we can stop.\\n                if consecutive_converged_count >= target_consecutive_converged:\\n                    break\\n\\n                # Check for strong divergence in Euler diagonal values.\\n                if m > 2 and abs(euler_diagonal_values[-1]) > abs(euler_diagonal_values[-2]) * 1000 and abs(euler_diagonal_values[-2]) > 1e-15: \\n                    return np.nan, np.inf # Indicate divergence by NaN, Inf\\n\\n    except Exception:\\n        # If Euler transformation process itself encounters an error (e.g., due to NaNs introduced),\\n        # return with high uncertainty.\\n        return np.nan, np.inf\\n\\n    # Final result from Euler acceleration.\\n    final_answer = euler_diagonal_values[-1] if len(euler_diagonal_values) > 0 else np.sum(segment_integrals)\\n    \\n    # Estimate error based on the last few Euler diagonal values and total segment errors.\\n    error_estimate_from_euler = np.inf\\n    if len(euler_diagonal_values) >= 2:\\n        # Use the difference between the last two Euler diagonal values as an indicator of remaining error from acceleration.\\n        error_estimate_from_euler = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n        # Add a floor to ensure the error estimate is at least machine precision relevant to the answer.\\n        error_estimate_from_euler = max(error_estimate_from_euler, 1e-14 * abs(final_answer), 1e-25) \\n    \\n    # Combine errors: propagated quadrature error plus Euler's own acceleration error.\\n    total_error_estimate = np.sqrt(segment_errors_sum_sq) + error_estimate_from_euler\\n    \\n    # Final check for NaN/Inf results from the Euler method.\\n    if np.isnan(final_answer) or np.isinf(final_answer) or np.isinf(total_error_estimate):\\n        return np.nan, np.inf\\n\\n    return final_answer, total_error_estimate"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
