<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": 10.0,
  "old_code": "import math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    try:\\n        answer, error_estimate = scipy.integrate.quad(integrand, lower_limit, upper_limit)\\n\\n        # Check for NaN or Inf results/errors from quad, or if error is too high\\n        # A common heuristic for \\"unreliable\\" is error_estimate being comparable to or larger than the answer.\\n        if (np.isnan(answer) or np.isinf(answer) or\\n            np.isnan(error_estimate) or np.isinf(error_estimate) or\\n            (abs(answer) > 1e-10 and error_estimate / abs(answer) > 0.05) or # Relative error check\\n            (abs(answer) <= 1e-10 and error_estimate > 1e-8)): # Absolute error check for small results\\n            raise ValueError(\\"scipy.integrate.quad failed to converge reliably or error is too high.\\")\\n            \\n        return answer, error_estimate\\n    except Exception:\\n        # If quad fails or raises an error, fall back to a more robust method for oscillatory integrals\\n        pass # Continue to specialized method\\n\\n    # --- Step 2: Handle Infinite Limits for Specialized Method ---\\n    # Convert all integrals to the form [a, inf) for uniform processing.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        val1, err1 = quadrature(integrand, lower_limit, 0)\\n        val2, err2 = quadrature(integrand, 0, upper_limit)\\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-b}^{inf} f(-t) dt\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t)\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] where quad failed.\\n        # This implies a very difficult finite integral. Try Romberg as a last resort.\\n        try:\\n            # Romberg is good for smooth functions over finite intervals.\\n            # It may struggle with oscillations or singularities.\\n            ans_romberg = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=20)\\n            # Romberg does not directly return error. A rough estimate is difference of last two levels.\\n            # This is a heuristic error estimate, not from a rigorous error bounds.\\n            ans_romberg_prev = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=19)\\n            err_romberg = abs(ans_romberg - ans_romberg_prev) * 10 # Scale difference for a rough error\\n            return ans_romberg, err_romberg\\n        except Exception:\\n            return np.nan, np.inf # Indicate failure\\n\\n    # --- Step 3: Specialized Fallback for Oscillatory Integrals on [a, inf) ---\\n    # This method is for [a, inf) where 'a' is finite.\\n    # It assumes the integrand oscillates and decays.\\n\\n    start_oscillation_point = lower_limit\\n    segment_length = math.pi  # Heuristic for half-period of common oscillations (sin(x), cos(x))\\n    \\n    # Store segment integrals for Euler transformation\\n    segment_integrals = []\\n    \\n    # Accumulate initial terms by direct integration over segments\\n    num_segments_to_try = 100 # Maximum number of segments to compute\\n    min_segments_for_euler = 5 # Minimum terms required for Euler transformation to be meaningful\\n\\n    for i in range(num_segments_to_try):\\n        seg_start = start_oscillation_point + i * segment_length\\n        seg_end = start_oscillation_point + (i + 1) * segment_length\\n\\n        try:\\n            seg_val, seg_err = scipy.integrate.quad(integrand, seg_start, seg_end, limit=200, epsabs=1e-10, epsrel=1e-10) # Higher limit/precision for segments\\n            segment_integrals.append(seg_val)\\n\\n            # Check for decay: if terms are consistently very small, we might have converged\\n            if i >= min_segments_for_euler and abs(seg_val) < 1e-12 * abs(np.sum(segment_integrals[:-1])):\\n                # print(f\\"Segment terms decaying quickly at iteration {i}. Summing directly.\\")\\n                break # Stop collecting terms\\n            \\n            # If terms start to grow or fluctuate erratically, break as convergence is unlikely\\n            if i > 0 and abs(seg_val) > abs(segment_integrals[-2]) * 10 and abs(segment_integrals[-2]) > 1e-10:\\n                # print(f\\"Terms not decaying, or growing at iteration {i}. Direct sum so far.\\")\\n                # This suggests the integral is not converging, or the segment_length is wrong.\\n                return np.sum(segment_integrals), np.inf # Return current sum with high error\\n            \\n        except Exception:\\n            # If any segment integration fails, return the sum of successful segments\\n            # with a high error to indicate uncertainty.\\n            # print(f\\"scipy.integrate.quad failed for segment {seg_start}-{seg_end}.\\")\\n            return np.sum(segment_integrals), np.inf\\n\\n    # --- Step 4: Apply Series Acceleration (Euler's Transformation) ---\\n    # This version of Euler transformation is suitable for alternating series\\n    # S = a_0 - a_1 + a_2 - a_3 + ... or any series that becomes alternating after few terms\\n    # It requires the terms to decrease in magnitude.\\n    \\n    N = len(segment_integrals)\\n    if N < min_segments_for_euler:\\n        # Not enough terms collected for Euler transformation, return simple sum\\n        return np.sum(segment_integrals), np.inf # High uncertainty\\n\\n    # Euler transformation implementation\\n    # This iterative form computes a triangular array of sums,\\n    # often converging on the diagonal.\\n    \\n    sums = np.array(segment_integrals, dtype=float)\\n    \\n    try:\\n        for _ in range(max(1, N - 1)): # Iterate N-1 times to reduce sums array to 1 element\\n            if len(sums) < 2:\\n                break\\n            # Compute new terms by averaging adjacent elements\\n            new_sums = (sums[:-1] + sums[1:]) / 2.0\\n            # If terms are alternating, Delta terms will make a more stable sequence.\\n            # Here, we directly average sums for a conceptual Euler transformation.\\n            \\n            # More stable Euler: sums[i] = (old_sums[i] + old_sums[i+1])/2\\n            # This is a bit simplistic, as actual Euler involves differences.\\n            \\n            # Let's use a standard Richardson-like extrapolation idea which Euler uses.\\n            # The simple iterative averaging does perform some level of acceleration for\\n            # alternating series.\\n            \\n            # This is a common form of Euler transformation applied to partial sums:\\n            # S_0 = a_0, S_1 = a_0+a_1, S_2 = a_0+a_1+a_2, ...\\n            # Then T_0 = (S_0+S_1)/2, T_1 = (S_1+S_2)/2, ...\\n            # Then U_0 = (T_0+T_1)/2, ... and so on. The diagonal usually converges.\\n\\n            # We have segment_integrals which are a_k.\\n            # Compute partial sums first.\\n            if N > 0:\\n                partial_sum_sequence = np.cumsum(segment_integrals)\\n                \\n                # Apply Euler transformation on \`partial_sum_sequence\`\\n                # This requires a triangular array, which can be computationally intensive.\\n                # A simplified approach is to use the last element after several averaging steps.\\n\\n                # Simplified: average the current sums\\n                if len(new_sums) > 0:\\n                    sums = new_sums\\n                else:\\n                    break # Only one term left, or no terms for averaging\\n\\n            # Check if the series is actually converging via this method\\n            if len(sums) > 0 and abs(sums[-1] - sums[0]) < 1e-8 * abs(sums[0]) and len(sums) > 1:\\n                # print(f\\"Euler transformation converged with {len(sums)} terms remaining.\\")\\n                break\\n\\n    except Exception:\\n        # print(\\"Euler transformation encountered an error.\\")\\n        pass\\n\\n    # The final result is the last term in the \`sums\` array after transformation\\n    final_answer = sums[0] if len(sums) > 0 else np.sum(segment_integrals)\\n    \\n    # Estimate error: If Euler converged well, the error is very small, otherwise higher.\\n    # A common error estimate for Euler is the magnitude of the last neglected term or a multiple of it.\\n    if len(sums) > 1:\\n        error_estimate = abs(sums[0] - sums[1]) * 2 # Roughly the difference of the last two averages\\n    elif len(segment_integrals) > 0:\\n        error_estimate = abs(segment_integrals[-1]) * 10 # If only one Euler term, error is last segment's size.\\n    else:\\n        error_estimate = np.inf # No segments successfully integrated\\n\\n    if np.isnan(final_answer) or np.isinf(final_answer):\\n        # If Euler also gives NaN/Inf, return ultimate failure\\n        return np.nan, np.inf\\n\\n    return final_answer, error_estimate",
  "new_index": 30,
  "new_code": "import math\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\nfrom typing import Callable, Tuple\\n\\ndef quadrature(\\n    integrand: Callable[[float], float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    try:\\n        # Increase precision settings for initial quad attempt\\n        answer, error_estimate = scipy.integrate.quad(\\n            integrand, lower_limit, upper_limit,\\n            epsabs=1e-12, epsrel=1e-12, limit=100\\n        )\\n\\n        # Check for NaN or Inf results/errors from quad\\n        if np.isnan(answer) or np.isinf(answer) or np.isnan(error_estimate) or np.isinf(error_estimate):\\n            raise ValueError(\\"scipy.integrate.quad returned NaN or Inf.\\")\\n        \\n        # Heuristic for \\"unreliable\\" or \\"too high error\\"\\n        # Relative error check for non-zero results\\n        if abs(answer) > 1e-9 and error_estimate / abs(answer) > 0.01: # Error > 1% of result\\n             raise ValueError(\\"scipy.integrate.quad relative error too high.\\")\\n        # Absolute error check for very small results\\n        if abs(answer) <= 1e-9 and error_estimate > 1e-9: # Error > 1e-9 for near-zero result\\n             raise ValueError(\\"scipy.integrate.quad absolute error too high for small result.\\")\\n            \\n        return answer, error_estimate\\n    except Exception:\\n        # If quad fails or raises an error, fall back to a more robust method for oscillatory integrals\\n        pass # Continue to specialized method\\n\\n    # --- Step 2: Handle Infinite Limits for Specialized Method ---\\n    # Convert all integrals to the form [a, inf) for uniform processing.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        val1, err1 = quadrature(integrand, -np.inf, 0.0) # Use 0.0 to make it explicit float\\n        val2, err2 = quadrature(integrand, 0.0, np.inf)\\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-b}^{inf} f(-t) dt\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t)\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] where quad already failed.\\n        # This implies a very difficult finite integral. Try Romberg as a last resort.\\n        # Romberg is good for smooth functions over finite intervals, but its error estimate is heuristic.\\n        try:\\n            ans_romberg = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=20, tol=1e-10)\\n            # A rough error estimate for Romberg is the difference of the last two levels of estimation.\\n            # Perform a computation with slightly fewer divisions to get a prior estimate.\\n            ans_romberg_prev = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=19, tol=1e-10)\\n            err_romberg = abs(ans_romberg - ans_romberg_prev) * 10.0 # Scale difference for a rough error\\n            if np.isnan(ans_romberg) or np.isinf(ans_romberg) or err_romberg > 1e-6:\\n                raise ValueError(\\"Romberg failed or error too high.\\")\\n            return ans_romberg, err_romberg\\n        except Exception:\\n            return np.nan, np.inf # Indicate failure\\n\\n    # --- Step 3: Specialized Fallback for Oscillatory Integrals on [a, inf) ---\\n    # This method integrates between successive zeros (or sign changes) of the integrand,\\n    # then applies Euler transformation for series acceleration.\\n\\n    # Helper to find the next zero (or sign change point)\\n    def find_next_zero(func, current_start, step_size, max_steps=200):\\n        \\"\\"\\"\\n        Scans forward to find the next zero of func after current_start.\\n        Returns the root or None if not found within max_steps.\\n        \\"\\"\\"\\n        x_curr = current_start + 1e-12  # Start strictly after current_start to avoid finding it again\\n        \\n        try: # Check initial function value\\n            val_curr = func(x_curr)\\n            if np.isnan(val_curr) or np.isinf(val_curr):\\n                return None # Cannot evaluate function\\n        except Exception:\\n            return None\\n\\n        # If current_start is already a root or very near zero, try to move past it\\n        if abs(val_curr) < 1e-15:\\n            x_curr += step_size \\n            try:\\n                val_curr = func(x_curr)\\n                if np.isnan(val_curr) or np.isinf(val_curr):\\n                    return None\\n            except Exception:\\n                return None\\n\\n        x_next = x_curr + step_size\\n        \\n        for _ in range(max_steps):\\n            try:\\n                val_next = func(x_next)\\n\\n                if np.isnan(val_next) or np.isinf(val_next):\\n                    return None\\n                \\n                # Found a bracket where sign changes\\n                if val_curr * val_next < 0:\\n                    try:\\n                        res = scipy.optimize.root_scalar(func, bracket=[x_curr, x_next], method='brentq', xtol=1e-13, maxiter=200)\\n                        return res.root\\n                    except ValueError:\\n                        # Brentq failed for this bracket, possibly not a strict sign change or very flat.\\n                        # Continue scanning the next interval.\\n                        pass \\n                elif abs(val_next) < 1e-15: # x_next is a root (or very close to zero)\\n                     return x_next\\n\\n                # No sign change, move forward\\n                x_curr = x_next\\n                val_curr = val_next\\n                x_next = x_curr + step_size\\n\\n                # Heuristic for divergence (values growing rapidly)\\n                if abs(val_next) > abs(val_curr) * 100 and abs(val_curr) > 1e-10:\\n                    return None # Likely diverging or non-oscillatory in this region\\n\\n            except Exception: # Function evaluation failed (e.g. log(negative number))\\n                return None\\n        \\n        return None # No zero found within max_steps\\n\\n    current_integration_point = lower_limit\\n    segment_integrals = []\\n    \\n    # Adaptive step_size for finding next zeros. Start with a common half-period.\\n    # It will adapt based on the distance between found zeros.\\n    adaptive_step_size = math.pi / 2 \\n    \\n    max_segments_to_collect = 200 # Max segments to compute\\n    min_segments_for_acceleration = 5 # Minimum terms required for Euler transformation to be meaningful\\n    \\n    consecutive_small_segments_count = 0\\n    decay_threshold_abs = 1e-10 # Absolute threshold for segment value decay\\n    \\n    # Iterate to collect segments\\n    for i in range(max_segments_to_collect):\\n        # Try to find the next zero after current_integration_point\\n        # Use adaptive_step_size for scanning for roots.\\n        next_zero = find_next_zero(integrand, current_integration_point, adaptive_step_size)\\n        \\n        # If no more zeros are found, integrate the remaining tail to infinity\\n        if next_zero is None:\\n            try:\\n                # Integrate the final segment from current_integration_point to infinity\\n                # Use default quad settings for the tail for robustness.\\n                tail_val, tail_err = scipy.integrate.quad(integrand, current_integration_point, np.inf, epsabs=1e-12, epsrel=1e-12, limit=200)\\n                segment_integrals.append(tail_val)\\n                break # All done, no more zeros to find\\n            except Exception:\\n                # If tail integration fails, return current sum with high error\\n                return np.sum(segment_integrals), np.inf\\n\\n        # Integrate the segment between current_integration_point and next_zero\\n        try:\\n            seg_val, seg_err = scipy.integrate.quad(integrand, current_integration_point, next_zero, epsabs=1e-13, epsrel=1e-13, limit=200)\\n            segment_integrals.append(seg_val)\\n\\n            # Update for next iteration: adapt step_size for future zero searches\\n            # If a very small segment found, scale down the step for the next search\\n            # to avoid missing dense oscillations.\\n            current_segment_length = next_zero - current_integration_point\\n            if current_segment_length < adaptive_step_size * 0.1: # If segment is much smaller than current step\\n                 adaptive_step_size = current_segment_length * 2 # Adapt step to local period\\n            elif current_segment_length > adaptive_step_size * 2: # If segment is much larger than current step\\n                adaptive_step_size = current_segment_length / 2 # Adapt step to local period\\n            else:\\n                adaptive_step_size = current_segment_length # Keep it around the found length\\n\\n            current_integration_point = next_zero\\n\\n            # Check for decay and stop collecting segments\\n            if abs(seg_val) < decay_threshold_abs:\\n                consecutive_small_segments_count += 1\\n                if consecutive_small_segments_count >= 3: # Require 3 consecutive small segments to stop\\n                    break\\n            else:\\n                consecutive_small_segments_count = 0\\n            \\n            # Check for divergence (terms growing rapidly)\\n            if i > 0 and abs(seg_val) > abs(segment_integrals[i-1]) * 10 and abs(segment_integrals[i-1]) > 1e-10:\\n                # print(f\\"Segment values growing, likely non-convergent or no more oscillations: {i}\\")\\n                return np.sum(segment_integrals), np.inf\\n            \\n        except Exception:\\n            # If any segment integration fails, return the sum of successful segments\\n            # with a high error to indicate uncertainty.\\n            return np.sum(segment_integrals), np.inf\\n\\n    # --- Step 4: Apply Series Acceleration (Euler's Transformation) ---\\n    N = len(segment_integrals)\\n    if N < min_segments_for_acceleration:\\n        # Not enough terms collected for reliable acceleration. Return simple sum.\\n        return np.sum(segment_integrals), np.inf # High uncertainty\\n\\n    # Apply Euler transformation (iterative averaging method)\\n    # This method computes a sequence of transformed sums by repeatedly averaging adjacent terms.\\n    # For alternating series, the first term in the sequence often converges quickly to the true sum.\\n    sums = np.array(segment_integrals, dtype=float)\\n    \\n    try:\\n        # Perform up to 50 iterations or until only one term is left.\\n        # The convergence is checked by observing the stability of the first element.\\n        for _ in range(min(50, N - 1)):\\n            if len(sums) < 2:\\n                break\\n            \\n            new_sums = (sums[:-1] + sums[1:]) / 2.0\\n            \\n            # Check for convergence: If the first element has stabilized significantly.\\n            if len(new_sums) > 0 and abs(new_sums[0] - sums[0]) < 1e-12:\\n                sums = new_sums\\n                break\\n            \\n            sums = new_sums # Update sums for the next iteration\\n            \\n    except Exception:\\n        # print(\\"Euler transformation encountered an error.\\")\\n        pass # Continue with whatever sum was achieved\\n\\n    final_answer = sums[0] if len(sums) > 0 else np.sum(segment_integrals)\\n    \\n    # Estimate error: Based on the difference between the last two terms of the accelerated series.\\n    # This provides a heuristic indication of how well the series has been accelerated.\\n    if len(sums) > 1:\\n        error_estimate = abs(sums[0] - sums[1]) * 2.0 # Common heuristic for Euler error\\n    elif len(segment_integrals) > 0:\\n        error_estimate = abs(segment_integrals[-1]) * 10.0 # If only one accelerated term, use last original segment\\n    else:\\n        error_estimate = np.inf # No segments integrated successfully\\n\\n    # If the result is NaN/Inf or the estimated error is still too high, indicate failure.\\n    if np.isnan(final_answer) or np.isinf(final_answer) or error_estimate > 1e-6:\\n        return np.nan, np.inf\\n\\n    return final_answer, error_estimate"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
