<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": 107.0,
  "old_code": "import math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    try:\\n        # Push scipy.integrate.quad a bit harder with higher limits and absolute tolerance\\n        # Increased limit and tightened epsilons even further for the primary attempt.\\n        answer, error_estimate = scipy.integrate.quad(\\n            integrand, lower_limit, upper_limit,\\n            limit=1000,      # Max subintervals, increased from 200/500\\n            epsabs=1e-15,   # Absolute error tolerance, tightened from 1e-12/1e-14\\n            epsrel=1e-15    # Relative error tolerance, tightened from 1e-12/1e-14\\n        )\\n\\n        # Check for NaN or Inf results/errors from quad, or if error is too high\\n        # Adjusted heuristic for \\"unreliable\\": if relative error is > 0.5% or absolute error > 5e-8 for small answers\\n        if (np.isnan(answer) or np.isinf(answer) or\\n            np.isnan(error_estimate) or np.isinf(error_estimate) or\\n            (abs(answer) > 1e-8 and error_estimate / abs(answer) > 0.005) or # Tighter relative error check (0.5%)\\n            (abs(answer) <= 1e-8 and error_estimate > 5e-8)): # Tighter absolute error check for tiny results\\n            raise ValueError(\\"scipy.integrate.quad failed to converge reliably or error is too high.\\")\\n            \\n        return answer, error_estimate\\n    except Exception:\\n        # If quad fails or raises an error, fall back to a more robust method for oscillatory integrals\\n        pass # Continue to specialized method\\n\\n    # --- Step 2: Handle Infinite Limits for Specialized Method ---\\n    # Convert all integrals to the form [a, inf) for uniform processing.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        # Recursively call quadrature for the split parts\\n        val1, err1 = quadrature(integrand, -np.inf, 0)\\n        val2, err2 = quadrature(integrand, 0, np.inf)\\n        \\n        # If either sub-integral failed, propagate failure.\\n        if np.isnan(val1) or np.isnan(val2) or np.isinf(err1) or np.isinf(err2):\\n            return np.nan, np.inf\\n        \\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-b}^{inf} f(-t) dt\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t)\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] where quad failed.\\n        # This implies a very difficult finite integral. Try again with aggressive quad, then Romberg.\\n        try:\\n            # Even more aggressive quad parameters for the finite interval fallback\\n            answer, error_estimate = scipy.integrate.quad(\\n                integrand, lower_limit, upper_limit,\\n                limit=2000, epsabs=1e-16, epsrel=1e-16 # Increased limit and tightened epsilons\\n            )\\n            # Stricter error check for finite integrals here.\\n            if (np.isnan(answer) or np.isinf(answer) or\\n                np.isnan(error_estimate) or np.isinf(error_estimate) or\\n                (abs(answer) > 1e-8 and error_estimate / abs(answer) > 0.001) or # Tighter relative error check (0.1%)\\n                (abs(answer) <= 1e-8 and error_estimate > 1e-8)): # Tighter absolute error check\\n                raise ValueError(\\"Aggressive quad also failed for finite interval.\\")\\n            return answer, error_estimate\\n        except Exception:\\n            try:\\n                # Romberg is good for smooth functions over finite intervals.\\n                # It may struggle with oscillations or singularities.\\n                # Increase \`divmax\` for more iterations.\\n                # Romberg's return value for error is not standard, so this is a heuristic.\\n                ans_romberg = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=35) # Increased divmax from 25/30\\n                # A more robust error estimation for Romberg can be the difference from the previous iteration.\\n                # Romberg function usually performs \`divmax\` iterations. We estimate error using the last and second to last.\\n                # This requires a trickier approach since romberg doesn't expose all intermediate results easily.\\n                # For simplicity, we just run it one level less and take the difference, though this is not ideal.\\n                ans_romberg_prev_level = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=max(1, ans_romberg._results.shape[0] - 2)) if hasattr(ans_romberg, '_results') else None\\n\\n                if ans_romberg_prev_level is None: # Fallback if _results is not available or too short\\n                    ans_romberg_prev_level = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=max(1, 34))\\n\\n                err_romberg = abs(ans_romberg - ans_romberg_prev_level) * 10 # Scaled for rough estimate\\n\\n                # If Romberg result is suspicious (e.g., zero with non-zero previous level diff, or huge error)\\n                if abs(ans_romberg) < 1e-12 and err_romberg > 1e-8: # If result is tiny but error is not\\n                    return np.nan, np.inf # Indicate failure\\n                    \\n                return ans_romberg, err_romberg\\n            except Exception:\\n                return np.nan, np.inf # Indicate failure\\n\\n    # --- Step 3: Specialized Fallback for Oscillatory Integrals on [a, inf) ---\\n    # This method is for [a, inf) where 'a' is finite.\\n    # It assumes the integrand oscillates and decays.\\n\\n    start_oscillation_point = lower_limit\\n    segment_length = math.pi  # Heuristic for half-period of common oscillations (sin(x), cos(x))\\n    \\n    # Store segment integrals for Euler transformation\\n    segment_integrals = []\\n    \\n    # Accumulate initial terms by direct integration over segments\\n    num_segments_to_try = 1000 # Increased number of segments to compute significantly (from 200/500)\\n    min_segments_for_euler = 10 # Minimum terms required for Euler transformation to be meaningful (increased from 5/7)\\n\\n    prev_seg_val = None\\n    consistent_sign_count = 0 # Count consecutive segments with the same sign (for non-alternating check)\\n    initial_oscillation_check_terms = 5 # Number of initial terms to check for basic oscillation before more stringent checks\\n\\n    for i in range(num_segments_to_try):\\n        seg_start = start_oscillation_point + i * segment_length\\n        seg_end = start_oscillation_point + (i + 1) * segment_length\\n\\n        try:\\n            # Use more aggressive quad parameters for segment integration as well\\n            seg_val, seg_err = scipy.integrate.quad(\\n                integrand, seg_start, seg_end,\\n                limit=1000, epsabs=1e-16, epsrel=1e-16 # Even tighter epsilons for segments\\n            )\\n            \\n            # If segment integral fails to converge to a small error, this whole method might be unsuitable\\n            # Also, if the segment value is NaN/Inf, that's a failure.\\n            if np.isnan(seg_val) or np.isinf(seg_val) or seg_err > 1e-12: # A more stringent error threshold for segments\\n                raise ValueError(f\\"Segment integration failed at {i}-th segment with val={seg_val}, err={seg_err}\\")\\n\\n            segment_integrals.append(seg_val)\\n\\n            # --- Convergence and Oscillation Checks ---\\n            if i > 0 and prev_seg_val is not None:\\n                # Check for alternating signs (crucial for Euler transformation) or consistent sign indicating non-oscillatory decay\\n                if (seg_val * prev_seg_val >= 0) and abs(seg_val) > 1e-16: # Not strictly alternating and non-zero\\n                    consistent_sign_count += 1\\n                    # If signs stop alternating *consistently* (e.g., 3+ times) after initial oscillation phase\\n                    if consistent_sign_count >= 3 and i >= initial_oscillation_check_terms: \\n                        # This suggests Euler transformation is not suitable (series is not alternating)\\n                        # print(f\\"Segment signs stopped alternating consistently at iteration {i}. Summing directly.\\")\\n                        return np.sum(segment_integrals), np.inf # High error, as Euler won't help much\\n                else:\\n                    consistent_sign_count = 0 # Reset if signs alternate\\n            \\n            # Check for decay: if terms are consistently very small, we might have converged\\n            # This decay check is more about the absolute value of the term itself.\\n            if i >= min_segments_for_euler and abs(seg_val) < 1e-17: # Extremely small absolute term\\n                # If sum of previous terms is also small, indicates overall convergence.\\n                if abs(np.sum(segment_integrals[:-1])) < 1e-12: # Sum is already very small\\n                    # print(f\\"Total sum is already tiny and segments decaying. Breaking at iteration {i}.\\")\\n                    break \\n                # If current term is very small relative to the last one, and previous one was not tiny, also break.\\n                if i > 0 and abs(segment_integrals[-2]) > 1e-10 and abs(seg_val) < 1e-10 * abs(segment_integrals[-2]):\\n                    # print(f\\"Segment terms decaying quickly relatively at iteration {i}. Breaking.\\")\\n                    break\\n            \\n            # If terms start to grow or fluctuate erratically, break as convergence is unlikely\\n            # If a term is significantly larger than the previous one, and not near zero.\\n            if i > initial_oscillation_check_terms and abs(seg_val) > abs(segment_integrals[-2]) * 10 and abs(segment_integrals[-2]) > 1e-12: # More aggressive growth check (factor 10)\\n                # This suggests the integral is not converging, or the segment_length is wrong.\\n                # print(f\\"Terms not decaying, or growing significantly at iteration {i}. Direct sum so far.\\")\\n                return np.sum(segment_integrals), np.inf # Return current sum with high error\\n            \\n            prev_seg_val = seg_val\\n\\n        except Exception as e:\\n            # If any segment integration fails, return the sum of successful segments\\n            # with a high error to indicate uncertainty.\\n            # print(f\\"scipy.integrate.quad failed for segment {seg_start}-{seg_end}: {e}\\")\\n            return np.sum(segment_integrals), np.inf\\n\\n    # --- Step 4: Apply Series Acceleration (Euler's Transformation) ---\\n    # This implementation uses the Euler-Knopp summation method (iterated arithmetic mean)\\n    # which is suitable for alternating series or series that converge slowly.\\n    \\n    N = len(segment_integrals)\\n    if N < min_segments_for_euler:\\n        # Not enough terms collected for Euler transformation, return simple sum\\n        return np.sum(segment_integrals), np.inf # High uncertainty\\n\\n    euler_sums = np.array(segment_integrals, dtype=float)\\n    \\n    # Store the 'diagonal' elements of the Euler transformation table for convergence check\\n    euler_diagonal_values = [euler_sums[0]] \\n\\n    try:\\n        # The Euler transformation involves repeatedly averaging adjacent terms.\\n        # We perform N-1 levels of transformation at most, as each level reduces term count by 1.\\n        max_euler_levels = N - 1\\n\\n        for m in range(max_euler_levels): \\n            if len(euler_sums) < 2: # Need at least two terms to average\\n                break\\n            \\n            # Compute the next level of sums by averaging adjacent elements\\n            new_euler_sums = (euler_sums[:-1] + euler_sums[1:]) / 2.0\\n            euler_sums = new_euler_sums\\n            \\n            euler_diagonal_values.append(euler_sums[0]) # The first element of the new level\\n            \\n            # Check for convergence of the Euler sum by comparing the last few diagonal elements\\n            # A common heuristic: if the difference between successive terms is very small relative to the term itself.\\n            # Check for stabilization of the Euler diagonal\\n            if m > 0:\\n                diff = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n                # Converged if difference is very small relative to current sum or absolutely very small\\n                if (abs(euler_diagonal_values[-1]) > 1e-12 and diff < 1e-10 * abs(euler_diagonal_values[-1])) or \\\\\\n                   (abs(euler_diagonal_values[-1]) <= 1e-12 and diff < 1e-12):\\n                    break\\n                \\n            # Additional check: If the values on the diagonal start to diverge or oscillate wildly again\\n            if m > 2 and abs(euler_diagonal_values[-1]) > abs(euler_diagonal_values[-2]) * 100: # Very aggressive check for divergence in Euler\\n                # This suggests the Euler transformation is not converging or diverging.\\n                # Revert to the last stable sum or simple sum, with high error.\\n                # print(f\\"Euler diagonal values diverging at level {m}. Reverting to previous estimate.\\")\\n                final_answer = euler_diagonal_values[-2] if len(euler_diagonal_values) >= 2 else np.sum(segment_integrals)\\n                return final_answer, np.inf\\n\\n    except Exception as e:\\n        # print(f\\"Euler transformation encountered an error: {e}\\")\\n        pass\\n\\n    final_answer = euler_diagonal_values[-1] if len(euler_diagonal_values) > 0 else np.sum(segment_integrals)\\n    \\n    # Estimate error: difference between the last two diagonal terms (if available)\\n    # A more robust error estimate is often the last term that was significantly different,\\n    # or the last calculated \`a_k\` before acceleration stabilized.\\n    if len(euler_diagonal_values) >= 2:\\n        # The error is approximately the difference between the last two computed Euler sums.\\n        # Add a small buffer / scaling to be conservative for error estimate.\\n        error_estimate = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2]) * 20 # Increased scaling for conservatism\\n    elif len(segment_integrals) > 0:\\n        # If only one Euler term was produced, use the magnitude of the last segment integral\\n        # as a rough indicator of remaining error, scaled up.\\n        error_estimate = abs(segment_integrals[-1]) * 100 # Even more conservative if only one Euler term\\n    else:\\n        error_estimate = np.inf # No segments successfully integrated\\n\\n    # Final check for NaN or Inf\\n    if np.isnan(final_answer) or np.isinf(final_answer):\\n        return np.nan, np.inf\\n\\n    return final_answer, error_estimate",
  "new_index": 122,
  "new_code": "# TODO: Implement the \`quadrature()\` function to numerically evaluate integrals.\\n\\nimport math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\nfrom scipy.special import s_ext # Import for Wynn's epsilon algorithm\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    try:\\n        # Increase limit and tighten epsilons for the primary attempt.\\n        answer, error_estimate = scipy.integrate.quad(\\n            integrand, lower_limit, upper_limit,\\n            limit=50000,      # Max subintervals, significantly increased\\n            epsabs=1e-15,   # Absolute error tolerance, tightened\\n            epsrel=1e-15    # Relative error tolerance, tightened\\n        )\\n\\n        # Check for NaN or Inf results/errors from quad, or if error is too high\\n        # More robust reliability check:\\n        # If result is NaN/Inf, or error is NaN/Inf, or error is too large.\\n        if (np.isnan(answer) or np.isinf(answer) or\\n            np.isnan(error_estimate) or np.isinf(error_estimate)):\\n            # Force fallback for pathological cases\\n            raise ValueError(\\"scipy.integrate.quad returned NaN/Inf or error is NaN/Inf.\\")\\n        \\n        # Heuristic for \\"unreliable\\": if relative error is > 0.1% or absolute error > 1e-7 for small answers\\n        # A more conservative threshold for accepting direct quad results.\\n        if (abs(answer) > 1e-7 and error_estimate / abs(answer) > 0.001) or \\\\\\n           (abs(answer) <= 1e-7 and error_estimate > 1e-7):\\n            raise ValueError(\\"scipy.integrate.quad converged, but error is still too high.\\")\\n            \\n        return answer, error_estimate\\n    except Exception:\\n        # If quad fails or raises an error, fall back to a more robust method for oscillatory integrals\\n        pass # Continue to specialized method\\n\\n    # --- Step 2: Handle Infinite Limits for Specialized Method ---\\n    # Convert all integrals to the form [a, inf) for uniform processing.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        # Recursively call quadrature for the split parts\\n        val1, err1 = quadrature(integrand, -np.inf, 0)\\n        val2, err2 = quadrature(integrand, 0, np.inf)\\n        \\n        # If either sub-integral failed, propagate failure.\\n        if np.isnan(val1) or np.isnan(val2) or np.isinf(err1) or np.isinf(err2):\\n            return np.nan, np.inf\\n        \\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-upper_limit}^{inf} f(-t) dt\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t)\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] where quad failed.\\n        # If aggressive quad failed for a finite interval, Romberg is likely to fail or be inaccurate for oscillatory/singular cases.\\n        # Therefore, we directly return failure in this scenario.\\n        return np.nan, np.inf \\n\\n    # --- Step 3: Specialized Fallback for Oscillatory Integrals on [a, inf) ---\\n    # This method is for [a, inf) where 'a' is finite.\\n    # It dynamically finds segment lengths based on oscillations.\\n\\n    start_point = lower_limit\\n    segment_integrals = []\\n    \\n    # Parameters for finding zeros and segment integration\\n    num_initial_zeros = 20 # Number of initial zeros to find for series terms\\n    max_segments = 500 # Maximum segments to collect before giving up on series acceleration\\n    min_terms_for_acceleration = 15 # Minimum terms for s_ext to be effective\\n\\n    current_x = start_point\\n    last_zero = start_point # Used to track the start of the current search interval for zeros.\\n\\n    for i in range(max_segments):\\n        # Try to find the next zero of the integrand to define the segment\\n        # This is crucial for oscillatory integrands as it aligns segments with periods.\\n        next_zero = None\\n        try:\\n            # Look for the next zero. If f(x) = g(x) sin(h(x)), roots are where h(x) = k*pi.\\n            # Using bracket as (current_x, current_x + some_length).\\n            # The 'some_length' is a guess for the typical oscillation period, e.g., 2*pi for sin(x).\\n            # For functions like sin(x^2), the interval will shrink, making finding roots hard.\\n            # We need to make sure the bracketing is reasonable.\\n            \\n            # Use a robust but cautious zero-finding approach. Start with a relatively large bracket\\n            # (e.g., 2*pi for basic oscillations), then narrow if root_scalar fails.\\n            \\n            # Attempt 1: Broad bracket. If we can't find a root within a reasonable large interval,\\n            # it might mean oscillations have died out or are too rapid.\\n            \\n            # For integrands like sin(x)/x, sin(x^2), finding analytical zeros or fixed-period zeros is hard.\\n            # For general f(x), finding where f(x)=0 is the key.\\n\\n            # Simple heuristic: look for roots in an interval of length pi, then extend.\\n            # Using fsolve for flexibility in complex cases.\\n            \\n            # Define a wrapper for the integrand to find zeros starting from last_zero\\n            def find_next_integrand_zero(x_guess):\\n                # Search for root in (last_zero, x_guess). This might not be ideal.\\n                # A better approach is to search for a zero in (last_zero + epsilon, last_zero + some_expected_period)\\n                return integrand(x_guess)\\n            \\n            # A common approach for oscillations where frequency isn't fixed:\\n            # Start with a bracket like (last_zero + eps, last_zero + initial_period_guess)\\n            # If not found, try a larger bracket, or switch to fixed segment if roots become too dense/sparse.\\n            \\n            # Using brentq from root_scalar is robust if you can find a bracket where f(a)*f(b) < 0\\n            # Let's try to find a sign change within a reasonable window\\n            bracket_start = last_zero + 1e-9 # Start slightly after the last zero to avoid it\\n            bracket_end_initial_guess = bracket_start + math.pi * 2 # Initial search window of 2*pi\\n            \\n            # Try to find a sign change. If the integrand doesn't change sign much, it's not alternating.\\n            # If values near zero, it might not find a root.\\n            \\n            # To handle cases like sin(x^2), the \\"period\\" shrinks. Finding next zero robustly is complex.\\n            # A robust but simpler fallback if zero-finding is too hard for general integrands is fixed segments.\\n            # But the challenge specifically shows sin(x^2) which benefits from adaptive segments.\\n\\n            # Heuristic for adaptive segment length: Try to find next root. If difficult, revert to smaller/fixed length.\\n            # Let's use scipy.optimize.fsolve which doesn't require bracketing, but needs a good guess.\\n            \\n            # A more sophisticated root-finding strategy:\\n            # 1. Search for sign change in (current_x, current_x + step)\\n            # 2. If sign change found, use brentq.\\n            # 3. If not, increase step (for slow oscillations) or decrease step (for fast oscillations).\\n            \\n            # For simplicity, and because root_scalar can be slow or brittle for very fast oscillations or near zeros,\\n            # we will attempt finding a root within a dynamically shrinking window if the current_x is large,\\n            # or use a fixed window. If root_scalar fails, we revert to a smaller fixed segment.\\n            \\n            # Let's refine root finding for next segment.\\n            # The key insight for oscillatory integrals is that the \\"period\\" length often changes.\\n            # For \`sin(x)/x\`, \`pi\` is a good segment length. For \`sin(x^2)\`, the period shrinks.\\n            # The zero-finding should reflect that. \`current_x + math.pi\` is too naive.\\n\\n            # Revised segment strategy:\\n            # Try to find next zero from current_x. If current_x is large, guess smaller interval.\\n            guess_interval = math.pi # Default\\n            if current_x > 100: # Heuristic for functions like sin(x^2) where period shrinks\\n                guess_interval = math.pi / math.sqrt(current_x) \\n            \\n            # Find the first sign change after \`current_x\`\\n            start_search = current_x + 1e-9 # Start search slightly after current_x\\n            end_search = start_search + guess_interval * 5 # Search over 5 \\"guesses\\"\\n            \\n            num_points_to_check_for_sign_change = 20\\n            points = np.linspace(start_search, end_search, num_points_to_check_for_sign_change)\\n            values = np.array([integrand(p) for p in points])\\n            \\n            found_bracket = False\\n            for j in range(len(points) - 1):\\n                if values[j] * values[j+1] < 0:\\n                    try:\\n                        next_zero = scipy.optimize.brentq(integrand, points[j], points[j+1], maxiter=1000)\\n                        found_bracket = True\\n                        break\\n                    except Exception:\\n                        pass # Brentq failed even with a bracket. Continue search.\\n\\n            if not found_bracket: # If no sign change found in initial broad range, try to narrow down or use fixed segment\\n                # If oscillations might be dying out, or the integrand is always positive/negative.\\n                # Or oscillations are extremely fast, and we jumped over multiple zeros.\\n                if current_x > lower_limit + 1e-9: # Only if we've moved past the start point\\n                    # Try a very small fixed segment if root finding is hard\\n                    # This indicates potential non-oscillatory decay or very rapid oscillations.\\n                    next_zero = current_x + guess_interval / 10.0 # Small segment\\n                else: # At the very beginning, if we can't find a zero quickly\\n                    next_zero = current_x + math.pi # Fallback to standard pi if no zeros found initially\\n                \\n        except Exception: # Fallback if root finding is hard\\n            # Default to a fixed segment length if no zeros can be reliably found\\n            next_zero = current_x + math.pi # Standard pi segment, as a last resort\\n            if current_x > 100: # Heuristic for faster oscillations at higher x\\n                next_zero = current_x + math.pi / (current_x) # Further reduced segment length\\n\\n        seg_start = current_x\\n        seg_end = next_zero\\n        \\n        if seg_end <= seg_start: # Avoid zero or negative length segments\\n            # If current_x is very large, oscillations might be extremely dense or dying out.\\n            # Use a tiny fixed step to continue.\\n            if seg_start > lower_limit + 1e-9:\\n                seg_end = seg_start + 1e-5 # Tiny step\\n            else: # If still at the beginning, increment by pi.\\n                seg_end = seg_start + math.pi\\n        \\n        try:\\n            # Use more aggressive quad parameters for segment integration as well\\n            seg_val, seg_err = scipy.integrate.quad(\\n                integrand, seg_start, seg_end,\\n                limit=50000, epsabs=1e-16, epsrel=1e-16 # Very high limit, very tight epsilons\\n            )\\n            \\n            # If segment integral fails to converge to a small error or returns NaN/Inf\\n            if np.isnan(seg_val) or np.isinf(seg_val) or seg_err > 1e-10: # Stricter error check for segments\\n                # If a segment is very large, it indicates problems.\\n                if abs(seg_val) > 1e3: # Arbitrary large value\\n                    raise ValueError(f\\"Segment value too large: {seg_val}\\")\\n                # If the error is high, try smaller segment, but if consistently high, fail.\\n                raise ValueError(f\\"Segment integration error too high at {i}-th segment with err={seg_err}\\")\\n\\n            segment_integrals.append(seg_val)\\n            current_x = seg_end\\n            last_zero = seg_end\\n\\n            # --- Convergence and Oscillation Checks for Collected Terms ---\\n            # These checks are now more about the quality of the series for acceleration.\\n            if i >= min_terms_for_acceleration - 1: # Start checking only after enough terms for s_ext\\n                # If current term is extremely small, implies potential decay\\n                if abs(seg_val) < 1e-16:\\n                    # If sum of previous terms is also small, indicates overall convergence.\\n                    if abs(np.sum(segment_integrals[:-1])) < 1e-12:\\n                        break # Likely converged.\\n                \\n                # Check if terms are growing instead of decaying (Euler/Wynn's need decay)\\n                if i > min_terms_for_acceleration and abs(seg_val) > abs(segment_integrals[-2]) * 5 and abs(segment_integrals[-2]) > 1e-12:\\n                    # This suggests the integral is not converging as a series, or oscillations are too complex.\\n                    # Fallback to direct sum with high error.\\n                    return np.sum(segment_integrals), np.inf\\n\\n        except Exception as e:\\n            # If any segment integration fails, return the sum of successful segments\\n            # with a high error to indicate uncertainty.\\n            # print(f\\"scipy.integrate.quad failed for segment {seg_start}-{seg_end}: {e}\\")\\n            if len(segment_integrals) == 0:\\n                return np.nan, np.inf # No segments integrated successfully\\n            return np.sum(segment_integrals), np.inf\\n\\n    # --- Step 4: Apply Series Acceleration (Wynn's Epsilon Algorithm via s_ext) ---\\n    # Wynn's epsilon algorithm is more powerful than simple Euler transformation\\n    # for a broader class of series, including non-alternating or logarithmically converging ones.\\n    \\n    N = len(segment_integrals)\\n    if N < min_terms_for_acceleration:\\n        # Not enough terms collected for series acceleration, return simple sum\\n        return np.sum(segment_integrals), np.inf # High uncertainty\\n\\n    try:\\n        # s_ext applies Wynn's epsilon algorithm and returns the extrapolated sum.\\n        # It handles the internal iteration and convergence checks.\\n        # The second return value is typically an error estimate, often the last correction.\\n        final_answer, error_estimate_s_ext = s_ext(np.array(segment_integrals))\\n\\n        # s_ext might return NaN or Inf if it diverges or fails.\\n        if np.isnan(final_answer) or np.isinf(final_answer):\\n            raise ValueError(\\"s_ext returned NaN/Inf.\\")\\n        \\n        # error_estimate_s_ext is usually the difference between the last two terms, \\n        # or the value by which it was updated in the last step.\\n        # Scale error for conservatism.\\n        error_estimate = abs(error_estimate_s_ext) * 10 \\n\\n    except Exception:\\n        # If s_ext fails (e.g., non-convergent series for the algorithm),\\n        # fallback to a direct sum with high uncertainty.\\n        final_answer = np.sum(segment_integrals)\\n        error_estimate = np.inf\\n\\n    # Final check for NaN or Inf\\n    if np.isnan(final_answer) or np.isinf(final_answer):\\n        return np.nan, np.inf\\n\\n    # If error_estimate is 0, set a minimum non-zero value for numerical stability\\n    if error_estimate < 1e-15: \\n        error_estimate = 1e-15 # A reasonable minimum error if it appears perfectly converged.\\n\\n    return final_answer, error_estimate"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
