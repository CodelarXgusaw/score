<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": 851.0,
  "old_code": "import math\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\nfrom typing import Callable, Tuple\\n\\n# Helper for robust quad calls with custom tolerances and limits\\ndef _robust_quad_call(func: Callable[float, float], a: float, b: float, limit_val: int, epsabs_val: float, epsrel_val: float) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Calls scipy.integrate.quad with specified parameters and performs robust checks\\n    to ensure the result is reliable and meets the requested tolerance.\\n    \\"\\"\\"\\n    try:\\n        val, err = scipy.integrate.quad(func, a, b, limit=limit_val, epsabs=epsabs_val, epsrel=epsrel_val)\\n        \\n        # Immediate checks for problematic results (NaN, Inf). These signify hard failures.\\n        if np.isnan(val) or np.isinf(val) or \\\\\\n           np.isnan(err) or np.isinf(err):\\n            raise ValueError(\\"Scipy quad result is NaN or Inf.\\")\\n        \\n        # Crucial reliability check:\\n        # scipy.integrate.quad returns 'err' as its *estimate* of the absolute error.\\n        # It attempts to achieve \`err <= max(epsabs, abs(val) * epsrel)\`.\\n        # If the returned 'err' is *greater* than the requested tolerance, it indicates\\n        # that quad failed to meet the precision it was asked for.\\n        # We add a small absolute epsilon to the target tolerance to account for\\n        # floating-point inaccuracies in the comparison.\\n        requested_tolerance_achieved_by_quad = max(epsabs_val, abs(val) * epsrel_val)\\n        # Modified for more robust float comparison against the requested tolerance.\\n        if err > requested_tolerance_achieved_by_quad * (1 + 100 * np.finfo(float).eps):\\n            raise ValueError(f\\"Scipy quad failed to meet requested tolerance: returned_err={err:.2e}, requested_tol={requested_tolerance_achieved_by_quad:.2e}.\\")\\n        \\n        return val, err\\n    except Exception as e:\\n        # Catch any exception that might occur during the quad call or subsequent checks.\\n        raise ValueError(f\\"Scipy quad failed or result unreliable: {e}\\")\\n\\n# Helper for Euler acceleration\\ndef _apply_euler_acceleration(series_terms: list[float], euler_abs_tol: float, euler_rel_tol: float, min_terms_for_euler: int, target_consecutive_converged: int) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Applies Euler transformation to a series of terms to accelerate convergence.\\n    Returns the accelerated sum and an error estimate.\\n    \\"\\"\\"\\n    \\n    initial_sum_terms = np.sum(series_terms) if series_terms else 0.0\\n\\n    N_terms = len(series_terms)\\n    if N_terms < min_terms_for_euler:\\n        # Not enough terms for effective Euler acceleration.\\n        # Provide a conservative error estimate based on the sum of the last few terms.\\n        error_estimate_no_euler = np.sum(np.abs(series_terms[max(0, N_terms - 15):])) if N_terms > 0 else 0.0\\n        \\n        # Add a small relative or absolute error component for overall uncertainty.\\n        if initial_sum_terms != 0:\\n            error_estimate_no_euler = max(error_estimate_no_euler, abs(initial_sum_terms) * euler_rel_tol * 10)\\n        else:\\n            error_estimate_no_euler = max(error_estimate_no_euler, euler_abs_tol * 10)\\n        \\n        return initial_sum_terms, error_estimate_no_euler\\n    \\n    euler_current_sequence = np.array(series_terms, dtype=float)\\n    if not euler_current_sequence.size > 0:\\n        return initial_sum_terms, np.inf\\n\\n    euler_diagonal_values = [euler_current_sequence[0]]\\n    consecutive_converged_count = 0\\n\\n    try:\\n        max_euler_levels = N_terms - 1\\n        for m in range(max_euler_levels): \\n            # Ensure at least two terms for transformation to avoid IndexErrors.\\n            if len(euler_current_sequence) < 2: \\n                break\\n            \\n            # Compute the next level of Euler transformation: (T_m^(j-1) + T_{m+1}^{(j-1)}) / 2.\\n            new_euler_sequence_array = (euler_current_sequence[:-1] + euler_current_sequence[1:]) / 2.0\\n            euler_current_sequence = new_euler_sequence_array\\n            \\n            # Check if the sequence became empty or problematic after transformation.\\n            if len(euler_current_sequence) == 0 or np.isnan(euler_current_sequence[0]) or np.isinf(euler_current_sequence[0]): \\n                break\\n\\n            current_euler_val = euler_current_sequence[0] # The first term of the new sequence is a diagonal value.\\n            euler_diagonal_values.append(current_euler_val) \\n            \\n            # Check for convergence in the Euler diagonal values.\\n            if m > 0 and len(euler_diagonal_values) >= 2:\\n                prev_euler_val = euler_diagonal_values[-2]\\n                diff = abs(current_euler_val - prev_euler_val)\\n                \\n                # Convergence criteria:\\n                # 1. Relative convergence for values larger than absolute tolerance.\\n                # 2. Absolute convergence for values around or smaller than absolute tolerance.\\n                is_relative_converged = (abs(current_euler_val) > euler_abs_tol) and \\\\\\n                                         (diff < euler_rel_tol * abs(current_euler_val))\\n                is_absolute_converged = (abs(current_euler_val) <= euler_abs_tol) and \\\\\\n                                         (diff < euler_abs_tol * (1 + np.finfo(float).eps)) \\n                \\n                if is_relative_converged or is_absolute_converged:\\n                    consecutive_converged_count += 1\\n                else:\\n                    consecutive_converged_count = 0 \\n                \\n                # Modified: target_consecutive_converged reduced for faster practical convergence.\\n                if consecutive_converged_count >= target_consecutive_converged: \\n                    break \\n                \\n                # Check for strong divergence in the Euler diagonal.\\n                if m > 2 and abs(prev_euler_val) > euler_abs_tol * 0.01 and \\\\\\n                   abs(current_euler_val) > abs(prev_euler_val) * 100:\\n                    # If Euler diverges, fallback to the initial sum of terms, error inf.\\n                    return initial_sum_terms, np.inf\\n\\n    except Exception:\\n        # If any numerical instability or error occurs during Euler transformation,\\n        # return the initial sum of terms as the best available estimate, with high error.\\n        return initial_sum_terms, np.inf\\n\\n    final_euler_sum = euler_diagonal_values[-1] if len(euler_diagonal_values) > 0 else initial_sum_terms\\n    error_estimate = np.inf \\n\\n    if len(euler_diagonal_values) >= 2:\\n        last_diff_euler = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n        if consecutive_converged_count >= target_consecutive_converged:\\n            # If Euler process converged sufficiently, error is estimated by last difference or requested tolerances.\\n            error_estimate = max(last_diff_euler, \\n                                 euler_rel_tol * abs(final_euler_sum), \\n                                 euler_abs_tol) \\n        else:\\n            # If Euler did not meet the strict convergence criteria, provide a more conservative error estimate.\\n            error_estimate = max(last_diff_euler * 5, # Multiply last difference for conservatism.\\n                                 euler_rel_tol * abs(final_euler_sum) * 5, # Higher relative error.\\n                                 euler_abs_tol * 5) # Higher absolute error.\\n\\n    return final_euler_sum, error_estimate\\n\\n# Helper for [a, inf) integration using geometric segments and Euler acceleration (original code's method as fallback)\\ndef _integrate_oscillatory_geometric_segments(integrand: Callable[float, float], lower_limit: float) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Integrates from lower_limit to infinity by summing integrals over geometrically growing segments.\\n    Applies Euler acceleration to the sum of these segments.\\n    \\"\\"\\"\\n    current_segment_start = float(lower_limit)\\n    segment_growth_factor = 1.2 # Factor by which subsequent segments grow in length.\\n    \\n    # Adaptive initial segment length candidates. Trying multiple helps find a good first oscillation cycle.\\n    initial_segment_length_candidates = [math.pi / 2.0, 1.0, 0.5, 0.1, 0.01, 0.001] # Added smaller steps\\n    \\n    segment_integrals = [] # List to store the integral value of each segment.\\n    \\n    max_segments_to_compute = 30000 # Increased cap for extreme cases\\n    min_segments_for_euler = 20 # Minimum segments required for Euler acceleration to be applied.\\n\\n    prev_seg_val = None \\n    consistent_sign_count = 0 \\n    consecutive_decay_count = 0 \\n    \\n    euler_abs_tol = 1e-10\\n    euler_rel_tol = 1e-8\\n    segment_integration_tol = 1e-8 # Tightened tolerance for integrating individual segments.\\n\\n    # Integrate the first segment: Try different initial lengths.\\n    found_good_first_segment = False\\n    base_segment_length = initial_segment_length_candidates[0] \\n    \\n    for try_length in initial_segment_length_candidates:\\n        seg_end = current_segment_start + try_length\\n        if seg_end <= current_segment_start + np.finfo(float).eps * 100: \\n            continue\\n        try:\\n            seg_val, seg_err = _robust_quad_call(\\n                integrand, current_segment_start, seg_end,\\n                limit_val=500000, \\n                epsabs_val=segment_integration_tol, epsrel_val=segment_integration_tol\\n            )\\n            found_good_first_segment = True\\n            base_segment_length = try_length \\n            break \\n        except ValueError:\\n            pass \\n    \\n    if not found_good_first_segment:\\n        # If no initial segment length produced a reliable result, the integral is likely problematic.\\n        return np.nan, np.inf \\n\\n    segment_integrals.append(seg_val)\\n    current_segment_start = seg_end\\n    prev_seg_val = seg_val \\n\\n    # Main loop for computing subsequent segments.\\n    for i in range(1, max_segments_to_compute): \\n        seg_start = current_segment_start\\n        seg_end = current_segment_start + base_segment_length * (segment_growth_factor ** i) \\n\\n        if seg_end - seg_start < np.finfo(float).eps * 100: \\n            break\\n\\n        try:\\n            seg_val, seg_err = _robust_quad_call(\\n                integrand, seg_start, seg_end,\\n                limit_val=500000, \\n                epsabs_val=segment_integration_tol, epsrel_val=segment_integration_tol\\n            )\\n        except ValueError: \\n            return np.sum(segment_integrals), np.inf \\n\\n        segment_integrals.append(seg_val)\\n        current_segment_start = seg_end\\n\\n        # --- Early stopping and Euler suitability checks ---\\n        if abs(seg_val) > euler_abs_tol * 0.01:\\n            if seg_val * prev_seg_val >= 0: \\n                consistent_sign_count += 1\\n            else:\\n                consistent_sign_count = 0 \\n        else:\\n            consistent_sign_count = 0 \\n        \\n        # If the series appears non-alternating for a long sequence, Euler acceleration may not converge.\\n        if consistent_sign_count >= 10 and i >= min_segments_for_euler:\\n            return np.sum(segment_integrals), np.inf \\n\\n        current_sum = np.sum(segment_integrals)\\n        if abs(seg_val) < (euler_abs_tol * 0.001) and \\\\\\n           (abs(seg_val) < (euler_rel_tol * 0.001 * abs(current_sum) if current_sum != 0 else euler_abs_tol * 0.001)): \\n            consecutive_decay_count += 1\\n            if consecutive_decay_count >= 15: \\n                break \\n        else:\\n            consecutive_decay_count = 0\\n        \\n        # Check for strong divergence in terms (integral unlikely to converge).\\n        if i >= min_segments_for_euler and \\\\\\n           abs(prev_seg_val) > euler_abs_tol * 0.01 and \\\\\\n           abs(seg_val) > abs(prev_seg_val) * 100:\\n            return np.sum(segment_integrals), np.inf \\n\\n        prev_seg_val = seg_val\\n    \\n    # Apply Euler acceleration to the collected segment integrals\\n    return _apply_euler_acceleration(segment_integrals, euler_abs_tol, euler_rel_tol, min_segments_for_euler, 3) # Modified target_consecutive_converged\\n\\n# Helper for [a, inf) integration using zero crossings\\ndef _integrate_oscillatory_by_zeros(integrand: Callable[float, float], lower_limit: float) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Integrates from lower_limit to infinity by finding successive zero crossings of the integrand,\\n    integrating over these oscillation cycles, and applying Euler acceleration.\\n    \\"\\"\\"\\n    zeros = [float(lower_limit)]\\n    segment_integrals = []\\n    \\n    # Helper to find a zero within an interval [a, b]\\n    def _find_zero_in_interval(func, a, b):\\n        try:\\n            return scipy.optimize.brentq(func, a, b, xtol=1e-15, rtol=1e-15)\\n        except ValueError:\\n            return None\\n\\n    # Helper to find the next bracketing interval for a zero (Modified)\\n    def _find_next_sign_change_interval(func, x_start, initial_step_size=0.1, step_growth_factor=1.5, max_interval_length=1e6):\\n        \\"\\"\\"\\n        Finds an interval [a, b] such that func(a) and func(b) have opposite signs,\\n        starting search from x_start with an exponentially growing step size.\\n        \\"\\"\\"\\n        x_prev = x_start\\n        f_prev = func(x_prev)\\n\\n        # Handle x_start being extremely close to a zero or the start of a flat region\\n        if abs(f_prev) < 1e-12: # Treat as a zero, search should start slightly past this\\n            x_prev += initial_step_size * 0.01 # Small step to move past current (known) zero\\n            f_prev = func(x_prev)\\n            if abs(f_prev) < 1e-12: # If still zero, might be identically zero or not oscillating.\\n                return None # Indicate no useful sign change can be found from here\\n\\n        current_step = initial_step_size\\n        max_search_x = x_start + max_interval_length # Limit how far we search\\n        \\n        while x_prev < max_search_x:\\n            x_curr = x_prev + current_step\\n            if x_curr >= max_search_x: # Don't overshoot max_search_x\\n                x_curr = max_search_x\\n            \\n            f_curr = func(x_curr)\\n\\n            # Check for sign change\\n            if np.sign(f_prev) != np.sign(f_curr) and f_prev != 0 and f_curr != 0:\\n                return (x_prev, x_curr)\\n            \\n            # Check if we landed directly on a zero (or very close)\\n            if abs(f_curr) < 1e-12:\\n                # If a zero is found, ensure we are not returning a point identical to x_start.\\n                if x_curr > x_start + np.finfo(float).eps * 100:\\n                    return (x_curr, x_curr) # Return a tiny interval to represent the zero\\n                else: # Found zero at or too close to x_start, continue search.\\n                    x_prev = x_curr + initial_step_size * 0.01 \\n                    f_prev = func(x_prev)\\n                    current_step = initial_step_size # Reset step size after a tiny jump\\n                    continue\\n\\n            # Exponentially increase step size for the next iteration\\n            current_step *= step_growth_factor\\n            if current_step > max_interval_length / 10.0: # Cap step size to prevent huge jumps.\\n                 current_step = max_interval_length / 10.0\\n            \\n            x_prev = x_curr\\n            f_prev = f_curr\\n\\n        return None # No sign change found within the search limits\\n\\n    # Parameters for zero-finding and Euler\\n    initial_search_step = 0.5 \\n    max_zeros_to_find = 500 # Max number of zero-defined segments to integrate\\n    \\n    # Euler parameters for zero-crossing method\\n    euler_abs_tol = 1e-12 # Tighter tolerance for this method\\n    euler_rel_tol = 1e-10\\n    min_segments_for_euler = 10 # Can be fewer terms than geometric method since already alternating\\n\\n    current_search_x = float(lower_limit)\\n    \\n    # Find initial zeros and integrate segments between them\\n    for i in range(max_zeros_to_find):\\n        bracket_interval = _find_next_sign_change_interval(integrand, current_search_x, initial_search_step)\\n        \\n        if bracket_interval is None:\\n            # No more zeros found, indicating end of oscillation or highly complex behavior.\\n            break\\n        \\n        next_zero = _find_zero_in_interval(integrand, bracket_interval[0], bracket_interval[1])\\n        \\n        # Ensure next_zero is valid and strictly greater than the last one to avoid infinite loops or tiny segments\\n        if next_zero is None or next_zero <= zeros[-1] + np.finfo(float).eps * 100:\\n            break\\n        \\n        zeros.append(next_zero)\\n        current_search_x = next_zero # Update search start for next iteration\\n\\n        # Integrate the segment between the last two found zeros\\n        seg_start_val = zeros[-2]\\n        seg_end_val = zeros[-1]\\n        \\n        if seg_end_val - seg_start_val < np.finfo(float).eps * 100: # Skip very tiny segments\\n            continue\\n\\n        try:\\n            seg_val, seg_err = _robust_quad_call(\\n                integrand, seg_start_val, seg_end_val,\\n                limit_val=500000, epsabs_val=1e-12, epsrel_val=1e-12 \\n            )\\n            segment_integrals.append(seg_val)\\n        except ValueError:\\n            # If a segment integral fails, sum previous good segments with infinite error.\\n            return np.sum(segment_integrals), np.inf \\n\\n    # If no segments were collected or too few for Euler, this method is not applicable.\\n    if not segment_integrals:\\n        raise ValueError(\\"No oscillation segments found or integrated.\\")\\n\\n    # Check if the series of segments is alternating; if not, Euler won't work well.\\n    # An alternating series is crucial for Euler acceleration to effectively sum.\\n    if len(segment_integrals) > 1:\\n        is_alternating = True\\n        for i in range(len(segment_integrals) - 1):\\n            if segment_integrals[i] * segment_integrals[i+1] >= 0 and abs(segment_integrals[i]) > euler_abs_tol * 0.01:\\n                is_alternating = False\\n                break\\n        if not is_alternating and len(segment_integrals) >= min_segments_for_euler:\\n            # If not alternating, Euler is not ideal for acceleration. Fail this method.\\n            raise ValueError(\\"Zero-crossing segments do not form an alternating series.\\")\\n\\n    # Apply Euler acceleration to the collected segment integrals\\n    euler_sum, euler_error = _apply_euler_acceleration(segment_integrals, euler_abs_tol, euler_rel_tol, min_segments_for_euler, 3) # Modified target_consecutive_converged\\n\\n    # Integrate the remaining tail (from the last zero to infinity)\\n    tail_sum = 0.0\\n    tail_err = 0.0\\n    if len(zeros) > 0 and zeros[-1] < np.inf:\\n        try:\\n            tail_sum, tail_err = _robust_quad_call(integrand, zeros[-1], np.inf, 500000, 1e-10, 1e-10)\\n        except ValueError:\\n            # If tail integration fails, return Euler sum with infinite error\\n            return euler_sum, np.inf \\n\\n    final_answer = euler_sum + tail_sum\\n    final_error = euler_error + tail_err\\n\\n    return final_answer, final_error\\n\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # Handle trivial case where limits are the same\\n    if lower_limit == upper_limit:\\n        return 0.0, 0.0\\n\\n    # --- Step 1: Tiered Attempts with scipy.integrate.quad() for ALL interval types ---\\n    # These attempts are for general-purpose convergence on any interval type.\\n    quad_attempts = [\\n        {'limit': 100000, 'epsabs': 1e-12, 'epsrel': 1e-12},\\n        {'limit': 200000, 'epsabs': 1e-13, 'epsrel': 1e-13},\\n        {'limit': 500000, 'epsabs': 1e-14, 'epsrel': 1e-14}\\n    ]\\n\\n    for attempt_params in quad_attempts:\\n        try:\\n            answer, error_estimate = _robust_quad_call(\\n                integrand, float(lower_limit), float(upper_limit),\\n                limit_val=attempt_params['limit'],\\n                epsabs_val=attempt_params['epsabs'],\\n                epsrel_val=attempt_params['epsrel']\\n            )\\n            return answer, error_estimate\\n        except ValueError:\\n            pass # Fallback to more specialized methods if current attempt fails\\n\\n    # --- Step 2: Handle Infinite Limits via Transformations or Splitting ---\\n    # At this stage, all direct quad calls failed.\\n    \\n    # Case: (-inf, inf)\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf).\\n        # Choosing 0 as the split point is a common heuristic.\\n        try:\\n            # Recursively call quadrature for the two new intervals.\\n            # The recursive calls will attempt _robust_quad_call first, then specialized methods.\\n            val1, err1 = quadrature(integrand, -np.inf, 0.0)\\n            val2, err2 = quadrature(integrand, 0.0, np.inf)\\n            \\n            # Explicitly propagate NaN/Inf from sub-integrals\\n            if np.isnan(val1) or np.isinf(val1) or np.isnan(val2) or np.isinf(val2):\\n                return np.nan, np.inf\\n            if np.isinf(err1) or np.isinf(err2):\\n                return val1 + val2, np.inf\\n            \\n            return val1 + val2, err1 + err2\\n        except Exception: \\n            return np.nan, np.inf\\n\\n    # Case: (-inf, b] where b is finite\\n    elif lower_limit == -np.inf and upper_limit != np.inf: \\n        # Transformation: x = -t. dx = -dt. Limits: x -> -inf => t -> inf; x -> upper_limit => t -> -upper_limit.\\n        # The integral becomes int_{inf}^{-upper_limit} f(-t) (-dt) = int_{-upper_limit}^{inf} f(-t) dt.\\n        # This converts it to a [finite_a, inf) problem, which is handled in the next block.\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t) \\n\\n        # Recursively call quadrature with the transformed integrand and new limits.\\n        val, err = quadrature(transformed_integrand_neg_inf, -float(upper_limit), np.inf)\\n        if np.isnan(val) or np.isinf(val) or np.isnan(err) or np.isinf(err):\\n            return np.nan, np.inf\\n        return val, err\\n    \\n    # --- Step 3: Specialized Methods for [a, inf) where 'a' is finite and previous attempts failed ---\\n    # At this point, we are specifically dealing with integrals of the form [lower_limit, inf).\\n    # This is the primary target for oscillatory integrands where standard quad fails.\\n\\n    if upper_limit == np.inf:\\n        # Strategy 1: Integration by zero crossings (preferred for strong oscillations)\\n        try:\\n            result, err = _integrate_oscillatory_by_zeros(integrand, lower_limit)\\n            # If this method returns a finite result and error, it's considered successful.\\n            if not (np.isnan(result) or np.isinf(result) or np.isnan(err) or np.isinf(err)):\\n                return result, err\\n        except Exception:\\n            # If the zero-crossing method fails entirely (e.g., no zeros found, brentq errors,\\n            # or it's not suitable for this function), we fall back.\\n            pass\\n\\n        # Strategy 2: Geometric Segment Summation (fallback if zero-crossing fails)\\n        try:\\n            result, err = _integrate_oscillatory_geometric_segments(integrand, lower_limit)\\n            return result, err\\n        except Exception:\\n            # If even the geometric segment method fails, the integral is likely problematic.\\n            return np.nan, np.inf\\n\\n    # Case: Finite [a, b] that quad failed on\\n    # For finite intervals, scipy.integrate.quad is the gold standard. If even its most\\n    # aggressive attempts fail, it suggests severe non-integrability, endpoint singularities,\\n    # or extremely pathological behavior that standard numerical integration is not designed for.\\n    # In such cases, returning NaN with infinite error is appropriate.\\n    elif upper_limit != np.inf: \\n        return np.nan, np.inf\\n\\n    # Fallback for any unhandled case (should not be reached if logic is complete)\\n    return np.nan, np.inf",
  "new_index": 860,
  "new_code": "# TODO: Implement the \`quadrature()\` function to numerically evaluate integrals.\\n\\nimport math\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\nfrom typing import Callable, Tuple\\n\\n# Helper for robust quad calls with custom tolerances and limits\\ndef _robust_quad_call(func: Callable[float, float], a: float, b: float, limit_val: int, epsabs_val: float, epsrel_val: float) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Calls scipy.integrate.quad with specified parameters and performs robust checks\\n    to ensure the result is reliable and meets the requested tolerance.\\n    \\"\\"\\"\\n    try:\\n        val, err = scipy.integrate.quad(func, a, b, limit=limit_val, epsabs=epsabs_val, epsrel=epsrel_val)\\n        \\n        # Immediate checks for problematic results (NaN, Inf). These signify hard failures.\\n        if np.isnan(val) or np.isinf(val) or \\\\\\n           np.isnan(err) or np.isinf(err):\\n            raise ValueError(\\"Scipy quad result is NaN or Inf.\\")\\n        \\n        # Crucial reliability check:\\n        # scipy.integrate.quad returns 'err' as its *estimate* of the absolute error.\\n        # It attempts to achieve \`err <= max(epsabs, abs(val) * epsrel)\`.\\n        # If the returned 'err' is *greater* than the requested tolerance, it indicates\\n        # that quad failed to meet the precision it was asked for.\\n        # We add a small absolute epsilon to the target tolerance to account for\\n        # floating-point inaccuracies in the comparison.\\n        requested_tolerance_achieved_by_quad = max(epsabs_val, abs(val) * epsrel_val)\\n        # Modified for more robust float comparison against the requested tolerance.\\n        if err > requested_tolerance_achieved_by_quad * (1 + 100 * np.finfo(float).eps):\\n            raise ValueError(f\\"Scipy quad failed to meet requested tolerance: returned_err={err:.2e}, requested_tol={requested_tolerance_achieved_by_quad:.2e}.\\")\\n        \\n        return val, err\\n    except Exception as e:\\n        # Catch any exception that might occur during the quad call or subsequent checks.\\n        raise ValueError(f\\"Scipy quad failed or result unreliable: {e}\\")\\n\\n# Helper for Euler acceleration\\ndef _apply_euler_acceleration(series_terms: list[float], euler_abs_tol: float, euler_rel_tol: float, min_terms_for_euler: int, target_consecutive_converged: int) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Applies Euler transformation to a series of terms to accelerate convergence.\\n    Returns the accelerated sum and an error estimate.\\n    \\"\\"\\"\\n    \\n    initial_sum_terms = np.sum(series_terms) if series_terms else 0.0\\n\\n    N_terms = len(series_terms)\\n    if N_terms < min_terms_for_euler:\\n        # Not enough terms for effective Euler acceleration.\\n        # Provide a conservative error estimate based on the sum of the last few terms.\\n        error_estimate_no_euler = np.sum(np.abs(series_terms[max(0, N_terms - 15):])) if N_terms > 0 else 0.0\\n        \\n        # Add a small relative or absolute error component for overall uncertainty.\\n        if initial_sum_terms != 0:\\n            error_estimate_no_euler = max(error_estimate_no_euler, abs(initial_sum_terms) * euler_rel_tol * 10)\\n        else:\\n            error_estimate_no_euler = max(error_estimate_no_euler, euler_abs_tol * 10)\\n        \\n        return initial_sum_terms, error_estimate_no_euler\\n    \\n    euler_current_sequence = np.array(series_terms, dtype=float)\\n    if not euler_current_sequence.size > 0:\\n        return initial_sum_terms, np.inf\\n\\n    euler_diagonal_values = [euler_current_sequence[0]]\\n    consecutive_converged_count = 0\\n\\n    try:\\n        max_euler_levels = N_terms - 1\\n        for m in range(max_euler_levels): \\n            # Ensure at least two terms for transformation to avoid IndexErrors.\\n            if len(euler_current_sequence) < 2: \\n                break\\n            \\n            # Compute the next level of Euler transformation: (T_m^(j-1) + T_{m+1}^{(j-1)}) / 2.\\n            new_euler_sequence_array = (euler_current_sequence[:-1] + euler_current_sequence[1:]) / 2.0\\n            euler_current_sequence = new_euler_sequence_array\\n            \\n            # Check if the sequence became empty or problematic after transformation.\\n            if len(euler_current_sequence) == 0 or np.isnan(euler_current_sequence[0]) or np.isinf(euler_current_sequence[0]): \\n                break\\n\\n            current_euler_val = euler_current_sequence[0] # The first term of the new sequence is a diagonal value.\\n            euler_diagonal_values.append(current_euler_val) \\n            \\n            # Check for convergence in the Euler diagonal values.\\n            if m > 0 and len(euler_diagonal_values) >= 2:\\n                prev_euler_val = euler_diagonal_values[-2]\\n                diff = abs(current_euler_val - prev_euler_val)\\n                \\n                # Convergence criteria:\\n                # 1. Relative convergence for values larger than absolute tolerance.\\n                # 2. Absolute convergence for values around or smaller than absolute tolerance.\\n                is_relative_converged = (abs(current_euler_val) > euler_abs_tol) and \\\\\\n                                         (diff < euler_rel_tol * abs(current_euler_val))\\n                is_absolute_converged = (abs(current_euler_val) <= euler_abs_tol) and \\\\\\n                                         (diff < euler_abs_tol * (1 + np.finfo(float).eps)) \\n                \\n                if is_relative_converged or is_absolute_converged:\\n                    consecutive_converged_count += 1\\n                else:\\n                    consecutive_converged_count = 0 \\n                \\n                # Modified: target_consecutive_converged reduced for faster practical convergence.\\n                if consecutive_converged_count >= target_consecutive_converged: \\n                    break \\n                \\n                # Check for strong divergence in the Euler diagonal.\\n                if m > 2 and abs(prev_euler_val) > euler_abs_tol * 0.01 and \\\\\\n                   abs(current_euler_val) > abs(prev_euler_val) * 100:\\n                    # If Euler diverges, fallback to the initial sum of terms, error inf.\\n                    return initial_sum_terms, np.inf\\n\\n    except Exception:\\n        # If any numerical instability or error occurs during Euler transformation,\\n        # return the initial sum of terms as the best available estimate, with high error.\\n        return initial_sum_terms, np.inf\\n\\n    final_euler_sum = euler_diagonal_values[-1] if len(euler_diagonal_values) > 0 else initial_sum_terms\\n    error_estimate = np.inf \\n\\n    if len(euler_diagonal_values) >= 2:\\n        last_diff_euler = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n        if consecutive_converged_count >= target_consecutive_converged:\\n            # If Euler process converged sufficiently, error is estimated by last difference or requested tolerances.\\n            error_estimate = max(last_diff_euler, \\n                                 euler_rel_tol * abs(final_euler_sum), \\n                                 euler_abs_tol) \\n        else:\\n            # If Euler did not meet the strict convergence criteria, provide a more conservative error estimate.\\n            error_estimate = max(last_diff_euler * 5, # Multiply last difference for conservatism.\\n                                 euler_rel_tol * abs(final_euler_sum) * 5, # Higher relative error.\\n                                 euler_abs_tol * 5) # Higher absolute error.\\n\\n    return final_euler_sum, error_estimate\\n\\n# Helper for [a, inf) integration using geometric segments and Euler acceleration (original code's method as fallback)\\ndef _integrate_oscillatory_geometric_segments(integrand: Callable[float, float], lower_limit: float) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Integrates from lower_limit to infinity by summing integrals over geometrically growing segments.\\n    Applies Euler acceleration to the sum of these segments.\\n    \\"\\"\\"\\n    current_segment_start = float(lower_limit)\\n    segment_growth_factor = 1.2 # Factor by which subsequent segments grow in length.\\n    \\n    # Adaptive initial segment length candidates. Trying multiple helps find a good first oscillation cycle.\\n    initial_segment_length_candidates = [math.pi / 2.0, 1.0, 0.5, 0.1, 0.01, 0.001] # Added smaller steps\\n    \\n    segment_integrals = [] # List to store the integral value of each segment.\\n    \\n    max_segments_to_compute = 30000 # Increased cap for extreme cases\\n    min_segments_for_euler = 20 # Minimum segments required for Euler acceleration to be applied.\\n\\n    prev_seg_val = None \\n    consistent_sign_count = 0 \\n    consecutive_decay_count = 0 \\n    \\n    euler_abs_tol = 1e-10\\n    euler_rel_tol = 1e-8\\n    segment_integration_tol = 1e-8 # Tightened tolerance for integrating individual segments.\\n\\n    # Integrate the first segment: Try different initial lengths.\\n    found_good_first_segment = False\\n    base_segment_length = initial_segment_length_candidates[0] \\n    \\n    for try_length in initial_segment_length_candidates:\\n        seg_end = current_segment_start + try_length\\n        if seg_end <= current_segment_start + np.finfo(float).eps * 100: \\n            continue\\n        try:\\n            seg_val, seg_err = _robust_quad_call(\\n                integrand, current_segment_start, seg_end,\\n                limit_val=500000, # Increased limit for segment integration\\n                epsabs_val=segment_integration_tol, epsrel_val=segment_integration_tol\\n            )\\n            found_good_first_segment = True\\n            base_segment_length = try_length \\n            break \\n        except ValueError:\\n            pass \\n    \\n    if not found_good_first_segment:\\n        # If no initial segment length produced a reliable result, the integral is likely problematic.\\n        return np.nan, np.inf \\n\\n    segment_integrals.append(seg_val)\\n    current_segment_start = seg_end\\n    prev_seg_val = seg_val \\n\\n    # Main loop for computing subsequent segments.\\n    for i in range(1, max_segments_to_compute): \\n        seg_start = current_segment_start\\n        seg_end = current_segment_start + base_segment_length * (segment_growth_factor ** i) \\n\\n        if seg_end - seg_start < np.finfo(float).eps * 100: \\n            break\\n\\n        try:\\n            seg_val, seg_err = _robust_quad_call(\\n                integrand, seg_start, seg_end,\\n                limit_val=500000, # Increased limit for segment integration\\n                epsabs_val=segment_integration_tol, epsrel_val=segment_integration_tol\\n            )\\n        except ValueError: \\n            return np.sum(segment_integrals), np.inf \\n\\n        segment_integrals.append(seg_val)\\n        current_segment_start = seg_end\\n\\n        # --- Early stopping and Euler suitability checks ---\\n        if abs(seg_val) > euler_abs_tol * 0.01:\\n            if seg_val * prev_seg_val >= 0: \\n                consistent_sign_count += 1\\n            else:\\n                consistent_sign_count = 0 \\n        else:\\n            consistent_sign_count = 0 \\n        \\n        # If the series appears non-alternating for a long sequence, Euler acceleration may not converge.\\n        if consistent_sign_count >= 10 and i >= min_segments_for_euler: # Increased from 5\\n            return np.sum(segment_integrals), np.inf \\n\\n        current_sum = np.sum(segment_integrals)\\n        if abs(seg_val) < (euler_abs_tol * 0.001) and \\\\\\n           (abs(seg_val) < (euler_rel_tol * 0.001 * abs(current_sum) if current_sum != 0 else euler_abs_tol * 0.001)): \\n            consecutive_decay_count += 1\\n            if consecutive_decay_count >= 15: # Increased from 10\\n                break \\n        else:\\n            consecutive_decay_count = 0\\n        \\n        # Check for strong divergence in terms (integral unlikely to converge).\\n        if i >= min_segments_for_euler and \\\\\\n           abs(prev_seg_val) > euler_abs_tol * 0.01 and \\\\\\n           abs(seg_val) > abs(prev_seg_val) * 100:\\n            return np.sum(segment_integrals), np.inf \\n\\n        prev_seg_val = seg_val\\n    \\n    # Apply Euler acceleration to the collected segment integrals\\n    return _apply_euler_acceleration(segment_integrals, euler_abs_tol, euler_rel_tol, min_segments_for_euler, 3) # Modified target_consecutive_converged\\n\\n# Helper for [a, inf) integration using zero crossings\\ndef _integrate_oscillatory_by_zeros(integrand: Callable[float, float], lower_limit: float) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Integrates from lower_limit to infinity by finding successive zero crossings of the integrand,\\n    integrating over these oscillation cycles, and applying Euler acceleration.\\n    \\"\\"\\"\\n    zeros = [float(lower_limit)]\\n    segment_integrals = []\\n    \\n    # Helper to find a zero within an interval [a, b]\\n    def _find_zero_in_interval(func, a, b):\\n        try:\\n            return scipy.optimize.brentq(func, a, b, xtol=1e-15, rtol=1e-15)\\n        except ValueError:\\n            return None\\n\\n    # Helper to find the next bracketing interval for a zero (Modified)\\n    def _find_next_sign_change_interval(func, x_start, initial_step_size=0.1, step_growth_factor=1.5, max_interval_length=1e6):\\n        \\"\\"\\"\\n        Finds an interval [a, b] such that func(a) and func(b) have opposite signs,\\n        starting search from x_start with an exponentially growing step size.\\n        \\"\\"\\"\\n        x_prev = x_start\\n        f_prev = func(x_prev)\\n\\n        # Handle x_start being extremely close to a zero or the start of a flat region\\n        if abs(f_prev) < 1e-12: # Treat as a zero, search should start slightly past this\\n            x_prev += initial_step_size * 0.01 # Small step to move past current (known) zero\\n            f_prev = func(x_prev)\\n            if abs(f_prev) < 1e-12: # If still zero, might be identically zero or not oscillating.\\n                return None # Indicate no useful sign change can be found from here\\n\\n        current_step = initial_step_size\\n        max_search_x = x_start + max_interval_length\\n        \\n        while x_prev < max_search_x:\\n            x_curr = x_prev + current_step\\n            if x_curr >= max_search_x: # Don't overshoot max_search_x\\n                x_curr = max_search_x\\n            \\n            f_curr = func(x_curr)\\n\\n            # Check for sign change\\n            if np.sign(f_prev) != np.sign(f_curr) and f_prev != 0 and f_curr != 0:\\n                return (x_prev, x_curr)\\n            \\n            # Check if we landed directly on a zero (or very close)\\n            if abs(f_curr) < 1e-12:\\n                # If a zero is found, ensure we are not returning a point identical to x_start.\\n                if x_curr > x_start + np.finfo(float).eps * 100:\\n                    return (x_curr, x_curr) # Return a tiny interval to represent the zero\\n                else: # Found zero at or too close to x_start, continue search.\\n                    x_prev = x_curr + initial_step_size * 0.01 \\n                    f_prev = func(x_prev)\\n                    current_step = initial_step_size # Reset step size after a tiny jump\\n                    continue\\n\\n            # Exponentially increase step size for the next iteration\\n            current_step *= step_growth_factor\\n            if current_step > max_interval_length / 10.0: # Cap step size to prevent huge jumps.\\n                 current_step = max_interval_length / 10.0\\n            \\n            x_prev = x_curr\\n            f_prev = f_curr\\n\\n        return None # No sign change found within the search limits\\n\\n    # Parameters for zero-finding and Euler\\n    initial_search_step = 0.5 \\n    max_zeros_to_find = 500 # Max number of zero-defined segments to integrate\\n    \\n    # Euler parameters for zero-crossing method\\n    euler_abs_tol = 1e-12 # Tighter tolerance for this method\\n    euler_rel_tol = 1e-10\\n    min_segments_for_euler = 10 # Can be fewer terms than geometric method since already alternating\\n\\n    current_search_x = float(lower_limit)\\n    \\n    # Find initial zeros and integrate segments between them\\n    for i in range(max_zeros_to_find):\\n        bracket_interval = _find_next_sign_change_interval(integrand, current_search_x, initial_search_step)\\n        \\n        if bracket_interval is None:\\n            # No more zeros found, indicating end of oscillation or highly complex behavior.\\n            break\\n        \\n        next_zero = _find_zero_in_interval(integrand, bracket_interval[0], bracket_interval[1])\\n        \\n        # Ensure next_zero is valid and strictly greater than the last one to avoid infinite loops or tiny segments\\n        if next_zero is None or next_zero <= zeros[-1] + np.finfo(float).eps * 100:\\n            break\\n        \\n        zeros.append(next_zero)\\n        current_search_x = next_zero # Update search start for next iteration\\n\\n        # Integrate the segment between the last two found zeros\\n        seg_start_val = zeros[-2]\\n        seg_end_val = zeros[-1]\\n        \\n        if seg_end_val - seg_start_val < np.finfo(float).eps * 100: # Skip very tiny segments\\n            continue\\n\\n        try:\\n            seg_val, seg_err = _robust_quad_call(\\n                integrand, seg_start_val, seg_end_val,\\n                limit_val=500000, epsabs_val=1e-12, epsrel_val=1e-12 # Tighter tolerances for zero-crossing integration\\n            )\\n            segment_integrals.append(seg_val)\\n        except ValueError:\\n            # If a segment integral fails, sum previous good segments with infinite error.\\n            return np.sum(segment_integrals), np.inf \\n\\n    # If no segments were collected or too few for Euler, this method is not applicable.\\n    if not segment_integrals:\\n        raise ValueError(\\"No oscillation segments found or integrated.\\")\\n\\n    # Check if the series of segments is alternating; if not, Euler won't work well.\\n    # An alternating series is crucial for Euler acceleration to effectively sum.\\n    if len(segment_integrals) > 1:\\n        is_alternating = True\\n        for i in range(len(segment_integrals) - 1):\\n            if segment_integrals[i] * segment_integrals[i+1] >= 0 and abs(segment_integrals[i]) > euler_abs_tol * 0.01:\\n                is_alternating = False\\n                break\\n        if not is_alternating and len(segment_integrals) >= min_segments_for_euler:\\n            # If not alternating, Euler is not ideal for acceleration. Fail this method.\\n            raise ValueError(\\"Zero-crossing segments do not form an alternating series.\\")\\n\\n    # Apply Euler acceleration to the collected segment integrals\\n    euler_sum, euler_error = _apply_euler_acceleration(segment_integrals, euler_abs_tol, euler_rel_tol, min_segments_for_euler, 3) # Modified target_consecutive_converged\\n\\n    # Integrate the remaining tail (from the last zero to infinity)\\n    tail_sum = 0.0\\n    tail_err = 0.0\\n    if len(zeros) > 0 and zeros[-1] < np.inf:\\n        try:\\n            tail_sum, tail_err = _robust_quad_call(integrand, zeros[-1], np.inf, 500000, 1e-10, 1e-10)\\n        except ValueError:\\n            # If tail integration fails, return Euler sum with infinite error\\n            return euler_sum, np.inf \\n\\n    final_answer = euler_sum + tail_sum\\n    final_error = euler_error + tail_err\\n\\n    return final_answer, final_error\\n\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # Handle trivial case where limits are the same\\n    if lower_limit == upper_limit:\\n        return 0.0, 0.0\\n\\n    # --- Step 1: Tiered Attempts with scipy.integrate.quad() for ALL interval types ---\\n    # These attempts are for general-purpose convergence on any interval type.\\n    quad_attempts = [\\n        {'limit': 100000, 'epsabs': 1e-12, 'epsrel': 1e-12},\\n        {'limit': 200000, 'epsabs': 1e-13, 'epsrel': 1e-13},\\n        {'limit': 500000, 'epsabs': 1e-14, 'epsrel': 1e-14}\\n    ]\\n\\n    for attempt_params in quad_attempts:\\n        try:\\n            answer, error_estimate = _robust_quad_call(\\n                integrand, float(lower_limit), float(upper_limit),\\n                limit_val=attempt_params['limit'],\\n                epsabs_val=attempt_params['epsabs'],\\n                epsrel_val=attempt_params['epsrel']\\n            )\\n            return answer, error_estimate\\n        except ValueError:\\n            pass # Fallback to more specialized methods if current attempt fails\\n\\n    # --- Step 2: Handle Infinite Limits via Transformations or Splitting ---\\n    # At this stage, all direct quad calls failed.\\n    \\n    # Case: (-inf, inf)\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf).\\n        # Choosing 0 as the split point is a common heuristic.\\n        try:\\n            # Recursively call quadrature for the two new intervals.\\n            # The recursive calls will attempt _robust_quad_call first, then specialized methods.\\n            val1, err1 = quadrature(integrand, -np.inf, 0.0)\\n            val2, err2 = quadrature(integrand, 0.0, np.inf)\\n            \\n            # Explicitly propagate NaN/Inf from sub-integrals\\n            if np.isnan(val1) or np.isinf(val1) or np.isnan(val2) or np.isinf(val2):\\n                return np.nan, np.inf\\n            if np.isinf(err1) or np.isinf(err2):\\n                return val1 + val2, np.inf\\n            \\n            return val1 + val2, err1 + err2\\n        except Exception: \\n            return np.nan, np.inf\\n\\n    # Case: (-inf, b] where b is finite\\n    elif lower_limit == -np.inf and upper_limit != np.inf: \\n        # Transformation: x = -t. dx = -dt. Limits: x -> -inf => t -> inf; x -> upper_limit => t -> -upper_limit.\\n        # The integral becomes int_{inf}^{-upper_limit} f(-t) (-dt) = int_{-upper_limit}^{inf} f(-t) dt.\\n        # This converts it to a [finite_a, inf) problem, which is handled in the next block.\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t) \\n\\n        # Recursively call quadrature with the transformed integrand and new limits.\\n        val, err = quadrature(transformed_integrand_neg_inf, -float(upper_limit), np.inf)\\n        if np.isnan(val) or np.isinf(val) or np.isnan(err) or np.isinf(err):\\n            return np.nan, np.inf\\n        return val, err\\n    \\n    # --- Step 3: Specialized Methods for [a, inf) where 'a' is finite and previous attempts failed ---\\n    # At this point, we are specifically dealing with integrals of the form [lower_limit, inf).\\n    # This is the primary target for oscillatory integrands where standard quad fails.\\n\\n    if upper_limit == np.inf:\\n        # Strategy 1: Integration by zero crossings (preferred for strong oscillations)\\n        try:\\n            result, err = _integrate_oscillatory_by_zeros(integrand, lower_limit)\\n            # If this method returns a finite result and error, it's considered successful.\\n            if not (np.isnan(result) or np.isinf(result) or np.isnan(err) or np.isinf(err)):\\n                return result, err\\n        except Exception:\\n            # If the zero-crossing method fails entirely (e.g., no zeros found, brentq errors,\\n            # or it's not suitable for this function), we fall back.\\n            pass\\n\\n        # Strategy 2: Geometric Segment Summation (fallback if zero-crossing fails)\\n        try:\\n            result, err = _integrate_oscillatory_geometric_segments(integrand, lower_limit)\\n            return result, err\\n        except Exception:\\n            # If even the geometric segment method fails, the integral is likely problematic.\\n            return np.nan, np.inf\\n\\n    # Case: Finite [a, b] that quad failed on\\n    # For finite intervals, scipy.integrate.quad is the gold standard. If even its most\\n    # aggressive attempts fail, it suggests severe non-integrability, endpoint singularities,\\n    # or extremely pathological behavior that standard numerical integration is not designed for.\\n    # In such cases, returning NaN with infinite error is appropriate.\\n    elif upper_limit != np.inf: \\n        return np.nan, np.inf\\n\\n    # Fallback for any unhandled case (should not be reached if logic is complete)\\n    return np.nan, np.inf"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
