<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": 378.0,
  "old_code": "import math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\n\\n# Helper function to find roots (zero-crossings)\\ndef _find_successive_roots(func: Callable[[float], float], x0: float, max_roots: int = 200, initial_step: float = math.pi) -> list[float]:\\n    \\"\\"\\"\\n    Finds a specified number of successive roots (zero-crossings) of a function\\n    starting from x0.\\n\\n    Args:\\n        func: The function for which to find roots.\\n        x0: The starting point for the root search.\\n        max_roots: The maximum number of roots to find.\\n        initial_step: An initial step size for bracketing roots.\\n\\n    Returns:\\n        A list of found roots, in increasing order.\\n    \\"\\"\\"\\n    roots = []\\n    current_x = float(x0)\\n    \\n    # Try to find the very first root after x0.\\n    # Nudge current_x slightly if it's exactly at a root or very close, to ensure progression.\\n    if abs(func(current_x)) < 1e-12:\\n        current_x += 1e-9 # Nudge to move past the current root\\n        \\n    try:\\n        sign_at_start = np.sign(func(current_x))\\n        if sign_at_start == 0: # If function is flat/zero near current_x\\n            # Probe a bit further to get a definitive sign\\n            sign_at_start = np.sign(func(current_x + 1e-6))\\n            if sign_at_start == 0:\\n                return [] # Likely not an oscillatory function with clear roots\\n                \\n        next_x_search_upper_bound = current_x + initial_step\\n        # Expand the search range for the first root more aggressively if needed\\n        # Limit initial search to avoid getting stuck on non-oscillatory but decaying functions\\n        initial_search_multiplier = 1.0\\n        max_initial_search_range = initial_step * 20 # Increased range\\n        \\n        while np.sign(func(next_x_search_upper_bound)) == sign_at_start and \\\\\\n              (next_x_search_upper_bound - current_x) < max_initial_search_range:\\n            initial_search_multiplier *= 1.5 # Exponentially increase step\\n            next_x_search_upper_bound = current_x + initial_step * initial_search_multiplier\\n            \\n            if initial_step * initial_search_multiplier > 1e6: # Prevent excessively large steps for the first root\\n                return []\\n        \\n        if np.sign(func(next_x_search_upper_bound)) != sign_at_start:\\n            bracket = [current_x, next_x_search_upper_bound]\\n            # Using xtol/rtol suitable for float64 precision\\n            # For root finding, slightly looser tolerances might be acceptable, as quad can refine\\n            root_result = scipy.optimize.root_scalar(func, bracket=bracket, method='brentq', xtol=1e-14, rtol=1e-14) # Slightly looser\\n            if root_result.converged:\\n                roots.append(root_result.root)\\n                current_x = root_result.root\\n            else:\\n                return [] # Could not find first root\\n        else: # Did not find a sign change in the initial aggressive search\\n            return []\\n\\n    except Exception:\\n        return [] # Failed to find the first root\\n\\n    # Find subsequent roots\\n    for _ in range(max_roots - len(roots)):\\n        try:\\n            # Heuristic for the next search interval: adapt based on previous root distances\\n            # or a default step if not enough previous roots.\\n            if len(roots) >= 2:\\n                # Use the last root distance as a guess\\n                current_root_distance = roots[-1] - roots[-2]\\n                next_guess_interval = current_root_distance * 1.0 # Assume constant period as default, no shrinking/growing factor\\n            else:\\n                next_guess_interval = initial_step / 2 # Default if only one root found\\n            \\n            # Ensure positive and not too small\\n            if next_guess_interval <= 1e-10: \\n                next_guess_interval = 1e-6 # Minimum step size\\n\\n            # Avoid re-finding the current root, start search strictly after it\\n            search_start = current_x + 1e-12 \\n            \\n            # Prevent infinite loop if root finding becomes difficult or function flattens\\n            max_single_root_search_dist = next_guess_interval * 50 # Adapt max search range\\n            if max_single_root_search_dist < 1e-5: # Ensure a minimum search range\\n                max_single_root_search_dist = 1e-5 \\n            \\n            temp_search_x = search_start + next_guess_interval * 0.1 # Start probing with a fraction of the guess\\n            if temp_search_x <= search_start: # Avoid getting stuck if initial probe is too small\\n                temp_search_x = search_start + 1e-6 \\n                \\n            sign_at_start_for_next_search = np.sign(func(search_start))\\n            \\n            search_multiplier = 1.0 # Multiplier for expanding the bracket for the next root\\n            \\n            while np.sign(func(temp_search_x)) == sign_at_start_for_next_search and \\\\\\n                  (temp_search_x - search_start) < max_single_root_search_dist:\\n                \\n                temp_search_x = search_start + next_guess_interval * search_multiplier\\n                search_multiplier *= 1.2 # Gradually increase the search step\\n                \\n                if temp_search_x <= search_start: # Avoid infinite loop if step size becomes problematic\\n                    temp_search_x = search_start + 1e-6 # Fallback to tiny step\\n                    if np.sign(func(temp_search_x)) == sign_at_start_for_next_search: # If still no sign change with tiny step\\n                        break # Give up on this root\\n\\n            if np.sign(func(temp_search_x)) != sign_at_start_for_next_search: # Found a sign change\\n                bracket = [search_start, temp_search_x]\\n                root_result = scipy.optimize.root_scalar(func, bracket=bracket, method='brentq', xtol=1e-14, rtol=1e-14) # Slightly looser\\n                if root_result.converged:\\n                    if root_result.root > current_x + 1e-12: # Ensure root is distinct and greater\\n                        roots.append(root_result.root)\\n                        current_x = root_result.root\\n                    else: # Found same root or smaller, implies no more distinct roots in this direction\\n                        break \\n                else:\\n                    break # Root finding failed for this iteration\\n            else:\\n                break # No sign change found within reasonable distance\\n\\n        except Exception:\\n            break # General failure in root finding loop\\n\\n    return roots\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    try:\\n        answer, error_estimate = scipy.integrate.quad(\\n            integrand, lower_limit, upper_limit,\\n            limit=50000,      # Increased max subintervals for initial attempt\\n            epsabs=1e-15,   # Absolute error tolerance, aligned with float64 precision\\n            epsrel=1e-15    # Relative error tolerance, aligned with float64 precision\\n        )\\n\\n        # Check for NaN or Inf results/errors from quad, or if error is too high\\n        if (np.isnan(answer) or np.isinf(answer) or\\n            np.isnan(error_estimate) or np.isinf(error_estimate) or\\n            (abs(answer) > 1e-8 and error_estimate / abs(answer) > 1e-7) or # Slightly adjusted relative error threshold\\n            (abs(answer) <= 1e-8 and error_estimate > 1e-16)): # Slightly adjusted absolute error threshold for small answers\\n            pass # If unreliable, proceed to specialized method\\n        else:\\n            return answer, error_estimate\\n    except Exception:\\n        pass # If quad fails or raises an error, fall back to a more robust method\\n\\n    # --- Step 2: Handle Infinite Limits for Specialized Method ---\\n    # Convert all integrals to the form [a, inf) for uniform processing.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        val1, err1 = quadrature(integrand, -np.inf, 0)\\n        val2, err2 = quadrature(integrand, 0, np.inf)\\n        \\n        if np.isnan(val1) or np.isnan(val2) or np.isinf(err1) or np.isinf(err2):\\n            return np.nan, np.inf\\n        \\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-upper_limit}^{inf} f(-t) dt\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t)\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] where initial quad failed.\\n        # This implies a very difficult finite integral. Try again with aggressive quad and roots.\\n        try:\\n            # Attempt to find roots within the finite interval to assist quad\\n            # Limit max_roots to avoid excessive computation for finite intervals\\n            roots_in_interval = _find_successive_roots(integrand, lower_limit, max_roots=1000, initial_step=(upper_limit - lower_limit) / 10 if (upper_limit - lower_limit) > 0 else math.pi)\\n            roots_in_interval = [r for r in roots_in_interval if lower_limit < r < upper_limit] # Ensure roots are strictly within interval\\n\\n            if roots_in_interval:\\n                answer, error_estimate = scipy.integrate.quad(\\n                    integrand, lower_limit, upper_limit,\\n                    points=roots_in_interval, limit=60000, epsabs=1e-16, epsrel=1e-16 # More aggressive limits\\n                )\\n            else:\\n                answer, error_estimate = scipy.integrate.quad(\\n                    integrand, lower_limit, upper_limit,\\n                    limit=60000, epsabs=1e-16, epsrel=1e-16 # More aggressive limits\\n                )\\n\\n            if (np.isnan(answer) or np.isinf(answer) or\\n                np.isnan(error_estimate) or np.isinf(error_estimate) or\\n                (abs(answer) > 1e-9 and error_estimate / abs(answer) > 1e-8) or # Even stricter error for finite intervals\\n                (abs(answer) <= 1e-9 and error_estimate > 1e-17)): \\n                raise ValueError(\\"Aggressive quad for finite interval failed.\\")\\n            return answer, error_estimate\\n        except Exception:\\n            return np.nan, np.inf # Indicate failure for difficult finite integral\\n\\n    # --- Step 3: Specialized Method for [a, inf) ---\\n    # This part applies if we're dealing with [a, inf) and initial quad failed.\\n    # First, try to find roots and use quad with points. If not, fallback to Euler.\\n    try:\\n        # Step 3a: Find roots and use scipy.integrate.quad with points\\n        # For infinite integrals, finding some initial roots can greatly help quad.\\n        \\n        # Try to find more roots for better guidance to quad\\n        # Increased max_roots to potentially find more oscillations\\n        all_found_roots = _find_successive_roots(integrand, lower_limit, max_roots=2000, initial_step=math.pi) \\n        \\n        # Use roots to define 'points' for quad. Quad can handle the infinite tail.\\n        # It's important to provide enough points but not an overwhelming number if\\n        # the oscillation becomes extremely dense later.\\n        # Let's use a dynamic number of roots, up to a certain density or count.\\n        roots_to_provide_to_quad = []\\n        if all_found_roots:\\n            # Provide up to the first N roots, or roots within a certain initial range.\\n            # This balances providing guidance without making quad's work explode for high frequencies.\\n            # A good heuristic is to provide roots over the first few 'periods' or a fixed range.\\n            # For \`sin(x^2)\`, periods shrink, so roots become dense. Let's limit the absolute range for roots.\\n            max_root_value_for_points = lower_limit + 200 * math.pi # Provide roots up to 200*pi from start\\n            roots_to_provide_to_quad = [r for r in all_found_roots if r < max_root_value_for_points]\\n            \\n            # Ensure we don't provide too many points; quad has its own limits\\n            if len(roots_to_provide_to_quad) > 1000:\\n                roots_to_provide_to_quad = roots_to_provide_to_quad[:1000] # Cap the number of points\\n\\n        if roots_to_provide_to_quad:\\n            # Pass roots as 'points' to quad. Quad is robust in handling the infinite tail\\n            answer, error_estimate = scipy.integrate.quad(\\n                integrand, lower_limit, np.inf,\\n                points=roots_to_provide_to_quad, limit=60000, epsabs=1e-16, epsrel=1e-16 # More aggressive limits\\n            )\\n\\n            if (np.isnan(answer) or np.isinf(answer) or\\n                np.isnan(error_estimate) or np.isinf(error_estimate) or\\n                (abs(answer) > 1e-9 and error_estimate / abs(answer) > 1e-8) or # Stricter error threshold\\n                (abs(answer) <= 1e-9 and error_estimate > 1e-17)): \\n                raise ValueError(\\"Quad with roots failed or unreliable.\\") # Fallback to Euler\\n            return answer, error_estimate\\n        else:\\n            raise ValueError(\\"No significant roots found for initial guiding, fall back to Euler.\\") # Proceed to Euler\\n    except Exception:\\n        # Step 3b: Fallback to Euler Acceleration (fixed pi segments)\\n        # This part applies if root-guided quad failed or couldn't find roots.\\n        current_segment_start = float(lower_limit)\\n        segment_length = math.pi # Fixed heuristic for general oscillation\\n\\n        segment_integrals = []\\n        \\n        max_segments_to_compute = 30000 # Increased number of segments for Euler (from 15000)\\n        min_segments_for_euler = 100 # Increased minimum segments for stability (from 50)\\n\\n        prev_seg_val = None\\n        consistent_sign_count = 0 \\n        consecutive_decay_count = 0 \\n\\n        for i in range(max_segments_to_compute):\\n            seg_start = current_segment_start\\n            seg_end = current_segment_start + segment_length\\n\\n            # Ensure the segment has non-zero length.\\n            if seg_end <= seg_start + 1e-12: \\n                break \\n\\n            try:\\n                # Use aggressive quad parameters for segment integration\\n                seg_val, seg_err = scipy.integrate.quad(\\n                    integrand, seg_start, seg_end,\\n                    limit=20000, epsabs=1e-15, epsrel=1e-15\\n                )\\n                \\n                # If segment integral fails to converge to a small error, this whole method might be unsuitable\\n                if np.isnan(seg_val) or np.isinf(seg_val) or seg_err > 1e-12: # Stricter segment error\\n                    raise ValueError(f\\"Segment integration failed at {i}-th segment with val={seg_val}, err={seg_err}\\")\\n\\n                segment_integrals.append(seg_val)\\n                current_segment_start = seg_end \\n\\n                # --- Checks for suitability of Euler transformation and early convergence ---\\n                if i > 0:\\n                    # Check for alternating signs (crucial for Euler)\\n                    # Only check sign if term is not effectively zero (to avoid issues with 0*0 or 0*positive being >=0)\\n                    if seg_val * prev_seg_val >= 0 and abs(seg_val) > 1e-12 and abs(prev_seg_val) > 1e-12: \\n                        consistent_sign_count += 1\\n                    else:\\n                        consistent_sign_count = 0 \\n                    \\n                    # If signs consistently do not alternate after a few initial terms, Euler transformation is not suitable.\\n                    if consistent_sign_count >= 50 and i >= min_segments_for_euler: # Increased threshold for non-alternating check (from 25)\\n                        return np.sum(segment_integrals), np.inf # High error, as Euler won't help much (potential divergence)\\n\\n                    # Check for rapid decay: if terms are consistently very small, implies convergence\\n                    if abs(seg_val) < (1e-15 * abs(prev_seg_val) + 1e-25): # Tighter relative and absolute threshold for decay\\n                        consecutive_decay_count += 1\\n                        if consecutive_decay_count >= 30: # Increased number of consecutive tiny segments (from 20)\\n                            # If the sum of previous terms is already very small, we can exit early.\\n                            if abs(np.sum(segment_integrals[:-consecutive_decay_count])) < 1e-10: # Tighter total sum threshold for early exit\\n                                break \\n                    else:\\n                        consecutive_decay_count = 0\\n                    \\n                    # Check for strong divergence: if terms start to grow significantly after an initial phase\\n                    # Use a larger factor for robust divergence detection\\n                    if i >= min_segments_for_euler and abs(seg_val) > abs(segment_integrals[-2]) * 2000 and abs(segment_integrals[-2]) > 1e-12: # Increased divergence factor (from 1500)\\n                        return np.sum(segment_integrals), np.inf \\n                \\n                prev_seg_val = seg_val\\n\\n            except Exception as e:\\n                # If any segment integration fails, return the sum of successful segments\\n                # with a high error to indicate uncertainty.\\n                return np.sum(segment_integrals), np.inf\\n\\n        # --- Step 4: Apply Series Acceleration (Euler's Transformation) ---\\n        N = len(segment_integrals)\\n        if N < min_segments_for_euler: # Not enough terms to apply Euler reliably\\n            return np.sum(segment_integrals), np.inf \\n\\n        euler_sums = np.array(segment_integrals, dtype=float)\\n        \\n        euler_diagonal_values = [euler_sums[0]] \\n        consecutive_converged_count = 0\\n        target_consecutive_converged = 5 # Increased required consecutive convergence (from 4)\\n\\n        try:\\n            max_euler_levels = N - 1\\n\\n            for m in range(max_euler_levels): \\n                if len(euler_sums) < 2: \\n                    break\\n                \\n                new_euler_sums = (euler_sums[:-1] + euler_sums[1:]) / 2.0\\n                euler_sums = new_euler_sums\\n                \\n                euler_diagonal_values.append(euler_sums[0]) \\n                \\n                # Check for convergence of the Euler sum by comparing the last few diagonal elements\\n                if m > 0:\\n                    diff = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n                    # Stricter relative convergence for non-zero values\\n                    # Stricter absolute convergence for values very close to zero\\n                    if (abs(euler_diagonal_values[-1]) > 1e-16 and diff < 1e-15 * abs(euler_diagonal_values[-1])) or \\\\\\n                       (abs(euler_diagonal_values[-1]) <= 1e-16 and diff < 1e-22): # Even stricter absolute convergence (from 5e-21)\\n                        consecutive_converged_count += 1\\n                    else:\\n                        consecutive_converged_count = 0 \\n                    \\n                    if consecutive_converged_count >= target_consecutive_converged:\\n                        break\\n\\n                    # Check for strong divergence in Euler diagonal (e.g., values grow significantly)\\n                    if m > 2 and abs(euler_diagonal_values[-1]) > abs(euler_diagonal_values[-2]) * 2000 and abs(euler_diagonal_values[-2]) > 1e-12: # Increased divergence factor (from 1500)\\n                        final_answer = euler_diagonal_values[-2] if len(euler_diagonal_values) >= 2 else np.sum(segment_integrals)\\n                        return final_answer, np.inf\\n\\n        except Exception:\\n            pass # Continue to return best available answer if Euler acceleration process breaks\\n\\n        final_answer = euler_diagonal_values[-1] if len(euler_diagonal_values) > 0 else np.sum(segment_integrals)\\n        \\n        # Estimate error: difference between the last two diagonal terms (if available) or the last segment magnitude\\n        if len(euler_diagonal_values) >= 2:\\n            error_estimate = max(abs(euler_diagonal_values[-1] - euler_diagonal_values[-2]), 1e-15 * abs(final_answer), 1e-22) # Tighter relative error for Euler, and minimum absolute error (from 5e-21)\\n        elif len(segment_integrals) > 0:\\n            error_estimate = abs(segment_integrals[-1]) * 100 # Conservative error if Euler did not fully converge\\n            if np.isnan(error_estimate) or np.isinf(error_estimate):\\n                error_estimate = np.inf\\n        else:\\n            error_estimate = np.inf # No segments successfully integrated\\n\\n        # Final check for NaN or Inf in the answer\\n        if np.isnan(final_answer) or np.isinf(final_answer):\\n            return np.nan, np.inf\\n\\n        return final_answer, error_estimate",
  "new_index": 386,
  "new_code": "# TODO: Implement the \`quadrature()\` function to numerically evaluate integrals.\\n\\nimport math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\n\\n# Helper function to find roots (zero-crossings)\\ndef _find_successive_roots(func: Callable[[float], float], x0: float, max_roots: int = 2000, initial_step: float = math.pi) -> list[float]:\\n    \\"\\"\\"\\n    Finds a specified number of successive roots (zero-crossings) of a function\\n    starting from x0.\\n\\n    Args:\\n        func: The function for which to find roots.\\n        x0: The starting point for the root search.\\n        max_roots: The maximum number of roots to find.\\n        initial_step: An initial step size for bracketing the very first root.\\n\\n    Returns:\\n        A list of found roots, in increasing order.\\n    \\"\\"\\"\\n    roots = []\\n    current_x = float(x0)\\n    \\n    _eps = np.finfo(float).eps # Machine epsilon for float64\\n    ROOT_XTOL = 10 * _eps # Tolerance for root location\\n    ROOT_RTOL = 10 * _eps # Relative tolerance for root location\\n\\n    # Nudge current_x slightly if it's exactly at a root or very close, to ensure progression.\\n    if abs(func(current_x)) < 10 * _eps: \\n        current_x += 10 * _eps # Nudge to move past potential current root\\n        \\n    try:\\n        # Find the first root after x0.\\n        sign_at_start = np.sign(func(current_x))\\n        if sign_at_start == 0: \\n            # Probe a bit further to get a definitive sign\\n            sign_at_start = np.sign(func(current_x + 10 * _eps))\\n            if sign_at_start == 0:\\n                # Still zero, assume flat and no oscillations or already past.\\n                return [] \\n        \\n        # Aggressive search for the first root. Expand upper bound until sign change or max range.\\n        search_lower_bound = current_x\\n        search_upper_bound = current_x + initial_step # Start with the provided initial_step\\n        max_first_root_search_range = initial_step * 100 # Allow substantial range for the first root\\n\\n        while np.sign(func(search_upper_bound)) == sign_at_start and \\\\\\n              (search_upper_bound - search_lower_bound) < max_first_root_search_range:\\n            search_upper_bound += max(initial_step * 0.1, (search_upper_bound - search_lower_bound) * 0.5) # Grow upper bound faster\\n            \\n            if search_upper_bound <= search_lower_bound: # Prevent stagnation\\n                search_upper_bound = search_lower_bound + 10 * _eps # Fallback to small step\\n                \\n        if np.sign(func(search_upper_bound)) != sign_at_start:\\n            bracket = [search_lower_bound, search_upper_bound]\\n            root_result = scipy.optimize.root_scalar(func, bracket=bracket, method='brentq', xtol=ROOT_XTOL, rtol=ROOT_RTOL)\\n            if root_result.converged:\\n                if root_result.root > x0 + 10 * _eps: # Ensure the found root is truly after x0\\n                    roots.append(root_result.root)\\n                    current_x = root_result.root\\n                else:\\n                    return [] # Root is not strictly after x0 (e.g., too close, or error)\\n            else:\\n                return [] # Could not find first root\\n        else:\\n            return [] # Did not find a sign change for the first root within range\\n\\n    except Exception: # Catch any errors during the first root search\\n        return []\\n\\n    # Find subsequent roots\\n    for _ in range(max_roots - len(roots)):\\n        try:\\n            # Adapt probe step based on the last found root distance, if available.\\n            if len(roots) >= 2:\\n                last_root_distance = roots[-1] - roots[-2]\\n                next_probe_step = max(initial_step * 0.01, last_root_distance * 0.8) # Adjust slightly down, or use small fraction of initial_step\\n            else:\\n                next_probe_step = initial_step * 0.1 # Default if only one root found\\n\\n            # Ensure probe step is reasonable\\n            next_probe_step = max(next_probe_step, 10 * _eps) # Minimum step to avoid stagnation\\n            \\n            search_lower_bound = current_x + 10 * _eps # Start search strictly after current_x\\n\\n            # If search_lower_bound is exactly a root, nudge it.\\n            sign_at_lower_bound = np.sign(func(search_lower_bound))\\n            if sign_at_lower_bound == 0:\\n                search_lower_bound += 10 * _eps\\n                sign_at_lower_bound = np.sign(func(search_lower_bound))\\n                if sign_at_lower_bound == 0: # Still zero, implies flat, no more roots.\\n                    break\\n\\n            search_upper_bound = search_lower_bound + next_probe_step\\n            max_single_root_search_range = next_probe_step * 200 # Allow substantial search range for one root\\n            \\n            while np.sign(func(search_upper_bound)) == sign_at_lower_bound and \\\\\\n                  (search_upper_bound - search_lower_bound) < max_single_root_search_range:\\n                search_upper_bound += max(next_probe_step * 0.1, (search_upper_bound - search_lower_bound) * 0.5) # Grow search upper bound faster\\n                if search_upper_bound <= search_lower_bound: # Prevent stagnation\\n                    search_upper_bound = search_lower_bound + 10 * _eps\\n\\n            if np.sign(func(search_upper_bound)) != sign_at_lower_bound: # Found a sign change\\n                bracket = [search_lower_bound, search_upper_bound]\\n                root_result = scipy.optimize.root_scalar(func, bracket=bracket, method='brentq', xtol=ROOT_XTOL, rtol=ROOT_RTOL)\\n                if root_result.converged:\\n                    if root_result.root > current_x + 10 * _eps: # Ensure root is distinct and strictly greater\\n                        roots.append(root_result.root)\\n                        current_x = root_result.root\\n                    else: # Found same root or too close, implies no more distinct roots in this direction\\n                        break \\n                else:\\n                    break # Root finding failed for this iteration\\n            else:\\n                break # No sign change found within reasonable distance\\n\\n        except Exception: # General failure in root finding loop\\n            break\\n\\n    return roots\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n    _eps = np.finfo(float).eps # Machine epsilon for float64 precision\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    try:\\n        # Use more robust but still accurate tolerances for initial quad attempt\\n        answer, error_estimate = scipy.integrate.quad(\\n            integrand, lower_limit, upper_limit,\\n            limit=50000,      # Max subintervals\\n            epsabs=1e-12,   # Absolute error tolerance\\n            epsrel=1e-12    # Relative error tolerance\\n        )\\n\\n        # Check for NaN or Inf results/errors from quad, or if error is too high\\n        if (np.isnan(answer) or np.isinf(answer) or\\n            np.isnan(error_estimate) or np.isinf(error_estimate) or\\n            (abs(answer) > 1e-8 and error_estimate / abs(answer) > 1e-7) or\\n            (abs(answer) <= 1e-8 and error_estimate > 1e-16)):\\n            pass # If unreliable, proceed to specialized method\\n        else:\\n            return answer, error_estimate\\n    except Exception:\\n        pass # If quad fails or raises an error, fall back to a more robust method\\n\\n    # --- Step 2: Handle Infinite Limits for Specialized Method ---\\n    # Convert all integrals to the form [a, inf) for uniform processing.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        val1, err1 = quadrature(integrand, -np.inf, 0)\\n        val2, err2 = quadrature(integrand, 0, np.inf)\\n        \\n        if np.isnan(val1) or np.isnan(val2) or np.isinf(err1) or np.isinf(err2):\\n            return np.nan, np.inf\\n        \\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-upper_limit}^{inf} f(-t) dt\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t)\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] where initial quad failed.\\n        # This implies a very difficult finite integral. Try again with aggressive quad and roots.\\n        try:\\n            # Attempt to find roots within the finite interval to assist quad\\n            # Limit max_roots to avoid excessive computation for finite intervals\\n            roots_in_interval = _find_successive_roots(integrand, lower_limit, max_roots=1000, initial_step=(upper_limit - lower_limit) / 10 if (upper_limit - lower_limit) > 0 else math.pi)\\n            roots_in_interval = [r for r r in roots_in_interval if lower_limit < r < upper_limit] # Ensure roots are strictly within interval\\n\\n            if roots_in_interval:\\n                answer, error_estimate = scipy.integrate.quad(\\n                    integrand, lower_limit, upper_limit,\\n                    points=roots_in_interval, limit=60000, epsabs=1e-12, epsrel=1e-12 # More aggressive limits\\n                )\\n            else:\\n                answer, error_estimate = scipy.integrate.quad(\\n                    integrand, lower_limit, upper_limit,\\n                    limit=60000, epsabs=1e-12, epsrel=1e-12 # More aggressive limits\\n                )\\n\\n            if (np.isnan(answer) or np.isinf(answer) or\\n                np.isnan(error_estimate) or np.isinf(error_estimate) or\\n                (abs(answer) > 1e-9 and error_estimate / abs(answer) > 1e-8) or\\n                (abs(answer) <= 1e-9 and error_estimate > 1e-17)):\\n                raise ValueError(\\"Aggressive quad for finite interval failed.\\")\\n            return answer, error_estimate\\n        except Exception:\\n            return np.nan, np.inf # Indicate failure for difficult finite integral\\n\\n    # --- Step 3: Specialized Method for [a, inf) ---\\n    # This part applies if we're dealing with [a, inf) and initial quad failed.\\n    # First, try to find roots and use quad with points. If not, fallback to Euler.\\n    try:\\n        # Step 3a: Find roots and use scipy.integrate.quad with points\\n        # For infinite integrals, finding some initial roots can greatly help quad.\\n        \\n        # Try to find more roots for better guidance to quad (max_roots=2000 from user)\\n        all_found_roots = _find_successive_roots(integrand, lower_limit, max_roots=2000, initial_step=math.pi) \\n        \\n        # Use roots to define 'points' for quad. Quad can handle the infinite tail.\\n        roots_to_provide_to_quad = []\\n        if all_found_roots:\\n            # Provide roots within a certain initial absolute range, to avoid overly dense points.\\n            max_root_value_for_points = lower_limit + 1000.0 # Provide roots up to this absolute value\\n            roots_to_provide_to_quad = [r for r in all_found_roots if r < max_root_value_for_points]\\n            \\n            # Ensure we don't provide too many points; quad has its own limits\\n            if len(roots_to_provide_to_quad) > 2000: # Cap the number of points (user value)\\n                roots_to_provide_to_quad = roots_to_provide_to_quad[:2000] \\n\\n        if roots_to_provide_to_quad:\\n            # Pass roots as 'points' to quad.\\n            answer, error_estimate = scipy.integrate.quad(\\n                integrand, lower_limit, np.inf,\\n                points=roots_to_provide_to_quad, limit=60000, epsabs=1e-12, epsrel=1e-12 # More aggressive limits\\n            )\\n\\n            if (np.isnan(answer) or np.isinf(answer) or\\n                np.isnan(error_estimate) or np.isinf(error_estimate) or\\n                (abs(answer) > 1e-9 and error_estimate / abs(answer) > 1e-8) or\\n                (abs(answer) <= 1e-9 and error_estimate > 1e-17)): \\n                raise ValueError(\\"Quad with roots failed or unreliable.\\") # Fallback to Euler\\n            return answer, error_estimate\\n        else:\\n            raise ValueError(\\"No significant roots found for initial guiding, fall back to Euler.\\") # Proceed to Euler\\n    except Exception:\\n        # Step 3b: Fallback to Euler Acceleration (fixed pi segments)\\n        current_segment_start = float(lower_limit)\\n        segment_length = math.pi # Fixed heuristic for general oscillation\\n\\n        segment_integrals = []\\n        \\n        max_segments_to_compute = 30000 # Increased number of segments for Euler (from user)\\n        min_segments_for_euler = 100 # Minimum segments for stability (from user)\\n\\n        prev_seg_val = None\\n        consistent_sign_count = 0 \\n        consecutive_decay_count = 0 \\n\\n        for i in range(max_segments_to_compute):\\n            seg_start = current_segment_start\\n            seg_end = current_segment_start + segment_length\\n\\n            # Ensure the segment has non-zero length.\\n            if seg_end <= seg_start + 10 * _eps: \\n                break \\n\\n            try:\\n                # Use robust quad parameters for segment integration\\n                seg_val, seg_err = scipy.integrate.quad(\\n                    integrand, seg_start, seg_end,\\n                    limit=20000, epsabs=1e-12, epsrel=1e-12\\n                )\\n                \\n                # If segment integral fails to converge to a small error, this whole method might be unsuitable\\n                if np.isnan(seg_val) or np.isinf(seg_val) or seg_err > 1e-10: # Looser segment error threshold for robustness\\n                    raise ValueError(f\\"Segment integration failed at {i}-th segment with val={seg_val}, err={seg_err}\\")\\n\\n                segment_integrals.append(seg_val)\\n                current_segment_start = seg_end \\n\\n                # --- Checks for suitability of Euler transformation and early convergence ---\\n                if i > 0:\\n                    # Check for alternating signs (crucial for Euler)\\n                    # Only check sign if term is not effectively zero (to avoid issues with 0*0 or 0*positive being >=0)\\n                    if seg_val * prev_seg_val >= 0 and abs(seg_val) > 1e-12 and abs(prev_seg_val) > 1e-12: \\n                        consistent_sign_count += 1\\n                    else:\\n                        consistent_sign_count = 0 \\n                    \\n                    # If signs consistently do not alternate after a few initial terms, Euler transformation is not suitable.\\n                    if consistent_sign_count >= 50 and i >= min_segments_for_euler: \\n                        return np.sum(segment_integrals), np.inf # High error, as Euler won't help much (potential divergence)\\n\\n                    # Check for rapid decay: if terms are consistently very small, implies convergence\\n                    if abs(seg_val) < (1e-14 * abs(prev_seg_val) + 1e-22): # Tighter relative and absolute threshold for decay\\n                        consecutive_decay_count += 1\\n                        if consecutive_decay_count >= 20: # Quicker early exit for decay (changed from 30)\\n                            # If the sum of previous terms is already very small, we can exit early.\\n                            if abs(np.sum(segment_integrals[:-consecutive_decay_count])) < 1e-8: # Tighter total sum threshold for early exit (changed from 1e-10)\\n                                break \\n                    else:\\n                        consecutive_decay_count = 0\\n                    \\n                    # Check for strong divergence: if terms start to grow significantly after an initial phase\\n                    if i >= min_segments_for_euler and abs(seg_val) > abs(segment_integrals[-2]) * 500 and abs(segment_integrals[-2]) > 1e-12: # More aggressive divergence detection (changed from 2000)\\n                        return np.sum(segment_integrals), np.inf \\n                \\n                prev_seg_val = seg_val\\n\\n            except Exception as e:\\n                # If any segment integration fails, return the sum of successful segments\\n                # with a high error to indicate uncertainty.\\n                return np.sum(segment_integrals), np.inf\\n\\n        # --- Step 4: Apply Series Acceleration (Euler's Transformation) ---\\n        N = len(segment_integrals)\\n        if N < min_segments_for_euler: # Not enough terms to apply Euler reliably\\n            return np.sum(segment_integrals), np.inf \\n\\n        euler_sums = np.array(segment_integrals, dtype=float)\\n        \\n        euler_diagonal_values = [euler_sums[0]] \\n        consecutive_converged_count = 0\\n        target_consecutive_converged = 5 # Required consecutive convergence (from user)\\n\\n        # Define convergence thresholds relative to machine epsilon\\n        euler_relative_convergence_threshold = 50 * _eps\\n        euler_absolute_convergence_threshold = 1e-18 # Absolute minimum convergence (more realistic than 1e-22)\\n\\n        try:\\n            max_euler_levels = N - 1\\n\\n            for m in range(max_euler_levels): \\n                if len(euler_sums) < 2: \\n                    break\\n                \\n                new_euler_sums = (euler_sums[:-1] + euler_sums[1:]) / 2.0\\n                euler_sums = new_euler_sums\\n                \\n                euler_diagonal_values.append(euler_sums[0]) \\n                \\n                # Check for convergence of the Euler sum by comparing the last few diagonal elements\\n                if m > 0:\\n                    diff = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n                    # Stricter relative convergence for non-zero values\\n                    # Stricter absolute convergence for values very close to zero\\n                    if (abs(euler_diagonal_values[-1]) > _eps and diff < euler_relative_convergence_threshold * abs(euler_diagonal_values[-1])) or \\\\\\n                       (abs(euler_diagonal_values[-1]) <= _eps and diff < euler_absolute_convergence_threshold):\\n                        consecutive_converged_count += 1\\n                    else:\\n                        consecutive_converged_count = 0 \\n                    \\n                    if consecutive_converged_count >= target_consecutive_converged:\\n                        break\\n\\n                    # Check for strong divergence in Euler diagonal\\n                    if m > 2 and abs(euler_diagonal_values[-1]) > abs(euler_diagonal_values[-2]) * 500 and abs(euler_diagonal_values[-2]) > 1e-12:\\n                        final_answer = euler_diagonal_values[-2] if len(euler_diagonal_values) >= 2 else np.sum(segment_integrals)\\n                        return final_answer, np.inf\\n\\n        except Exception:\\n            pass # Continue to return best available answer if Euler acceleration process breaks\\n\\n        final_answer = euler_diagonal_values[-1] if len(euler_diagonal_values) > 0 else np.sum(segment_integrals)\\n        \\n        # Estimate error: difference between the last two diagonal terms (if available) or the last segment magnitude\\n        if len(euler_diagonal_values) >= 2:\\n            error_estimate = max(abs(euler_diagonal_values[-1] - euler_diagonal_values[-2]), euler_relative_convergence_threshold * abs(final_answer), euler_absolute_convergence_threshold)\\n        elif len(segment_integrals) > 0:\\n            error_estimate = abs(segment_integrals[-1]) * 100 # Conservative error if Euler did not fully converge\\n            if np.isnan(error_estimate) or np.isinf(error_estimate):\\n                error_estimate = np.inf\\n        else:\\n            error_estimate = np.inf # No segments successfully integrated\\n\\n        # Final check for NaN or Inf in the answer\\n        if np.isnan(final_answer) or np.isinf(final_answer):\\n            return np.nan, np.inf\\n\\n        return final_answer, error_estimate"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
