<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": 508.0,
  "old_code": "# TODO: Implement the \`quadrature()\` function to numerically evaluate integrals.\\n\\nimport math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # Helper for robust quad calls with custom tolerances and limits\\n    def _robust_quad_call(func, a, b, limit_val, epsabs_val, epsrel_val, points=None):\\n        try:\\n            val, err = scipy.integrate.quad(\\n                func, a, b,\\n                limit=limit_val,\\n                epsabs=epsabs_val,\\n                epsrel=epsrel_val,\\n                points=points\\n            )\\n            \\n            # Check for NaN/Inf results from quad\\n            is_nan_inf = np.isnan(val) or np.isinf(val) or \\\\\\n                         np.isnan(err) or np.isinf(err)\\n            \\n            is_error_too_high = False\\n            if not is_nan_inf:\\n                # Target error is max(epsabs, epsrel * abs(val))\\n                target_error = max(epsabs_val, epsrel_val * abs(val))\\n                # If actual error is significantly higher than target error, consider it failed convergence.\\n                if err > target_error * 5: # Factor of 5 for robustness\\n                    is_error_too_high = True\\n            \\n            if is_nan_inf or is_error_too_high:\\n                raise ValueError(\\"Quad result deemed unreliable or poor convergence.\\")\\n            return val, err\\n        except Exception as e:\\n            # Catch all exceptions from scipy.integrate.quad and _robust_quad_call logic\\n            raise ValueError(f\\"scipy.integrate.quad failed: {e}\\")\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    # Attempt with higher limit and tighter tolerances for a more robust first try.\\n    try:\\n        answer, error_estimate = _robust_quad_call(\\n            integrand, lower_limit, upper_limit,\\n            limit_val=100000, epsabs_val=1e-12, epsrel_val=1e-12 # More robust initial tolerances\\n        )\\n        return answer, error_estimate\\n    except ValueError:\\n        pass # Fallback to more specialized methods if initial attempt fails\\n\\n    # --- Step 2: Handle Infinite Limits via Transformations or Splitting ---\\n    # Convert all integrals to [finite_a, inf) or [finite_a, finite_b]\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        val1, err1 = quadrature(integrand, -np.inf, 0)\\n        val2, err2 = quadrature(integrand, 0, np.inf)\\n        \\n        # Propagate failure if any sub-integral is problematic.\\n        if np.isnan(val1) or np.isnan(val2) or np.isinf(err1) or np.isinf(err2):\\n            return np.nan, np.inf\\n        \\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transformation: x -> -t, dx -> -dt. Integral becomes int_{-upper_limit}^{inf} f(-t) dt\\n        # This converts it to a [finite_a, inf) problem, which will be handled by segment summation.\\n        def transformed_integrand_neg_inf(t):\\n            try:\\n                return integrand(-t)\\n            except Exception:\\n                return 0.0\\n\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] (finite interval where initial quad failed)\\n        # For finite intervals, scipy.integrate.quad is the best general tool.\\n        # If even aggressive initial attempts fail for a finite integral, it's typically\\n        # due to non-integrability, endpoint singularities, or extreme oscillations not\\n        # addressed by standard quad rules, which are beyond the scope of this general\\n        # infinite-oscillatory problem.\\n        return np.nan, np.inf\\n\\n    # --- Step 3: Specialized Method for [a, inf) (finite 'a') where previous attempts failed ---\\n    # At this point, we are dealing with integrals of the form [lower_limit, inf),\\n    # where lower_limit is finite, and initial quad failed.\\n\\n    # Primary strategy for oscillatory integrands on infinite domains: Segment Summation with Euler Acceleration.\\n    # The transformations like x=1/t or x=a+(1-u)/u are *not* used here. They are detrimental\\n    # for oscillatory integrands as they introduce artificial non-integrable singularities\\n    # at the transformed endpoint (t=0 or u=0).\\n\\n    current_segment_start = float(lower_limit)\\n    # Heuristic for segment length: starts reasonably, grows exponentially.\\n    # A slightly larger growth factor to reach larger x values faster.\\n    segment_growth_factor = 1.1 # Increased from 1.05\\n    current_segment_length = max(math.pi / 2.0, 1.0) # Start with a reasonable length (related to pi)\\n    \\n    segment_integrals = []\\n    \\n    max_segments_to_compute = 5000 # Reduced from 10000, as segments grow faster\\n    min_segments_for_euler = 50 # Reduced from 100, apply Euler earlier if possible\\n\\n    prev_seg_val = None\\n    consistent_sign_count = 0 \\n    consecutive_decay_count = 0 \\n    \\n    # Tolerances for convergence in Euler method. Tighter for higher precision.\\n    euler_abs_tol = 1e-11 # Tightened from 1e-10\\n    euler_rel_tol = 1e-9 # Tightened from 1e-8\\n\\n    for i in range(max_segments_to_compute):\\n        seg_start = current_segment_start\\n        seg_end = current_segment_start + current_segment_length\\n\\n        if seg_end - seg_start < 1e-12: # Ensure meaningful segment length\\n            break \\n\\n        try:\\n            # Integrate each segment using scipy.integrate.quad with slightly tighter tolerances.\\n            # Increased \`limit\` for quad within segments to handle more oscillations.\\n            seg_val, seg_err = scipy.integrate.quad(\\n                integrand, seg_start, seg_end,\\n                limit=20000, epsabs=1e-11, epsrel=1e-10 # Tighter tolerances and higher limit for segments\\n            )\\n            \\n            # If segment integration is problematic (NaN/Inf, or high error),\\n            # return sum of collected segments with infinite error.\\n            if np.isnan(seg_val) or np.isinf(seg_val) or seg_err > 1e-6:\\n                if len(segment_integrals) > 0:\\n                    return np.sum(segment_integrals), np.inf \\n                else:\\n                    return np.nan, np.inf\\n\\n            segment_integrals.append(seg_val)\\n            current_segment_start = seg_end\\n            current_segment_length *= segment_growth_factor\\n\\n            # --- Early stopping and Euler suitability checks ---\\n            if i > 0:\\n                # Check for consistent non-alternating signs. Euler works best on alternating series.\\n                # If series is not alternating for many terms, Euler might not accelerate well.\\n                if seg_val * prev_seg_val >= 0 and abs(seg_val) > euler_abs_tol * 0.1: \\n                    consistent_sign_count += 1\\n                else:\\n                    consistent_sign_count = 0 \\n                \\n                if consistent_sign_count >= 100 and i >= min_segments_for_euler: \\n                    # Not an alternating series, Euler might not be suitable here.\\n                    return np.sum(segment_integrals), np.inf \\n\\n                # Check for rapid decay of terms indicating convergence without Euler acceleration.\\n                if abs(seg_val) < (euler_abs_tol * 0.01) and \\\\\\n                   (abs(seg_val) < (euler_rel_tol * 0.01 * abs(np.sum(segment_integrals)) + euler_abs_tol * 0.01)): \\n                    consecutive_decay_count += 1\\n                    if consecutive_decay_count >= 5: # Reduced from 10\\n                        break # Enough decay, stop collecting segments\\n                else:\\n                    consecutive_decay_count = 0\\n                \\n                # Check for strong divergence in terms (integral unlikely to converge).\\n                if i >= min_segments_for_euler and abs(seg_val) > abs(segment_integrals[-2]) * 1000 and abs(segment_integrals[-2]) > euler_abs_tol * 0.1: \\n                    return np.sum(segment_integrals), np.inf \\n\\n            prev_seg_val = seg_val\\n\\n        except Exception:\\n            # If segment integration failed for any reason, return the sum of good segments.\\n            if len(segment_integrals) > 0:\\n                return np.sum(segment_integrals), np.inf\\n            else:\\n                return np.nan, np.inf\\n\\n    # Initial sum of collected segments if Euler fails or not enough terms.\\n    initial_sum_segments = np.sum(segment_integrals) if segment_integrals else 0.0\\n    \\n    # Apply Euler's Transformation for series acceleration\\n    N_segments = len(segment_integrals)\\n    if N_segments < min_segments_for_euler:\\n        # Not enough terms for reliable Euler transformation.\\n        return initial_sum_segments, np.inf \\n\\n    # Implement Euler's transformation efficiently using numpy array operations\\n    # The Euler transform is applied to the sequence of terms, assuming it's alternating\\n    euler_sums = np.array(segment_integrals, dtype=float)\\n    euler_diagonal_values = [euler_sums[0]]\\n    consecutive_converged_count = 0\\n    target_consecutive_converged = 4 # Reduced from 5\\n\\n    try:\\n        max_euler_levels = N_segments - 1\\n\\n        for m in range(max_euler_levels): \\n            if len(euler_sums) < 2:\\n                break\\n            \\n            # Compute the next level of Euler transformation (averaging adjacent terms)\\n            new_euler_sums_len = len(euler_sums) - 1\\n            new_euler_sums_array = (euler_sums[:new_euler_sums_len] + euler_sums[1:new_euler_sums_len+1]) / 2.0\\n            euler_sums = new_euler_sums_array\\n            \\n            current_euler_val = euler_sums[0]\\n            euler_diagonal_values.append(current_euler_val) \\n            \\n            # Check for convergence in the Euler diagonal.\\n            if m > 0 and len(euler_diagonal_values) >= 2:\\n                prev_euler_val = euler_diagonal_values[-2]\\n                diff = abs(current_euler_val - prev_euler_val)\\n                \\n                # Convergence criteria: difference very small relatively OR absolutely.\\n                if (abs(current_euler_val) > euler_abs_tol and diff < euler_rel_tol * abs(current_euler_val)) or \\\\\\n                   (abs(current_euler_val) <= euler_abs_tol and diff < euler_abs_tol * 0.1): \\n                    consecutive_converged_count += 1\\n                else:\\n                    consecutive_converged_count = 0 \\n                \\n                if consecutive_converged_count >= target_consecutive_converged:\\n                    break\\n                \\n                # Check for strong divergence in Euler diagonal (transformation becoming unstable).\\n                if m > 2 and abs(current_euler_val) > abs(prev_euler_val) * 1000 and abs(prev_euler_val) > euler_abs_tol * 0.1: \\n                    # If Euler diverges, fallback to sum of segments as best guess, error inf.\\n                    return initial_sum_segments, np.inf\\n\\n    except Exception:\\n        # If any numerical instability occurs during Euler transformation,\\n        # return the sum of segments as the best available estimate, with high error.\\n        return initial_sum_segments, np.inf\\n\\n    # Final result from Euler transformation (last value on the diagonal)\\n    final_answer = euler_diagonal_values[-1] if len(euler_diagonal_values) > 0 else initial_sum_segments\\n    \\n    # Calculate error estimate based on Euler convergence.\\n    error_estimate = np.inf # Default error\\n\\n    if len(euler_diagonal_values) >= 2:\\n        last_diff_euler = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n        # If the process converged sufficiently according to strict criteria\\n        if consecutive_converged_count >= target_consecutive_converged:\\n            error_estimate = max(last_diff_euler, \\n                                 euler_rel_tol * abs(final_answer), \\n                                 euler_abs_tol) \\n        else:\\n            # If not strictly converged, but the Euler transformation ran and\\n            # produced a sequence of values, use the last difference as a heuristic for error.\\n            # Capped to avoid over-optimism.\\n            error_estimate = min(np.inf, last_diff_euler * 5) # Reduced heuristic multiplier from 10 to 5\\n            if abs(final_answer) < euler_abs_tol * 10: # If result is near zero, ensure abs error is not too small\\n                error_estimate = max(error_estimate, euler_abs_tol * 0.1)\\n            elif abs(final_answer) > euler_abs_tol * 10: # If result is non-zero, ensure relative error is not too small\\n                 error_estimate = max(error_estimate, euler_rel_tol * abs(final_answer) * 0.1)\\n\\n    # Final check for NaN/Inf results from any stage.\\n    if np.isnan(final_answer) or np.isinf(final_answer):\\n        return np.nan, np.inf\\n\\n    return final_answer, error_estimate",
  "new_index": 522,
  "new_code": "import math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # Helper for robust quad calls with custom tolerances and limits\\n    def _robust_quad_call(func, a, b, limit_val, epsabs_val, epsrel_val, points=None):\\n        try:\\n            val, err = scipy.integrate.quad(\\n                func, a, b,\\n                limit=limit_val,\\n                epsabs=epsabs_val,\\n                epsrel=epsrel_val,\\n                points=points\\n            )\\n            \\n            # Check for NaN/Inf results from quad\\n            is_nan_inf = np.isnan(val) or np.isinf(val) or \\\\\\n                         np.isnan(err) or np.isinf(err)\\n            \\n            is_error_too_high = False\\n            if not is_nan_inf:\\n                # Target error is max(epsabs, epsrel * abs(val))\\n                target_error = max(epsabs_val, epsrel_val * abs(val))\\n                # If actual error is significantly higher than target error, consider it failed convergence.\\n                if err > target_error * 5: # Factor of 5 for robustness\\n                    is_error_too_high = True\\n            \\n            if is_nan_inf or is_error_too_high:\\n                raise ValueError(\\"Quad result deemed unreliable or poor convergence.\\")\\n            return val, err\\n        except Exception as e:\\n            # Catch all exceptions from scipy.integrate.quad and _robust_quad_call logic\\n            raise ValueError(f\\"scipy.integrate.quad failed: {e}\\")\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    # Attempt with higher limit and tighter tolerances for a more robust first try.\\n    try:\\n        # A higher limit is helpful for more complex integrands\\n        answer, error_estimate = _robust_quad_call(\\n            integrand, lower_limit, upper_limit,\\n            limit_val=100000, epsabs_val=1e-12, epsrel_val=1e-12 # More robust initial tolerances\\n        )\\n        return answer, error_estimate\\n    except ValueError:\\n        pass # Fallback to more specialized methods if initial attempt fails\\n\\n    # --- Step 2: Handle Infinite Limits via Transformations or Splitting ---\\n    # Convert all integrals to [finite_a, inf) or [finite_a, finite_b]\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, split_point] and [split_point, inf)\\n        # Use 0 as the split point if it's within the original range, or pick a finite point.\\n        # Here 0 is generally fine unless the integrand has a known issue at 0.\\n        split_point = 0.0\\n        \\n        val1, err1 = quadrature(integrand, -np.inf, split_point)\\n        val2, err2 = quadrature(integrand, split_point, np.inf)\\n        \\n        # Propagate failure if any sub-integral is problematic.\\n        if np.isnan(val1) or np.isnan(val2) or np.isinf(err1) or np.isinf(err2):\\n            return np.nan, np.inf\\n        \\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transformation: x -> -t, dx -> -dt. Integral becomes int_{-upper_limit}^{inf} f(-t) dt\\n        # This converts it to a [finite_a, inf) problem, which will be handled by segment summation.\\n        def transformed_integrand_neg_inf(t):\\n            try:\\n                return integrand(-t)\\n            except Exception:\\n                # If evaluation fails, it's likely outside the defined domain or problematic.\\n                # Returning NaN is more robust for failed integrand evaluation.\\n                return np.nan \\n\\n        # The new lower limit is -upper_limit\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] (finite interval where initial quad failed)\\n        # For finite intervals, scipy.integrate.quad is the best general tool.\\n        # If even aggressive initial attempts fail for a finite integral, it's typically\\n        # due to non-integrability, endpoint singularities, or extreme oscillations not\\n        # addressed by standard quad rules, which are beyond the scope of this general\\n        # infinite-oscillatory problem.\\n        # Given it reached here, the first _robust_quad_call already failed,\\n        # so returning NaN/Inf is appropriate.\\n        return np.nan, np.inf\\n\\n    # --- Step 3: Specialized Method for [a, inf) (finite 'a') where previous attempts failed ---\\n    # At this point, we are dealing with integrals of the form [lower_limit, inf),\\n    # where lower_limit is finite, and initial quad failed.\\n\\n    # Primary strategy for oscillatory integrands on infinite domains: Segment Summation with Euler Acceleration.\\n    # The transformations like x=1/t or x=a+(1-u)/u are *not* used here. They are detrimental\\n    # for oscillatory integrands as they introduce artificial non-integrable singularities\\n    # at the transformed endpoint (t=0 or u=0).\\n\\n    segment_integrals = []\\n    \\n    # --- Zero-crossing guided initial segmentation ---\\n    zero_crossings = []\\n    try:\\n        # Search for first few zero-crossings to better define initial segments\\n        # Heuristic search for zero-crossings\\n        search_start_val = float(lower_limit)\\n        search_step = math.pi / 2.0 # A common oscillation period\\n        num_crossings_to_find = 15 # Number of crossings to use as initial points\\n        max_search_range = 100 * search_step # Don't search too far for crossings\\n        \\n        # Ensure search_start_val is not already problematic (e.g. at a singularity)\\n        # Try a slight offset if the initial point leads to an exception or NaN.\\n        try:\\n            val_at_start = integrand(search_start_val)\\n            if np.isnan(val_at_start) or np.isinf(val_at_start):\\n                 search_start_val += 1e-6 # Offset slightly\\n        except Exception:\\n            search_start_val += 1e-6 # Move slightly past potential singularity\\n            \\n        current_x = search_start_val\\n        \\n        # We need at least two distinct points to form a bracket for root_scalar\\n        # Initial bracket for root search should be non-zero length and distinct points.\\n        prev_f_val = None\\n        try:\\n            prev_f_val = integrand(current_x)\\n        except Exception:\\n            pass # continue without initial f_val if it fails\\n\\n        for _ in range(num_crossings_to_find * 2): # Try more steps than crossings needed\\n            next_x_search = current_x + search_step\\n            if next_x_search > search_start_val + max_search_range:\\n                break # Stop searching if too far\\n\\n            try:\\n                # Get the value at next_x_search\\n                f_next_val = integrand(next_x_search)\\n                \\n                # Try to find a root using brentq if a sign change is detected\\n                # Check for sign change after both values are obtained and not NaN/Inf\\n                if prev_f_val is not None and \\\\\\n                   not (np.isnan(prev_f_val) or np.isinf(prev_f_val) or np.isnan(f_next_val) or np.isinf(f_next_val)) and \\\\\\n                   (prev_f_val * f_next_val < 0): # Check for sign change\\n                    \\n                    # Ensure current_x and next_x_search are distinct and valid for a bracket\\n                    if current_x < next_x_search and abs(next_x_search - current_x) > 1e-9: # A small threshold for distinctness\\n                        root_result = scipy.optimize.root_scalar(integrand, bracket=[current_x, next_x_search], method='brentq', xtol=1e-12) # Tighter xtol\\n                        if root_result.converged:\\n                            # Add root only if it's distinct from the last one found and current_x\\n                            if not zero_crossings or (abs(root_result.root - zero_crossings[-1]) > 1e-8 and abs(root_result.root - current_x) > 1e-8):\\n                                zero_crossings.append(root_result.root)\\n                            current_x = root_result.root # Start next search from the found root\\n                            prev_f_val = integrand(current_x) # Update prev_f_val for next iteration\\n                        else:\\n                            current_x = next_x_search\\n                            prev_f_val = f_next_val # No root found in this interval, move on\\n                    else:\\n                        current_x = next_x_search\\n                        prev_f_val = f_next_val # Bracket invalid, move on\\n                else: # No sign change or problematic values, move on\\n                    current_x = next_x_search\\n                    prev_f_val = f_next_val\\n            except Exception: # Errors during integrand evaluation (e.g., domain errors)\\n                current_x = next_x_search # Move on\\n                prev_f_val = None # Reset prev_f_val as it's unreliable\\n\\n            if len(zero_crossings) >= num_crossings_to_find:\\n                break\\n            \\n    except Exception:\\n        zero_crossings = [] # If finding zero crossings fails, proceed without them\\n\\n    # Define segments based on zero crossings if found, otherwise use initial heuristic.\\n    integration_points = [float(lower_limit)]\\n    if zero_crossings:\\n        # Filter out crossings that are too close to each other or to the lower_limit\\n        # Also ensure they are after the current lower limit.\\n        for zc in zero_crossings:\\n            if zc > integration_points[-1] + 1e-8: # Ensure distinct and forward\\n                integration_points.append(zc)\\n    \\n    current_segment_start = float(lower_limit)\\n    \\n    # Heuristic for segment length for segments after zero-crossing defined ones\\n    segment_growth_factor = 1.1 # Increased from 1.05\\n    current_heuristic_segment_length = max(math.pi / 2.0, 1.0) # Start with a reasonable length (related to pi)\\n    \\n    max_segments_to_compute = 5000 # Reduced from 10000, as segments grow faster\\n    min_segments_for_euler = 50 # Apply Euler earlier if possible\\n\\n    prev_seg_val = None\\n    consistent_sign_count = 0 \\n    consecutive_decay_count = 0 \\n    \\n    # Tolerances for convergence in Euler method. Tighter for higher precision.\\n    euler_abs_tol = 1e-12 # Tightened further for Euler convergence\\n    euler_rel_tol = 1e-10 # Tightened further for Euler convergence\\n\\n    # Integrate the segments\\n    for i in range(max_segments_to_compute):\\n        seg_start = current_segment_start\\n        \\n        # Use zero-crossing points for initial segments\\n        if len(integration_points) > 1 and seg_start < integration_points[-1] - 1e-9:\\n            # Find the next integration point\\n            next_point_idx = np.searchsorted(integration_points, seg_start + 1e-9)\\n            if next_point_idx < len(integration_points) and integration_points[next_point_idx] > seg_start:\\n                seg_end = integration_points[next_point_idx]\\n            else: # All specific points exhausted, or next point is not valid/distinct, switch to heuristic length\\n                seg_end = seg_start + current_heuristic_segment_length\\n        else: # No more specific points or none were found, use heuristic length\\n            seg_end = seg_start + current_heuristic_segment_length\\n\\n        if seg_end - seg_start < 1e-12: # Ensure meaningful segment length\\n            # If segment becomes too small, it indicates convergence or issue.\\n            # If already small, and Euler hasn't converged, it might be an unresolvable issue.\\n            if len(segment_integrals) > min_segments_for_euler:\\n                # If we've collected enough segments for Euler, try to proceed.\\n                break \\n            else: # Too small segment and not enough for Euler, implies issue.\\n                return np.nan, np.inf\\n\\n        try:\\n            # Integrate each segment using scipy.integrate.quad with slightly tighter tolerances.\\n            # Increased \`limit\` for quad within segments to handle more oscillations.\\n            seg_val, seg_err = scipy.integrate.quad(\\n                integrand, seg_start, seg_end,\\n                limit=20000, epsabs=1e-13, epsrel=1e-11 # Tighter epsabs/epsrel for segment integrals\\n            )\\n            \\n            # If segment integration is problematic (NaN/Inf, or high error compared to its value),\\n            # return sum of collected segments with infinite error.\\n            if np.isnan(seg_val) or np.isinf(seg_val) or \\\\\\n               (abs(seg_val) > euler_abs_tol and seg_err > 1e-5 * abs(seg_val)) or \\\\\\n               (abs(seg_val) <= euler_abs_tol and seg_err > euler_abs_tol * 0.1): \\n                if len(segment_integrals) > 0:\\n                    return np.sum(segment_integrals), np.inf \\n                else:\\n                    return np.nan, np.inf\\n\\n            segment_integrals.append(seg_val)\\n            current_segment_start = seg_end\\n            \\n            # Only grow segment length if we're past the zero-crossing defined segments\\n            if not zero_crossings or seg_end >= integration_points[-1] - 1e-9: # If all explicit points consumed\\n                current_heuristic_segment_length *= segment_growth_factor\\n\\n            # --- Early stopping and Euler suitability checks ---\\n            if i > 0:\\n                # Check for consistent non-alternating signs. Euler works best on alternating series.\\n                # If series is not alternating for many terms, Euler might not accelerate well.\\n                # (abs(seg_val) > euler_abs_tol * 0.1) condition prevents checking sign for terms that are effectively zero.\\n                if seg_val * prev_seg_val >= 0 and abs(seg_val) > euler_abs_tol * 0.1: \\n                    consistent_sign_count += 1\\n                else:\\n                    consistent_sign_count = 0 \\n                \\n                if consistent_sign_count >= 150 and i >= min_segments_for_euler: # If not strictly alternating for many terms\\n                    break # Stop and sum directly. (Euler likely won't help much)\\n\\n                # Check for rapid decay of terms indicating convergence without Euler acceleration.\\n                # Added relative decay check to be more robust.\\n                if (abs(seg_val) < (euler_abs_tol * 0.001)) and \\\\\\n                   (abs(seg_val) < (euler_rel_tol * 0.001 * abs(np.sum(segment_integrals)))): \\n                    consecutive_decay_count += 1\\n                    if consecutive_decay_count >= 10: # If terms are consistently very small\\n                        break # Enough decay, stop collecting segments and sum\\n\\n                else:\\n                    consecutive_decay_count = 0\\n                \\n                # Check for strong divergence in terms (integral unlikely to converge).\\n                if i >= min_segments_for_euler and abs(seg_val) > abs(segment_integrals[-2]) * 10000 and abs(segment_integrals[-2]) > euler_abs_tol * 0.1: # Increased factor for clear divergence\\n                    return np.sum(segment_integrals), np.inf \\n\\n            prev_seg_val = seg_val\\n\\n        except Exception:\\n            # If segment integration failed for any reason, return the sum of good segments.\\n            # If no segments were collected, return NaN.\\n            if len(segment_integrals) > 0:\\n                return np.sum(segment_integrals), np.inf\\n            else:\\n                return np.nan, np.inf\\n\\n    # Initial sum of collected segments if Euler fails or not enough terms.\\n    initial_sum_segments = np.sum(segment_integrals) if segment_integrals else 0.0\\n    \\n    # Apply Euler's Transformation for series acceleration\\n    N_segments = len(segment_integrals)\\n    if N_segments < min_segments_for_euler:\\n        # Not enough terms for reliable Euler transformation.\\n        # Fallback to direct sum, but acknowledge it might not be fully converged.\\n        return initial_sum_segments, np.inf \\n\\n    # Implement Euler's transformation efficiently using numpy array operations\\n    # The Euler transform is applied to the sequence of terms, assuming it's alternating\\n    euler_sums = np.array(segment_integrals, dtype=float)\\n    # The first diagonal value is the first term itself.\\n    euler_diagonal_values = [euler_sums[0]] \\n    consecutive_converged_count = 0\\n    target_consecutive_converged = 5 # Increased from 4 for stricter convergence\\n\\n    try:\\n        max_euler_levels = N_segments - 1\\n\\n        # Use the iterative averaging method for Euler's transformation, which is robust\\n        current_row = euler_sums\\n        for m in range(max_euler_levels): \\n            if len(current_row) < 2:\\n                break\\n            \\n            # Compute the next level of Euler transformation (averaging adjacent terms)\\n            next_row_array = (current_row[:-1] + current_row[1:]) / 2.0\\n            current_row = next_row_array\\n            \\n            current_euler_val = current_row[0]\\n            euler_diagonal_values.append(current_euler_val) \\n            \\n            # Check for convergence in the Euler diagonal.\\n            if m > 0 and len(euler_diagonal_values) >= 2:\\n                prev_euler_val = euler_diagonal_values[-2]\\n                diff = abs(current_euler_val - prev_euler_val)\\n                \\n                # Convergence criteria: difference very small relatively OR absolutely.\\n                # Use absolute tolerance for diff when the value itself is near zero.\\n                if (abs(current_euler_val) > euler_abs_tol and diff < euler_rel_tol * abs(current_euler_val)) or \\\\\\n                   (abs(current_euler_val) <= euler_abs_tol and diff < euler_abs_tol): # Use abs_tol for diff when value is near zero\\n                    consecutive_converged_count += 1\\n                else:\\n                    consecutive_converged_count = 0 \\n                \\n                if consecutive_converged_count >= target_consecutive_converged:\\n                    break\\n                \\n                # Check for strong divergence in Euler diagonal (transformation becoming unstable).\\n                # This indicates the series might not be suitable for Euler acceleration or numerical instability.\\n                if m > 2 and abs(current_euler_val) > abs(prev_euler_val) * 10000 and abs(prev_euler_val) > euler_abs_tol * 0.1: # Increased factor for clear divergence\\n                    # If Euler diverges, fallback to sum of segments as best guess, error inf.\\n                    return initial_sum_segments, np.inf\\n\\n    except Exception:\\n        # If any numerical instability occurs during Euler transformation,\\n        # return the sum of segments as the best available estimate, with high error.\\n        return initial_sum_segments, np.inf\\n\\n    # Final result from Euler transformation (last value on the diagonal)\\n    final_answer = euler_diagonal_values[-1] if len(euler_diagonal_values) > 0 else initial_sum_segments\\n    \\n    # Calculate error estimate based on Euler convergence.\\n    error_estimate = np.inf # Default error\\n\\n    if len(euler_diagonal_values) >= 2:\\n        last_diff_euler = abs(euler_diagonal_values[-1] - euler_diagonal_values[-2])\\n        # If the process converged sufficiently according to strict criteria\\n        if consecutive_converged_count >= target_consecutive_converged:\\n            # The error is estimated by the last difference in the converging diagonal.\\n            # Also ensure it meets the absolute/relative tolerance minimum.\\n            error_estimate = max(last_diff_euler, \\n                                 euler_rel_tol * abs(final_answer), \\n                                 euler_abs_tol) \\n        else:\\n            # If not strictly converged, but the Euler transformation ran and\\n            # produced a sequence of values, use the last difference as a heuristic for error.\\n            # Capped to avoid over-optimism or underestimation.\\n            error_estimate = min(np.inf, last_diff_euler * target_consecutive_converged * 2) # Heuristic multiplier\\n            \\n            # Ensure a minimum error even if difference is tiny.\\n            if abs(final_answer) < euler_abs_tol * 10: # If result is near zero\\n                error_estimate = max(error_estimate, euler_abs_tol * 0.5) # A larger fraction of abs_tol\\n            elif abs(final_answer) > euler_abs_tol * 10: # If result is non-zero\\n                 error_estimate = max(error_estimate, euler_rel_tol * abs(final_answer) * 0.5) # A larger fraction of rel_tol\\n            \\n            # If Euler transformation did not converge as expected, the estimate is less reliable.\\n            # Assign a higher error to reflect this uncertainty.\\n            if not np.isinf(error_estimate): # Only if it's not already infinite\\n                error_estimate = min(np.inf, error_estimate * 10) # Significantly higher error\\n\\n    # Final check for NaN/Inf results from any stage.\\n    if np.isnan(final_answer) or np.isinf(final_answer):\\n        return np.nan, np.inf\\n\\n    return final_answer, error_estimate"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
