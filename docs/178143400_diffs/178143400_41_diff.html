<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": 10.0,
  "old_code": "import math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    try:\\n        answer, error_estimate = scipy.integrate.quad(integrand, lower_limit, upper_limit)\\n\\n        # Check for NaN or Inf results/errors from quad, or if error is too high\\n        # A common heuristic for \\"unreliable\\" is error_estimate being comparable to or larger than the answer.\\n        if (np.isnan(answer) or np.isinf(answer) or\\n            np.isnan(error_estimate) or np.isinf(error_estimate) or\\n            (abs(answer) > 1e-10 and error_estimate / abs(answer) > 0.05) or # Relative error check\\n            (abs(answer) <= 1e-10 and error_estimate > 1e-8)): # Absolute error check for small results\\n            raise ValueError(\\"scipy.integrate.quad failed to converge reliably or error is too high.\\")\\n            \\n        return answer, error_estimate\\n    except Exception:\\n        # If quad fails or raises an error, fall back to a more robust method for oscillatory integrals\\n        pass # Continue to specialized method\\n\\n    # --- Step 2: Handle Infinite Limits for Specialized Method ---\\n    # Convert all integrals to the form [a, inf) for uniform processing.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, 0] and [0, inf)\\n        val1, err1 = quadrature(integrand, lower_limit, 0)\\n        val2, err2 = quadrature(integrand, 0, upper_limit)\\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-b}^{inf} f(-t) dt\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t)\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] where quad failed.\\n        # This implies a very difficult finite integral. Try Romberg as a last resort.\\n        try:\\n            # Romberg is good for smooth functions over finite intervals.\\n            # It may struggle with oscillations or singularities.\\n            ans_romberg = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=20)\\n            # Romberg does not directly return error. A rough estimate is difference of last two levels.\\n            # This is a heuristic error estimate, not from a rigorous error bounds.\\n            ans_romberg_prev = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=19)\\n            err_romberg = abs(ans_romberg - ans_romberg_prev) * 10 # Scale difference for a rough error\\n            return ans_romberg, err_romberg\\n        except Exception:\\n            return np.nan, np.inf # Indicate failure\\n\\n    # --- Step 3: Specialized Fallback for Oscillatory Integrals on [a, inf) ---\\n    # This method is for [a, inf) where 'a' is finite.\\n    # It assumes the integrand oscillates and decays.\\n\\n    start_oscillation_point = lower_limit\\n    segment_length = math.pi  # Heuristic for half-period of common oscillations (sin(x), cos(x))\\n    \\n    # Store segment integrals for Euler transformation\\n    segment_integrals = []\\n    \\n    # Accumulate initial terms by direct integration over segments\\n    num_segments_to_try = 100 # Maximum number of segments to compute\\n    min_segments_for_euler = 5 # Minimum terms required for Euler transformation to be meaningful\\n\\n    for i in range(num_segments_to_try):\\n        seg_start = start_oscillation_point + i * segment_length\\n        seg_end = start_oscillation_point + (i + 1) * segment_length\\n\\n        try:\\n            seg_val, seg_err = scipy.integrate.quad(integrand, seg_start, seg_end, limit=200, epsabs=1e-10, epsrel=1e-10) # Higher limit/precision for segments\\n            segment_integrals.append(seg_val)\\n\\n            # Check for decay: if terms are consistently very small, we might have converged\\n            if i >= min_segments_for_euler and abs(seg_val) < 1e-12 * abs(np.sum(segment_integrals[:-1])):\\n                # print(f\\"Segment terms decaying quickly at iteration {i}. Summing directly.\\")\\n                break # Stop collecting terms\\n            \\n            # If terms start to grow or fluctuate erratically, break as convergence is unlikely\\n            if i > 0 and abs(seg_val) > abs(segment_integrals[-2]) * 10 and abs(segment_integrals[-2]) > 1e-10:\\n                # print(f\\"Terms not decaying, or growing at iteration {i}. Direct sum so far.\\")\\n                # This suggests the integral is not converging, or the segment_length is wrong.\\n                return np.sum(segment_integrals), np.inf # Return current sum with high error\\n            \\n        except Exception:\\n            # If any segment integration fails, return the sum of successful segments\\n            # with a high error to indicate uncertainty.\\n            # print(f\\"scipy.integrate.quad failed for segment {seg_start}-{seg_end}.\\")\\n            return np.sum(segment_integrals), np.inf\\n\\n    # --- Step 4: Apply Series Acceleration (Euler's Transformation) ---\\n    # This version of Euler transformation is suitable for alternating series\\n    # S = a_0 - a_1 + a_2 - a_3 + ... or any series that becomes alternating after few terms\\n    # It requires the terms to decrease in magnitude.\\n    \\n    N = len(segment_integrals)\\n    if N < min_segments_for_euler:\\n        # Not enough terms collected for Euler transformation, return simple sum\\n        return np.sum(segment_integrals), np.inf # High uncertainty\\n\\n    # Euler transformation implementation\\n    # This iterative form computes a triangular array of sums,\\n    # often converging on the diagonal.\\n    \\n    sums = np.array(segment_integrals, dtype=float)\\n    \\n    try:\\n        for _ in range(max(1, N - 1)): # Iterate N-1 times to reduce sums array to 1 element\\n            if len(sums) < 2:\\n                break\\n            # Compute new terms by averaging adjacent elements\\n            new_sums = (sums[:-1] + sums[1:]) / 2.0\\n            # If terms are alternating, Delta terms will make a more stable sequence.\\n            # Here, we directly average sums for a conceptual Euler transformation.\\n            \\n            # More stable Euler: sums[i] = (old_sums[i] + old_sums[i+1])/2\\n            # This is a bit simplistic, as actual Euler involves differences.\\n            \\n            # Let's use a standard Richardson-like extrapolation idea which Euler uses.\\n            # The simple iterative averaging does perform some level of acceleration for\\n            # alternating series.\\n            \\n            # This is a common form of Euler transformation applied to partial sums:\\n            # S_0 = a_0, S_1 = a_0+a_1, S_2 = a_0+a_1+a_2, ...\\n            # Then T_0 = (S_0+S_1)/2, T_1 = (S_1+S_2)/2, ...\\n            # Then U_0 = (T_0+T_1)/2, ... and so on. The diagonal usually converges.\\n\\n            # We have segment_integrals which are a_k.\\n            # Compute partial sums first.\\n            if N > 0:\\n                partial_sum_sequence = np.cumsum(segment_integrals)\\n                \\n                # Apply Euler transformation on \`partial_sum_sequence\`\\n                # This requires a triangular array, which can be computationally intensive.\\n                # A simplified approach is to use the last element after several averaging steps.\\n\\n                # Simplified: average the current sums\\n                if len(new_sums) > 0:\\n                    sums = new_sums\\n                else:\\n                    break # Only one term left, or no terms for averaging\\n\\n            # Check if the series is actually converging via this method\\n            if len(sums) > 0 and abs(sums[-1] - sums[0]) < 1e-8 * abs(sums[0]) and len(sums) > 1:\\n                # print(f\\"Euler transformation converged with {len(sums)} terms remaining.\\")\\n                break\\n\\n    except Exception:\\n        # print(\\"Euler transformation encountered an error.\\")\\n        pass\\n\\n    # The final result is the last term in the \`sums\` array after transformation\\n    final_answer = sums[0] if len(sums) > 0 else np.sum(segment_integrals)\\n    \\n    # Estimate error: If Euler converged well, the error is very small, otherwise higher.\\n    # A common error estimate for Euler is the magnitude of the last neglected term or a multiple of it.\\n    if len(sums) > 1:\\n        error_estimate = abs(sums[0] - sums[1]) * 2 # Roughly the difference of the last two averages\\n    elif len(segment_integrals) > 0:\\n        error_estimate = abs(segment_integrals[-1]) * 10 # If only one Euler term, error is last segment's size.\\n    else:\\n        error_estimate = np.inf # No segments successfully integrated\\n\\n    if np.isnan(final_answer) or np.isinf(final_answer):\\n        # If Euler also gives NaN/Inf, return ultimate failure\\n        return np.nan, np.inf\\n\\n    return final_answer, error_estimate",
  "new_index": 41,
  "new_code": "import math\\nfrom typing import Any, Callable, Tuple\\nimport numpy as np\\nimport scipy.integrate\\nimport scipy.optimize\\nfrom scipy.special import sum_euler\\n\\ndef _find_next_root(func: Callable[[float], float], x_start: float, initial_step: float, max_search_steps: int = 150) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Finds the next root of func(x) after x_start.\\n    Returns (root, actual_distance_covered_to_find_root)\\n    If no root is found up to max_search_steps, returns (np.inf, last_step_attempted).\\n    \\"\\"\\"\\n    current_x = x_start\\n    step = initial_step\\n    \\n    # Adjust x_start if it's too close to a root or is a root to find the *next* distinct root\\n    f_val_at_start = func(x_start)\\n    if abs(f_val_at_start) < 1e-12: # If x_start is approximately a root\\n        current_x = x_start + step / 10.0 # Nudge past it\\n        # Ensure nudge is effective for very small or very large x_start\\n        if current_x <= x_start:\\n            current_x = x_start + 1e-6 # Absolute small step\\n        f_start_search = func(current_x)\\n    else:\\n        f_start_search = f_val_at_start\\n\\n    for i in range(max_search_steps):\\n        x_end_search = current_x + step\\n        f_end_search = func(x_end_search)\\n\\n        # Check if a sign change occurred, indicating a root in [current_x, x_end_search]\\n        if np.sign(f_start_search) != np.sign(f_end_search) and f_start_search != 0 and f_end_search != 0:\\n            try:\\n                # Found a bracket, refine the root using Brent's method (robust)\\n                root_result = scipy.optimize.root_scalar(func, bracket=[current_x, x_end_search], method='brentq', xtol=1e-13)\\n                # Return the found root and the actual distance from original x_start\\n                return root_result.root, (root_result.root - x_start) \\n            except ValueError:\\n                # If root_scalar fails (e.g., function too flat, multiple roots in bracket, etc.)\\n                # this indicates a problematic section for root finding.\\n                # Signal failure to find a clean root, implying this method might not be suitable for this segment.\\n                return np.inf, step \\n        \\n        # Check for decay: if function value becomes very small, oscillations might have ceased\\n        # This is to prevent infinite loops for functions decaying to zero without crossing axis.\\n        if abs(f_end_search) < 1e-15 * (1 + abs(f_start_search)) and abs(f_start_search) > 1e-10:\\n            # Function value has decayed significantly.\\n            # Consider this the effective end of the oscillation domain.\\n            return np.inf, step # Signal end of oscillations\\n        \\n        # Update for next iteration\\n        current_x = x_end_search\\n        f_start_search = f_end_search\\n        \\n        # Adaptive step size: If no root is found, increase the search step to cover more ground.\\n        # This is a heuristic. For decreasing oscillation periods (e.g., sin(x^2)), this step\\n        # adjustment is suboptimal, and a more specific 'points' approach would be better.\\n        # However, for a general function, increasing step is a common strategy.\\n        if i > 0:\\n            step *= 1.2 \\n            \\n    return np.inf, step # No root found within max_search_steps\\n\\n\\ndef quadrature(\\n    integrand: Callable[float, float],\\n    lower_limit: float,\\n    upper_limit: float,\\n) -> Tuple[float, float]:\\n    \\"\\"\\"\\n    Estimate the numeric value of the definite integral, especially\\n    when scipy.integrate.quad() fails to converge or returns a large error\\n    estimate or NaN.\\n    \\"\\"\\"\\n\\n    # --- Step 1: Initial Attempt with scipy.integrate.quad() ---\\n    try:\\n        # Increase limits and precision for quad to give it a fair chance\\n        answer, error_estimate = scipy.integrate.quad(integrand, lower_limit, upper_limit, limit=200, epsabs=1e-9, epsrel=1e-9)\\n\\n        # Check for NaN or Inf results/errors from quad, or if error is too high\\n        # Use a threshold for error relative to absolute value, or absolute error for small answers.\\n        is_unreliable = (np.isnan(answer) or np.isinf(answer) or\\n                         np.isnan(error_estimate) or np.isinf(error_estimate) or\\n                         (abs(answer) > 1e-10 and error_estimate / abs(answer) > 0.01) or # Relative error check (1%)\\n                         (abs(answer) <= 1e-10 and error_estimate > 1e-7)) # Absolute error check for small results\\n        \\n        if is_unreliable:\\n            # print(f\\"Initial quad failed reliably for {lower_limit} to {upper_limit}. Answer: {answer}, Error: {error_estimate}\\")\\n            raise ValueError(\\"scipy.integrate.quad failed to converge reliably or error is too high.\\")\\n            \\n        return answer, error_estimate\\n    except Exception:\\n        # print(f\\"Initial quad failed with error: {e}. Falling back to specialized method.\\")\\n        pass # Continue to specialized method\\n\\n    # --- Step 2: Handle Infinite Limits for Specialized Method ---\\n    # Convert all integrals to the form [a, inf) for uniform processing.\\n    if lower_limit == -np.inf and upper_limit == np.inf:\\n        # Split into two infinite integrals: (-inf, C] and [C, inf)\\n        # Choosing C=0 is typical and safe.\\n        val1, err1 = quadrature(integrand, lower_limit, 0)\\n        val2, err2 = quadrature(integrand, 0, upper_limit)\\n        return val1 + val2, err1 + err2\\n    elif lower_limit == -np.inf and upper_limit != np.inf: # Case: (-inf, b]\\n        # Transform x -> -t, dx -> -dt. Integral becomes int_{-upper_limit}^{inf} f(-t) dt\\n        def transformed_integrand_neg_inf(t):\\n            return integrand(-t)\\n        # Recursive call with transformed integrand and limits [ -upper_limit, inf)\\n        return quadrature(transformed_integrand_neg_inf, -upper_limit, np.inf)\\n    elif upper_limit != np.inf: # Case: [a, b] where quad failed.\\n        # For a finite interval where quad failed (e.g., due to severe oscillations or singularities),\\n        # Romberg is an option but primarily for smooth functions.\\n        try:\\n            # Romberg is typically for well-behaved functions over finite intervals.\\n            # It's a less robust fallback for hard oscillatory/singular finite integrals.\\n            # Using it here as it was in the original, but acknowledge its limitations.\\n            ans_romberg = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=20)\\n            # Romberg does not directly return error. A rough estimate is difference of last two levels.\\n            ans_romberg_prev = scipy.integrate.romberg(integrand, lower_limit, upper_limit, divmax=19)\\n            err_romberg = abs(ans_romberg - ans_romberg_prev) * 10 # Scale difference for a rough error\\n            return ans_romberg, err_romberg\\n        except Exception:\\n            return np.nan, np.inf # Indicate failure for finite domain if quad and Romberg failed.\\n\\n    # --- Step 3: Specialized Fallback for Oscillatory Integrals on [a, inf) ---\\n    # This method is for [a, inf) where 'a' is finite.\\n    # It attempts to find roots of the integrand to define integration segments for series acceleration.\\n\\n    current_x = lower_limit\\n    segment_integrals = []\\n    \\n    # Heuristic for initial step size for root finding.\\n    initial_search_step = math.pi # A common period guess. It will adapt based on found roots.\\n    \\n    # Max number of segments to compute directly to check for pattern/decay\\n    max_segments_to_collect = 300 \\n    # Min segments for sum_euler to work well\\n    min_segments_for_euler = 5 \\n    \\n    # A threshold to consider integrand decayed. Could be relative or absolute.\\n    decay_threshold_val = 1e-12 \\n    \\n    segment_error_sum = 0.0 # Accumulate errors from segment integrations\\n\\n    # Collect segment integrals by finding consecutive roots of the integrand\\n    for i in range(max_segments_to_collect):\\n        try:\\n            next_root, actual_step_size_taken = _find_next_root(integrand, current_x, initial_search_step)\\n            \\n            # If next_root is np.inf, it means no more distinct roots were found within search range,\\n            # or the integrand has decayed significantly.\\n            if next_root == np.inf:\\n                # Integrate from current_x to infinity for the tail.\\n                # If this fails, then the remaining integral is hard.\\n                tail_val, tail_err = scipy.integrate.quad(integrand, current_x, np.inf, limit=200, epsabs=1e-10, epsrel=1e-10)\\n                segment_integrals.append(tail_val)\\n                segment_error_sum += tail_err\\n                break # All oscillations effectively handled\\n            \\n            # Integrate over the segment between roots\\n            seg_val, seg_err = scipy.integrate.quad(integrand, current_x, next_root, limit=200, epsabs=1e-12, epsrel=1e-12)\\n            \\n            segment_integrals.append(seg_val)\\n            segment_error_sum += seg_err\\n\\n            # Update initial_search_step for next root search based on the actual segment length found\\n            # This helps adapt to changing oscillation frequencies (e.g., sin(x^2))\\n            # But only if a valid step was found.\\n            if actual_step_size_taken > 1e-10: # Avoid tiny steps leading to issues\\n                initial_search_step = actual_step_size_taken \\n\\n            # Check for decay: if segment value is very small, oscillations might have effectively ceased\\n            # This is a critical check for convergence for integrals over infinite domains.\\n            if i >= min_segments_for_euler and abs(seg_val) < decay_threshold_val * (1 + abs(np.sum(segment_integrals[:-1]))):\\n                # If significant decay observed, attempt to integrate the remaining tail to infinity\\n                tail_val, tail_err = scipy.integrate.quad(integrand, next_root, np.inf, limit=200, epsabs=1e-10, epsrel=1e-10)\\n                segment_integrals.append(tail_val) # Add the tail integral as a last segment\\n                segment_error_sum += tail_err\\n                break # Stop collecting terms\\n            \\n            # Check for non-convergence or growing terms (indicates issue or non-convergent integral)\\n            if i > 0 and abs(seg_val) > abs(segment_integrals[-2]) * 10 and abs(segment_integrals[-2]) > decay_threshold_val:\\n                # Terms are growing or not decaying as expected for a convergent oscillatory integral.\\n                return np.sum(segment_integrals), np.inf # Return current sum with high error\\n            \\n            current_x = next_root\\n            \\n        except Exception as e:\\n            # If any segment integration or root finding fails unexpectedly\\n            # Return the sum of successful segments with high error to indicate uncertainty\\n            # print(f\\"Segment integration or root finding failed at iteration {i}: {e}\\")\\n            return np.sum(segment_integrals), np.inf\\n\\n    # --- Step 4: Apply Series Acceleration (Euler's Transformation) ---\\n    # \`sum_euler\` is suitable for series sum_{k=0}^N (-1)^k a_k where a_k > 0 and decays.\\n    # Our \`segment_integrals\` list contains s_k = Integral(f(x) dx) over [x_k, x_{k+1}]\\n    # If the integrand f(x) genuinely oscillates around zero, s_k will have alternating signs.\\n\\n    N = len(segment_integrals)\\n    if N < min_segments_for_euler:\\n        # Not enough terms collected for reliable Euler transformation\\n        # Return direct sum and a heuristic error (e.g., 10% of sum or sum of segment errors)\\n        return np.sum(segment_integrals), segment_error_sum + abs(np.sum(segment_integrals)) * 0.1 \\n\\n    # Prepare terms for sum_euler.\\n    # sum_euler expects a sequence of *positive* terms and applies the alternating sign itself.\\n    # We need to sum s_0 + s_1 + s_2 + ...\\n    # If s_k = (-1)^k * b_k (where b_k > 0), then sum_euler(b_k) computes this.\\n    # If s_0 is negative, we can compute -sum_euler(abs(s_k)) if s_k = -(-1)^k * b_k\\n    \\n    # Check if the series is predominantly alternating and extract absolute values\\n    is_predominantly_alternating = True\\n    sign_checker = np.sign(segment_integrals[0]) # Expected sign of the first term\\n    if sign_checker == 0 and N > 1: # If first term is zero, check next\\n        sign_checker = np.sign(segment_integrals[1])\\n    \\n    euler_terms = []\\n    initial_negation = False\\n    if sign_checker < 0: # If the first non-zero term is negative\\n        initial_negation = True\\n\\n    for i, s_k in enumerate(segment_integrals):\\n        if abs(s_k) > 1e-15: # Avoid adding tiny terms\\n            expected_sign = sign_checker * ((-1)**i)\\n            if np.sign(s_k) != expected_sign:\\n                is_predominantly_alternating = False\\n                break\\n            euler_terms.append(abs(s_k))\\n        else: # If segment value is essentially zero, it doesn't break the alternating pattern\\n            euler_terms.append(0.0) # Keep array length consistent for sum_euler\\n\\n    final_answer = np.sum(segment_integrals) # Default to direct sum\\n    error_estimate = segment_error_sum\\n\\n    if is_predominantly_alternating and len(euler_terms) >= min_segments_for_euler:\\n        try:\\n            accelerated_sum = sum_euler(euler_terms)\\n            if initial_negation:\\n                final_answer = -accelerated_sum\\n            else:\\n                final_answer = accelerated_sum\\n            \\n            # Error estimate for accelerated sum: can be related to the last term of the transformed series\\n            # A common heuristic is a multiple of the last *effective* term from acceleration.\\n            # Here, we use a multiple of the last absolute segment integral.\\n            error_estimate = abs(euler_terms[-1]) * 10 # Heuristic, could be more refined\\n            \\n        except Exception:\\n            # print(f\\"Euler transformation failed. Falling back to direct sum.\\")\\n            pass # Keep direct sum as fallback\\n\\n    if np.isnan(final_answer) or np.isinf(final_answer):\\n        # If the specialized method also yields NaN/Inf, return ultimate failure\\n        return np.nan, np.inf\\n\\n    return final_answer, error_estimate"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
