<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diff Viewer</title>
    <!-- Google "Inter" font family -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        display: flex;
        margin: 0; /* Simplify bounds so the parent can determine the correct iFrame height. */
        padding: 0;
        overflow: hidden; /* Code can be long and wide, causing scroll-within-scroll. */
      }

      .container {
        padding: 1.5rem;
        background-color: #fff;
      }

      h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1f2937;
        margin-bottom: 1rem;
        text-align: center;
      }

      .diff-output-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        background-color: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 0.75rem;
        box-shadow:
          0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        padding: 1.5rem;
        font-size: 0.875rem;
        line-height: 1.5;
      }

      .diff-original-column {
        padding: 0.5rem;
        border-right: 1px solid #cbd5e1;
        min-height: 150px;
      }

      .diff-modified-column {
        padding: 0.5rem;
        min-height: 150px;
      }

      .diff-line {
        display: block;
        min-height: 1.5em;
        padding: 0 0.25rem;
        white-space: pre-wrap;
        word-break: break-word;
      }

      .diff-added {
        background-color: #d1fae5;
        color: #065f46;
      }
      .diff-removed {
        background-color: #fee2e2;
        color: #991b1b;
        text-decoration: line-through;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="diff-output-container">
        <div class="diff-original-column">
          <h2 id="original-title">Before</h2>
          <pre id="originalDiffOutput"></pre>
        </div>
        <div class="diff-modified-column">
          <h2 id="modified-title">After</h2>
          <pre id="modifiedDiffOutput"></pre>
        </div>
      </div>
    </div>
    <script>
      // Function to dynamically load the jsdiff library.
      function loadJsDiff() {
        const script = document.createElement("script");
        script.src = "https://cdnjs.cloudflare.com/ajax/libs/jsdiff/8.0.2/diff.min.js";
        script.integrity =
          "sha512-8pp155siHVmN5FYcqWNSFYn8Efr61/7mfg/F15auw8MCL3kvINbNT7gT8LldYPq3i/GkSADZd4IcUXPBoPP8gA==";
        script.crossOrigin = "anonymous";
        script.referrerPolicy = "no-referrer";
        script.onload = populateDiffs; // Call populateDiffs after the script is loaded
        script.onerror = () => {
          console.error("Error: Failed to load jsdiff library.");
          const originalDiffOutput = document.getElementById("originalDiffOutput");
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = "";
          }
        };
        document.head.appendChild(script);
      }

      function populateDiffs() {
        const originalDiffOutput = document.getElementById("originalDiffOutput");
        const modifiedDiffOutput = document.getElementById("modifiedDiffOutput");
        const originalTitle = document.getElementById("original-title");
        const modifiedTitle = document.getElementById("modified-title");

        // Check if jsdiff library is loaded.
        if (typeof Diff === "undefined") {
          console.error("Error: jsdiff library (Diff) is not loaded or defined.");
          // This case should ideally be caught by script.onerror, but keeping as a fallback.
          if (originalDiffOutput) {
            originalDiffOutput.innerHTML =
              '<p style="color: #dc2626; text-align: center; padding: 2rem;">Error: Diff library failed to load. Please try refreshing the page or check your internet connection.</p>';
          }
          if (modifiedDiffOutput) {
            modifiedDiffOutput.innerHTML = ""; // Clear modified output if error
          }
          return; // Exit since jsdiff is not loaded.
        }

        // The injected codes to display.
        const codes = JSON.parse(`{
  "old_index": 0.0,
  "old_code": "#TODO(LLM): pip install any additional libraries you may need\\n\\nclass Model:\\n    # TODO(LLM): Implement a real model that can be trained and make predictions.\\n\\n    def segment_single_image(self, image: np.ndarray) -> np.ndarray:\\n        \\"\\"\\" Predicts the segmentation mask for a single image. \\"\\"\\"\\n        # TODO(LLM): Replace this placeholder with a real prediction.\\n        H, W, _ = image.shape\\n        return np.random.randint(0, 10, (H, W))\\n\\nmodel = Model()\\n\\nfor image, label_mask in training_data_paths:\\n  # TODO: Train the model on the each image/mask tumple in the \`training_data\` dataset\\n  break\\n",
  "new_index": 2,
  "new_code": "import torch\\nimport torch.nn as nn\\nfrom torch.utils.data import Dataset, DataLoader, Subset\\nimport torchvision.transforms as transforms\\nimport segmentation_models_pytorch as smp\\nimport numpy as np\\nfrom PIL import Image\\nimport os\\nimport tqdm # for progress bar\\nimport random # for setting random seeds\\nfrom sklearn.model_selection import train_test_split # To create a validation split from training data\\n\\n# Define constants\\nNUM_CLASSES = 17\\nIMG_SIZE = 256\\nBATCH_SIZE = 16\\nLEARNING_RATE = 1e-4\\nNUM_EPOCHS = 10\\nVALIDATION_SPLIT_RATIO = 0.1 # Use 10% of training data for validation during training\\n\\n# ImageNet means and stds for normalization, common for pre-trained backbones\\nMEAN = [0.485, 0.456, 0.406]\\nSTD = [0.229, 0.224, 0.225]\\n\\n# Device configuration\\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\\n# Function to set random seeds for reproducibility\\ndef _set_seed(seed=42):\\n    torch.manual_seed(seed)\\n    if torch.cuda.is_available():\\n        torch.cuda.manual_seed_all(seed)\\n    np.random.seed(seed)\\n    random.seed(seed)\\n    torch.backends.cudnn.deterministic = True\\n    torch.backends.cudnn.benchmark = False\\n\\n_set_seed(42) # Using the same seed as train/test split generation\\n\\n# Custom Dataset for DLRSD\\nclass DLRSDDataset(Dataset):\\n    def __init__(self, data_paths, transform=None):\\n        self.data_paths = data_paths\\n        self.transform = transform\\n\\n    def __len__(self):\\n        return len(self.data_paths)\\n\\n    def __getitem__(self, idx):\\n        image_path, label_path = self.data_paths[idx]\\n\\n        image = Image.open(image_path).convert('RGB')\\n        label = Image.open(label_path)\\n\\n        # Convert to numpy arrays first\\n        image_np = np.array(image, dtype=np.float32)\\n        label_np = np.array(label, dtype=np.int64)\\n\\n        # Labels are 1-indexed (1 to 17), convert to 0-indexed (0 to 16) for CrossEntropyLoss\\n        label_np = label_np - 1\\n\\n        if self.transform:\\n            image_tensor = self.transform(image_np)\\n            # Labels do not need image-like normalization, just conversion to tensor\\n            label_tensor = torch.from_numpy(label_np)\\n        else:\\n            # Fallback if no transform is provided (though transform is mandatory here)\\n            image_tensor = transforms.ToTensor()(image_np)\\n            label_tensor = torch.from_numpy(label_np)\\n\\n        return image_tensor, label_tensor\\n\\n# Image transformations for training and validation\\n# Note: ToPILImage is needed as torchvision.transforms typically operate on PIL Images.\\n# Transforms.ToTensor() converts HxWxC numpy to CxHxW tensor and scales [0, 255] to [0, 1].\\ntrain_transform = transforms.Compose([\\n    transforms.ToPILImage(),\\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\\n    transforms.ToTensor(),\\n    transforms.Normalize(mean=MEAN, std=STD)\\n])\\n\\nval_transform = transforms.Compose([\\n    transforms.ToPILImage(),\\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\\n    transforms.ToTensor(),\\n    transforms.Normalize(mean=MEAN, std=STD)\\n])\\n\\n# Custom Model wrapper class that conforms to the problem's expected interface\\nclass Model:\\n    def __init__(self, pytorch_model):\\n        self.pytorch_model = pytorch_model.to(device)\\n        self.val_transform = val_transform # Use validation transform for single image prediction\\n\\n    def segment_single_image(self, image: np.ndarray) -> np.ndarray:\\n        \\"\\"\\" Predicts the segmentation mask for a single image. \\"\\"\\"\\n        self.pytorch_model.eval() # Set model to evaluation mode\\n\\n        # Apply the same transformations as validation data and add batch dimension\\n        input_image = self.val_transform(image).unsqueeze(0).to(device)\\n\\n        with torch.no_grad():\\n            output_logits = self.pytorch_model(input_image)\\n\\n        # Get the class with the highest probability for each pixel\\n        # output_logits has shape (N, C, H, W)\\n        predicted_mask = torch.argmax(output_logits, dim=1).squeeze(0) # Remove batch dimension\\n\\n        # Convert to numpy array\\n        predicted_mask_np = predicted_mask.cpu().numpy()\\n\\n        # Convert 0-indexed predictions back to 1-indexed for evaluation\\n        predicted_mask_np = predicted_mask_np + 1\\n\\n        return predicted_mask_np\\n\\n# Prepare datasets and dataloaders\\nfull_train_dataset = DLRSDDataset(training_data_paths, transform=train_transform)\\n\\n# Split the training data into actual training and a validation subset\\ntrain_indices, val_indices = train_test_split(\\n    range(len(full_train_dataset)), test_size=VALIDATION_SPLIT_RATIO, random_state=42\\n)\\n\\ntrain_dataset_actual = Subset(full_train_dataset, train_indices)\\nval_dataset_for_training = Subset(full_train_dataset, val_indices) # This uses the *same* base dataset, but different indices\\n\\ntrain_loader = DataLoader(train_dataset_actual, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\\nval_loader = DataLoader(val_dataset_for_training, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\\n\\n\\n# Initialize the segmentation model (U-Net with ResNet34 backbone)\\nsmp_model = smp.Unet(\\n    encoder_name=\\"resnet34\\",       # Choose a robust encoder\\n    encoder_weights=\\"imagenet\\",    # Use pre-trained weights for faster convergence\\n    in_channels=3,                 # RGB image\\n    classes=NUM_CLASSES,           # Number of output classes (0-indexed: 0 to 16 for CrossEntropyLoss)\\n    activation=None                # No activation for CrossEntropyLoss (it applies softmax internally)\\n)\\nsmp_model.to(device)\\n\\n# Define loss function and optimizer\\ncriterion = nn.CrossEntropyLoss() # Suitable for multi-class pixel-wise classification\\noptimizer = torch.optim.Adam(smp_model.parameters(), lr=LEARNING_RATE)\\n\\n# Training loop\\nprint(f\\"Starting training for {NUM_EPOCHS} epochs on {device}...\\")\\nfor epoch in range(NUM_EPOCHS):\\n    smp_model.train() # Set model to training mode\\n    train_loss = 0.0\\n    with tqdm.tqdm(train_loader, desc=f\\"Epoch {epoch+1}/{NUM_EPOCHS} Train\\") as pbar:\\n        for images, masks in pbar:\\n            images = images.to(device)\\n            masks = masks.to(device) # Masks are already 0-indexed from dataset\\n\\n            optimizer.zero_grad()\\n            outputs = smp_model(images)\\n            loss = criterion(outputs, masks)\\n            loss.backward()\\n            optimizer.step()\\n\\n            train_loss += loss.item()\\n            pbar.set_postfix({'loss': loss.item()})\\n\\n    avg_train_loss = train_loss / len(train_loader)\\n    print(f\\"Epoch {epoch+1} finished. Avg Train Loss: {avg_train_loss:.4f}\\")\\n\\n    # Validation phase\\n    smp_model.eval() # Set model to evaluation mode\\n    val_loss = 0.0\\n    val_true_masks = []\\n    val_pred_masks = []\\n\\n    with torch.no_grad():\\n        with tqdm.tqdm(val_loader, desc=f\\"Epoch {epoch+1}/{NUM_EPOCHS} Val\\") as pbar_val:\\n            for images, masks in pbar_val:\\n                images = images.to(device)\\n                masks = masks.to(device) # Masks are 0-indexed\\n\\n                outputs = smp_model(images)\\n                loss = criterion(outputs, masks)\\n                val_loss += loss.item()\\n\\n                # Convert predictions to 1-indexed for mIoU calculation\\n                # torch.argmax returns 0-indexed class IDs\\n                preds = torch.argmax(outputs, dim=1).cpu().numpy() + 1\\n                # Convert true masks to 1-indexed for mIoU calculation\\n                masks_np = masks.cpu().numpy() + 1\\n\\n                val_true_masks.extend(preds.tolist()) # Extend as list of arrays\\n                val_pred_masks.extend(masks_np.tolist()) # Extend as list of arrays\\n\\n    avg_val_loss = val_loss / len(val_loader)\\n\\n    # Calculate mIoU on the validation set using 1-indexed masks\\n    current_mean_iou = calculate_mean_iou(\\n        np.array(val_true_masks), # Convert list of arrays back to single numpy array\\n        np.array(val_pred_masks), # Convert list of arrays back to single numpy array\\n        NUM_CLASSES,\\n        ignore_index=None # No ignore_index specified for DLRSD classes\\n    )\\n    print(f\\"Epoch {epoch+1} - Avg Val Loss: {avg_val_loss:.4f}, Val Mean IoU: {current_mean_iou:.4f}\\")\\n\\nprint(\\"Training complete!\\")\\n\\n# Assign the trained PyTorch model (wrapped in Model class) to the \`model\` variable\\nmodel = Model(smp_model)"
}`);
        const originalCode = codes["old_code"];
        const modifiedCode = codes["new_code"];
        const originalIndex = codes["old_index"];
        const modifiedIndex = codes["new_index"];

        function displaySideBySideDiff(originalText, modifiedText) {
          const diff = Diff.diffLines(originalText, modifiedText);

          let originalHtmlLines = [];
          let modifiedHtmlLines = [];

          const escapeHtml = (text) =>
            text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");

          diff.forEach((part) => {
            // Split the part's value into individual lines.
            // If the string ends with a newline, split will add an empty string at the end.
            // We need to filter this out unless it's an actual empty line in the code.
            const lines = part.value.split("\n");
            const actualContentLines =
              lines.length > 0 && lines[lines.length - 1] === "" ? lines.slice(0, -1) : lines;

            actualContentLines.forEach((lineContent) => {
              const escapedLineContent = escapeHtml(lineContent);

              if (part.removed) {
                // Line removed from original, display in original column, add blank in modified.
                originalHtmlLines.push(
                  `<span class="diff-line diff-removed">${escapedLineContent}</span>`,
                );
                // Use &nbsp; for consistent line height.
                modifiedHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
              } else if (part.added) {
                // Line added to modified, add blank in original column, display in modified.
                // Use &nbsp; for consistent line height.
                originalHtmlLines.push(`<span class="diff-line">&nbsp;</span>`);
                modifiedHtmlLines.push(
                  `<span class="diff-line diff-added">${escapedLineContent}</span>`,
                );
              } else {
                // Equal part - no special styling (no background)
                // Common line, display in both columns without any specific diff class.
                originalHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
                modifiedHtmlLines.push(`<span class="diff-line">${escapedLineContent}</span>`);
              }
            });
          });

          // Join the lines and set innerHTML.
          originalDiffOutput.innerHTML = originalHtmlLines.join("");
          modifiedDiffOutput.innerHTML = modifiedHtmlLines.join("");
        }

        // Initial display with default content on DOMContentLoaded.
        displaySideBySideDiff(originalCode, modifiedCode);

        // Title the texts with their node numbers.
        originalTitle.textContent = `Parent #${originalIndex}`;
        modifiedTitle.textContent = `Child #${modifiedIndex}`;
      }

      // Load the jsdiff script when the DOM is fully loaded.
      document.addEventListener("DOMContentLoaded", loadJsDiff);
    </script>
  </body>
</html>
